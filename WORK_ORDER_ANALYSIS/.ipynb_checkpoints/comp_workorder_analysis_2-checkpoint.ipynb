{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#general imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting imports\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textwrap import wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#set to display full column and cells to width of screen\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set style for seaborn plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "#custom color pallette (connected commmunities color palette)\n",
    "con_colors = ['#587EBF', '#548F8F', '#FD765B', '#C86FB4','#8FC7A1', '#AEE9FA']\n",
    "#setting palette\n",
    "sns.set_palette(sns.color_palette(con_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "#1. Define multiple string search function to be called when searching multiple words\n",
    "def mstrsrch(df, col, terms):\n",
    "    return df[col].str.contains('|'.join(terms), case = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check data type for each column, select only entries that can be or have been completed (includes \"open\" work orders), and make necessary conversions (i.e. datetime)\n",
    "2. Split LOCATION string based on period and REPAIRS_DONE_LIST on \";\" into new columns\n",
    "3. Move GND01 entries from building and staircase into ROOM column (indicates this is where an exterior compactor is located)\n",
    "4. Concatenate problem and failure columns\n",
    "5. Recode all exterior compactor entries to room location \n",
    "6. Split external compactor locations from internal compactor rooms by (de)selecting GND01\n",
    "7. Categorization process\n",
    "\n",
    "9. Join (overwrite using .update) manually corrected miscategorized compactor entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1A. Load CSV\n",
    "comp_data_raw = pd.read_csv(\"comp_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1B. Select for LAST_LABTRANS_TRANSTYPE == WORK. This is because other data is unreliable and many conditions are found to be \"unfounded\" or the staff cannot gain access to the floor/room.\n",
    "#    other analysis should be completed for non-work values\n",
    "comp_data_raw = comp_data_raw[comp_data_raw.LAST_LABTRANS_TRANSTYPE == 'WORK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1B. Convert date columns to datetime\n",
    "comp_data_raw[\"REPORTDATE\"] = pd.to_datetime(comp_data_raw[\"REPORTDATE\"])\n",
    "comp_data_raw[\"ZZCREATEDATE\"] = pd.to_datetime(comp_data_raw[\"ZZCREATEDATE\"])\n",
    "comp_data_raw[\"SCHEDSTART\"] = pd.to_datetime(comp_data_raw[\"SCHEDSTART\"],errors='coerce')\n",
    "comp_data_raw[\"TARGSTARTDATE\"] = pd.to_datetime(comp_data_raw[\"TARGSTARTDATE\"], errors='coerce')\n",
    "comp_data_raw[\"ACTSTART\"] = pd.to_datetime(comp_data_raw[\"ACTSTART\"])\n",
    "comp_data_raw[\"ACTFINISH\"] = pd.to_datetime(comp_data_raw[\"ACTFINISH\"])\n",
    "comp_data_raw[\"STATUSDATE\"] = pd.to_datetime(comp_data_raw[\"STATUSDATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2A. Split location string\n",
    "# KEY: 0 - TDS, 1 - BUILDING, 2 - STAIRHALL, 3 - ROOM\n",
    "# new data frame with split value columns \n",
    "split_loc = comp_data_raw[\"LOCATION\"].str.split(\".\", expand = True) \n",
    "# assign new columns based on split\n",
    "comp_data_raw[\"TDS\"]= split_loc[0] \n",
    "comp_data_raw[\"BUILDING\"]= split_loc[1]\n",
    "comp_data_raw[\"STAIRHALL\"]= split_loc[2] \n",
    "comp_data_raw[\"ROOM\"]= split_loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2B. Split REPAIRS_DONE_LIST\n",
    "split_repairs = comp_data_raw[\"REPAIRS_DONE_LIST\"].str.split(\";\", expand = True) \n",
    "# assign new columns based on split\n",
    "comp_data_raw[\"REPAIR1\"]= split_repairs[0] \n",
    "comp_data_raw[\"REPAIR2\"]= split_repairs[1]\n",
    "comp_data_raw[\"REPAIR3\"]= split_repairs[2] \n",
    "comp_data_raw[\"REPAIR4\"]= split_repairs[3]\n",
    "comp_data_raw[\"REPAIR5\"]= split_repairs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3A. Copy GND01 and erase GND01 from BUILDING column\n",
    "comp_data_raw[\"ROOM\"] = np.where(comp_data_raw.BUILDING.str.contains(\"GND01\")== True, \"GND01\", comp_data_raw[\"ROOM\"])\n",
    "comp_data_raw[\"BUILDING\"] = np.where(comp_data_raw.BUILDING.str.contains('GND01') == True, \"\", comp_data_raw[\"BUILDING\"])\n",
    "\n",
    "#3B. Copy GND01 to ROOM column and erase GND01 from STAIRHALL column\n",
    "comp_data_raw[\"ROOM\"] = np.where(comp_data_raw.STAIRHALL.str.contains(\"GND01\")== True, \"GND01\", comp_data_raw[\"ROOM\"])\n",
    "comp_data_raw[\"STAIRHALL\"] = np.where(comp_data_raw.STAIRHALL.str.contains('GND01') == True, \"\", comp_data_raw[\"STAIRHALL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Concatenate problem and failure code\n",
    "comp_data_raw['PROBLEMFAILURE'] = comp_data_raw['PROBLEMCODE'] + comp_data_raw['FAILURECODE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5A. Recode exterior compactor entries as ROOM == 'GND01'\n",
    "ext_terms = ['EXTERIOR', 'EZ', 'E-Z']\n",
    "comp_data_raw[\"ROOM\"] = np.where(mstrsrch(comp_data_raw, 'DESCRIPTION', ext_terms) | mstrsrch(comp_data_raw, 'PROBLEMFAILURE', ext_terms) == True, \"GND01\", comp_data_raw['ROOM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Split interior compactor work orders and exterior compactor work orders based on location\n",
    "int_comp_data = comp_data_raw[comp_data_raw.ROOM != \"GND01\"]\n",
    "ext_comp_data = comp_data_raw[comp_data_raw.ROOM == \"GND01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPAIR ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Function for graph generation of top 5 repairs by type for each development:\n",
    "    1. Iterate through unique consolidation\n",
    "        1. Iterate through developments within each consolidation\n",
    "            1. Apply value_counts to each REPAIR column\n",
    "            2. Create SUM column with sum of each repair row\n",
    "            3. Take 5 largest values\n",
    "            4. Plot values on bar graph\n",
    "            5. Export bar graph with unique consolidation,development,and building identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Define function for graph production of 5 most common repairs for each development\n",
    "\n",
    "def top_5_rep_by_dev(df, comp_type):\n",
    "    #comp_type is interior or exterior\n",
    "    comp_type = comp_type.title()\n",
    "    #iterate through consolidation\n",
    "    for consol_name in df.CONSOLIDATED_NAME.unique().tolist():\n",
    "        consol_rep_df = df[df.CONSOLIDATED_NAME == consol_name]\n",
    "        consol_num = consol_rep_df.loc[:, \"CONSOLIDATED_TDS_NUM\"].iloc[0]\n",
    "        #iterate through each development within the consolidation\n",
    "        for dev_name in consol_rep_df.DEVELOPMENT_NAME.unique().tolist():\n",
    "            dev_rep_df = consol_rep_df[consol_rep_df.DEVELOPMENT_NAME == dev_name]\n",
    "            dev_num = dev_rep_df.loc[:, \"TDS_NUM\"].iloc[0]\n",
    "            dev_rep = dev_rep_df[['REPAIR1', 'REPAIR2', 'REPAIR3', 'REPAIR4', 'REPAIR5']].apply(pd.Series.value_counts)\n",
    "            dev_rep['SUM'] = dev_rep.sum(axis=1)\n",
    "            dev_rep_t5 = dev_rep.nlargest(5,'SUM')\n",
    "            if len(dev_rep_t5) >= 3:\n",
    "                #Plot values\n",
    "                ax = sns.barplot(x=dev_rep_t5.index.str.title(), y=dev_rep_t5['SUM'])\n",
    "                ax.set(xlabel=\"Repair Type\", ylabel = \"# of Repairs\")\n",
    "                ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\"right\")\n",
    "                ax.set_title('\\n'.join(wrap(\"Most Common Repairs by Type in \"+ comp_type + \" Compactor Locations in \"+dev_name.title()+ \" Development 1/1/2019 - 7/1/2020\")))\n",
    "                plt.tight_layout()\n",
    "                plt.savefig('Dev_'+comp_type+'_Comp_Repair_BarCharts/svg/'+consol_name.title()+'_'+str(consol_num)+'_'+dev_name.title()+'_'+str(dev_num)+\"_\"+comp_type+\"_Comp_Rep_BarChart.svg\")\n",
    "                plt.savefig('Dev_'+comp_type+'_Comp_Repair_BarCharts/png/'+consol_name.title()+'_'+str(consol_num)+'_'+dev_name.title()+'_'+str(dev_num)+\"_\"+comp_type+\"_Comp_Rep_BarChart.png\", dpi=300)\n",
    "                plt.close()\n",
    "            else:\n",
    "                pass\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Interior Compactor Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Drop Building NAs, convert datatype of BUILDING to integer \n",
    "2. Function for top 5 buildings that needed repairs in interior compactor locations within time frame:\n",
    "    1. Iterate through unique consolidation\n",
    "        1. Iterate through unique developments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# 1A. Select only data where the BUILDING column is not na\n",
    "int_comp_rep = int_comp_data[int_comp_data['BUILDING'].notna()]\n",
    "# 1B. Convert BUILDING column to integer, generates error but not an issue\n",
    "int_comp_rep.loc[:,'BUILDING'] = pd.to_numeric(int_comp_rep.BUILDING, downcast='signed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/textpath.py:90: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/textpath.py:203: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  glyph = font.load_char(ccode, flags=LOAD_NO_HINTING)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/textpath.py:90: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/textpath.py:203: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  glyph = font.load_char(ccode, flags=LOAD_NO_HINTING)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/textpath.py:90: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/textpath.py:203: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  glyph = font.load_char(ccode, flags=LOAD_NO_HINTING)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/textpath.py:90: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/textpath.py:203: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  glyph = font.load_char(ccode, flags=LOAD_NO_HINTING)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/textpath.py:90: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/textpath.py:203: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  glyph = font.load_char(ccode, flags=LOAD_NO_HINTING)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/textpath.py:90: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/textpath.py:203: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  glyph = font.load_char(ccode, flags=LOAD_NO_HINTING)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    }
   ],
   "source": [
    "top_5_rep_by_dev(int_comp_rep, \"Interior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Breukelen', 'Kingsborough', 'Marcy', 'Wyckoff Gardens', 'Monroe',\n",
       "       'Riis', 'Gowanus', 'Brevoort', 'Richmond Terrace', 'Marlboro',\n",
       "       'Douglass', 'Farragut', 'Claremont Consolidated', 'Cooper Park',\n",
       "       'Vladeck Combined', 'Lincoln', 'Hammel', \"Saint Mary's Park\",\n",
       "       'Frederick Samuel Apartments', 'Glenwood', 'Sotomayor', 'Linden',\n",
       "       'Rangel', 'Ingersoll', 'Saint Nicholas', 'Van Dyke I', 'Johnson',\n",
       "       'Penn-Wortman', 'Forest', 'Borinquen Plaza', 'Tompkins',\n",
       "       'Unity Plaza', 'Wagner', 'Drew Hamilton', 'Marble Hill', 'Howard',\n",
       "       'Straus', 'Taft', 'Sumner', 'Clinton', 'Edenwald', 'Baruch',\n",
       "       'Redfern', 'Morrisania Air Rights', 'South Jamaica',\n",
       "       'Reid Apartments', 'Castle Hill', 'Soundview', 'Red Hook East',\n",
       "       'Wise Towers', 'Queensbridge South', 'Williamsburg', 'Ravenswood',\n",
       "       'Kraus Management (BX 3)', 'Amsterdam', 'Pelham Parkway',\n",
       "       'Kraus Management (MB 1)', 'Wilson', 'Throggs Neck',\n",
       "       'Manhattanville', 'Fulton', 'South Beach', 'Chelsea', 'Jefferson',\n",
       "       'Morris', 'Pomonok', 'Beach 41st Street', 'Cypress Hills',\n",
       "       'Woodside', 'Eastchester Gardens', 'Dyckman', 'Whitman',\n",
       "       'Mill Brook', 'Brownsville', 'Baisley Park', 'Butler',\n",
       "       'Washington', 'Jackie Robinson', 'Polo Grounds Towers', 'Bushwick',\n",
       "       'Queensbridge North', 'Adams', 'Lafayette Gardens', 'Carver',\n",
       "       'Bay View', \"Mariner's Harbor\", 'Boulevard', 'Smith',\n",
       "       'Fort Washington Ave Rehab', 'Astoria', 'Boston Secor',\n",
       "       \"O'Dwyer Gardens\", 'Latimer Gardens', 'Wald', 'Sedgwick',\n",
       "       'Melrose', 'Bronx River', 'Isaacs', 'Ocean Hill', 'Marcus Garvey',\n",
       "       'Tilden', 'Grant', 'Sheepshead Bay', 'La Guardia',\n",
       "       'Lower East Side', '1010 EAST 178TH STREET', 'East River',\n",
       "       'Harlem River', 'Park Rock Consolidation', 'Gun Hill', 'Todt Hill',\n",
       "       'Red Hook West', 'Mitchel', 'Lehman Village',\n",
       "       'Union Avenue Consolidated', 'Highbridge Gardens',\n",
       "       'Surfside Gardens', 'Berry', 'Carey Gardens', 'Patterson',\n",
       "       'Gompers', 'Langston Hughes Apts', 'Taylor St - Wythe Ave',\n",
       "       'King Towers', 'Woodson', 'West Brighton', 'Sack Wern', 'Albany',\n",
       "       'Seth Low Houses', 'Mott Haven', 'Webster', 'Parkside', 'Rutgers',\n",
       "       'Roosevelt', 'Pink', 'Stapleton', 'Fort Independence',\n",
       "       'Building Management Associates (BX 1)', 'Stuyvesant Gardens'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_comp_rep['CONSOLIDATED_NAME'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Define function for table production of top 5 buildings that needed repairs in interior compactor locations within time frame\n",
    "\n",
    "def top_5_buildings_rep(df):\n",
    "    #iterate through consolidation\n",
    "    consol_list = df.CONSOLIDATED_NAME.unique().tolist()\n",
    "    \n",
    "    #For testing purposes...\n",
    "    #consol_list = ['Sumner', 'Harlem River']\n",
    "    \n",
    "    block_header = r'''\n",
    "                        \\begin{tabular}[t]{cc}\n",
    "                        \\multicolumn{2}{l}{%s}                                                                                                                                   \\\\ \\hline\n",
    "                        \\multicolumn{1}{|c|}{\\cellcolor{ccorange}{\\color[HTML]{FFFFFF} Building}} & \\multicolumn{1}{c|}{\\cellcolor{ccorange}{\\color[HTML]{FFFFFF} Total Repairs}} \\\\ \\hline\n",
    "                        '''\n",
    "\n",
    "    bldg_line = r'\\multicolumn{1}{|c|}{%s}                                                        & \\multicolumn{1}{c|}{%s}                                                             \\\\ \\hline'+'\\n'\n",
    "    \n",
    "    for consol_name in consol_list:\n",
    "        \n",
    "        consol_rep_df = df[df.CONSOLIDATED_NAME == consol_name]\n",
    "        consol_num = consol_rep_df.loc[:, \"CONSOLIDATED_TDS_NUM\"].iloc[0]\n",
    "        #iterate through each development within the consolidation\n",
    "        \n",
    "        consol_block = r'''\\begin{table}[H]\n",
    "        \\small\n",
    "        '''\n",
    "        \n",
    "        dev_blocks = []\n",
    "        \n",
    "        for dev_name in consol_rep_df.DEVELOPMENT_NAME.unique().tolist():\n",
    "            dev_rep_df = consol_rep_df[consol_rep_df.DEVELOPMENT_NAME == dev_name]\n",
    "            dev_num = dev_rep_df.loc[:, \"TDS_NUM\"].iloc[0]\n",
    "            build_rep_grp = dev_rep_df.groupby(['BUILDING']).TOTAL_REPAIRS_DONE.sum().reset_index()\n",
    "            build_rep_grp_t5 = build_rep_grp.nlargest(5, 'TOTAL_REPAIRS_DONE').reset_index(drop=True)\n",
    "            #rename columns for legibility\n",
    "            #build_rep_grp_t5 = build_rep_grp_t5.rename(columns={'BUILDING': 'Building Number', 'TOTAL_REPAIRS_DONE': 'Total Repairs Done'})\n",
    "            #FOR KYLE\n",
    "            \n",
    "            dev_block = r''''''\n",
    "            dev_block += block_header\n",
    "            dev_block += (bldg_line*build_rep_grp_t5.shape[0])\n",
    "            dev_block += r'\\end{tabular}'+'\\n'\n",
    "\n",
    "            \n",
    "            dev_block_data = []\n",
    "            dev_block_data.append(str(dev_name).replace('&','\\&'))\n",
    "            \n",
    "            for row in build_rep_grp_t5.itertuples():\n",
    "                dev_block_data.append(str(int(row.BUILDING)))\n",
    "                dev_block_data.append(str(int(row.TOTAL_REPAIRS_DONE)))\n",
    "            \n",
    "            dev_blocks.append(dev_block % tuple(dev_block_data))\n",
    "        \n",
    "        if len(dev_blocks)<=4:\n",
    "            inner_table = r'''\\begin{tabularx}{\\textwidth}{p{.1em}'''+('c'*len(dev_blocks))+r'''}\n",
    "               & %s'''+r'& %s'*(len(dev_blocks)-1)+'\\n'+r'\\end{tabularx}'\n",
    "            \n",
    "            inner_data = []\n",
    "            for block in dev_blocks:\n",
    "                #block = block.replace('$WIDTH$', str(1/(len(dev_blocks))))\n",
    "                inner_data.append(block)\n",
    "            \n",
    "            consol_block += inner_table % tuple(inner_data)\n",
    "                \n",
    "        elif len(dev_blocks)>4:\n",
    "            inner_table = r'\\begin{tabularx}{\\textwidth}{p{.1em}'+'c'*(math.ceil(len(dev_blocks)/2))+r'''}\n",
    "                                & %s''' + (r'& %s'*(math.ceil(len(dev_blocks)/2)-1)) + r'''\\\\\n",
    "                                & %s''' + (r'& %s'*(math.ceil(len(dev_blocks)/2)-1))+r''' \\\\\n",
    "                            \\end{tabularx}'''\n",
    "            \n",
    "            inner_data = []\n",
    "            for block in dev_blocks:\n",
    "                #block = block.replace('$WIDTH$', str(1/(math.ceil(len(dev_blocks)/2))))\n",
    "                inner_data.append(block)\n",
    "            \n",
    "            while len(inner_data) <(math.ceil(len(dev_blocks)/2)*2):\n",
    "                inner_data.append('')\n",
    "                \n",
    "            consol_block += inner_table % tuple(inner_data)\n",
    "        \n",
    "        \n",
    "        consol_block += r'\\end{table}'\n",
    "        \n",
    "        with open(f'Dev_Interior_Comp_Repair_Tables/{str(consol_num).zfill(3)}_repair_table.tex', 'w') as file_handle:\n",
    "            file_handle.write(consol_block)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_buildings_rep(int_comp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Exterior Compactor Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jubarton/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/jubarton/opt/anaconda3/lib/python3.7/site-packages/matplotlib/textpath.py:90: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=LOAD_NO_HINTING)\n",
      "/Users/jubarton/opt/anaconda3/lib/python3.7/site-packages/matplotlib/textpath.py:203: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  glyph = font.load_char(ccode, flags=LOAD_NO_HINTING)\n",
      "/Users/jubarton/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 9 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    }
   ],
   "source": [
    "top_5_rep_by_dev(ext_comp_data, \"Exterior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM AND FAILURE CODE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
