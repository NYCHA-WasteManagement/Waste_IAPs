{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaTeX Automation for NYCHA Waste Individual Action Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import docx2txt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Global Vars and Options\n",
    "os.chdir('/Users/kyleslugg/Documents/NYCHA/Production')\n",
    "cons_tds = '073'\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and Process Text Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO COME:\n",
    "- Waste Services and Assets\n",
    "- Waste Distribution (top text -- bottom accounted for below)\n",
    "- What Is an IAP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Character Substitutions for LaTeX -- set and define \"clean\" method\n",
    "def clean_text(text):\n",
    "    substitutions = {'“':\"``\",\n",
    "                '”': \"''\",\n",
    "                '’':\"'\",\n",
    "                ' ':' ',\n",
    "                '–':'--',\n",
    "                ' ':' ',\n",
    "                '\\xa0':' '}\n",
    "    \n",
    "    for key, value in substitutions.items():\n",
    "        text = text.replace(key, value)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_overview_text(cons_tds):\n",
    "    header = re.compile(r'((\\w*\\s)*(Overview)):?')\n",
    "    \n",
    "    overview_text = docx2txt.process(f'TEXT/{cons_tds}_Overview.docx')\n",
    "    try:\n",
    "        overview_text = overview_text.replace(header.findall(overview_text)[0]+'\\n','')\n",
    "    except:\n",
    "        overview_text = overview_text.replace(header.findall(overview_text)[0][0]+'\\n','')\n",
    "    overview_text = clean_text(overview_text)\n",
    "    \n",
    "    with open(f'TEXT/overview_text/{cons_tds}_overview.tex', 'w') as file_handle:\n",
    "        file_handle.write(overview_text)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_overview_text(cons_tds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_analysis_text(cons_tds):\n",
    "    analysis_text = docx2txt.process(f'TEXT/{cons_tds}_Analysis.docx')\n",
    "\n",
    "    header = re.compile(r'([\\w\\s]*:)')\n",
    "\n",
    "    section_headings = {'Inspection and Collection Requirement':['Inspection and Collection Requirement',\n",
    "                                                                'Inspection and Collection Requirements',\n",
    "                                                                'Collection and Inspection Requirement',\n",
    "                                                                'Collection and Inspection Requirements'],\n",
    "                        \n",
    "                        'Removal or Storage Requirement':['Removal or Storage Requirement',\n",
    "                                                          'Removal or Storage Requirements',\n",
    "                                                         'Removal and Storage Requirement',\n",
    "                                                         'Removal and Storage Requirements',\n",
    "                                                         'Storage or Removal Requirement',\n",
    "                                                         'Storage and Removal Requirement',\n",
    "                                                         'Storage and Removal Requirements']}\n",
    "    \n",
    "    for heading, variants in section_headings.items():\n",
    "        for variant in variants:\n",
    "            analysis_text = analysis_text.replace(variant, r'\\textbf{%s}' % heading)\n",
    "\n",
    "    analysis_text = analysis_text.replace(header.findall(analysis_text)[0]+'\\n','')\n",
    "\n",
    "    latex_block = clean_text(analysis_text)\n",
    "\n",
    "    with open(f'TEXT/analysis_text/{cons_tds}_analysis.tex', 'w') as file_handle:\n",
    "        file_handle.write(latex_block)\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_analysis_text(cons_tds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and Prepare Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set asset map path\n",
    "asset_map_path = f\"MAPS/asset_maps/{cons_tds}_asset_map.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split context map into two pages\n",
    "def process_context_map(cons_tds):\n",
    "    image = Image.open(f'MAPS/context_maps/{cons_tds}_context_map.png')\n",
    "    width, height = image.size\n",
    "\n",
    "    bb1 = (0,0,width/2,height)\n",
    "    bb2 = (width/2, 0, width, height)\n",
    "\n",
    "    img_1 = image.crop(bb1)\n",
    "    img_2 = image.crop(bb2)\n",
    "\n",
    "    img_1.save(f'MAPS/context_maps/{cons_tds}_context_1.png', format=\"PNG\")\n",
    "    img_2.save(f'MAPS/context_maps/{cons_tds}_context_2.png', format=\"PNG\")\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_context_map(cons_tds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO COME:\n",
    "- Waste Services and Assets\n",
    "- Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_overview_data():#Load Data\n",
    "    overview_data = pd.read_csv('DATA/overview_table_data.csv')\n",
    "    overview_data['CONS_TDS'] = overview_data['CONS_TDS'].apply(lambda x: str(x).zfill(3))\n",
    "    overview_data['TDS'] = overview_data['TDS'].apply(lambda x: str(x).zfill(3))\n",
    "    \n",
    "    return overview_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Overview Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_overview_table(cons_tds, overview_data=overview_data):\n",
    "    \n",
    "    cons_data = overview_data.loc[overview_data['CONS_TDS']== cons_tds]\n",
    "    \n",
    "    overview_table = ''\n",
    "\n",
    "    overview_frame = r'''\n",
    "    \\begin{tabular}{l|c|c|c|c|}\n",
    "    \\cline{2-5}\n",
    "                                                                           & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} TDS \\#} & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} Total Households} & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} Official Population} & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} Average Family Size} \\\\ \\hline\n",
    "\n",
    "    '''\n",
    "\n",
    "    development_template = r'''\\multicolumn{1}{|l|}{\\cellcolor{ccteallight}%s}        & %s                                                   & %s                                                           & %s                                                                & %s                                                                \\\\ \\hline'''\n",
    "\n",
    "\n",
    "    overview_table += overview_frame\n",
    "\n",
    "    for row in cons_data.itertuples():\n",
    "        dev_name = row.DEV_NAME.title()\n",
    "        dev_tds = row.TDS\n",
    "        total_hhs = row.TOTAL_HH\n",
    "        official_population = row.TOTAL_POP\n",
    "        avg_family_size = row.AVG_FAMILY_SIZE\n",
    "\n",
    "        overview_table += development_template % (dev_name, dev_tds, total_hhs, official_population, avg_family_size)\n",
    "\n",
    "    overview_table += r'''\n",
    "    \\end{tabular}\n",
    "    '''\n",
    "    \n",
    "    with open(f'TABLES/overview_table/{cons_tds}_overview_table.tex', 'w') as file_handle:\n",
    "        file_handle.write(overview_table)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Typology Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_typology_data():\n",
    "    #Cleaning and Shaping Data\n",
    "    typ_1 = pd.read_csv('DATA/typologies_1.csv')\n",
    "    typ_2 = pd.read_csv('DATA/typologies_2.csv')\n",
    "\n",
    "    typ_1.columns = ['CONS_NAME', 'DEV_NAME', 'TDS', 'TYPOLOGY']\n",
    "    typ_2.columns = ['CONS_NAME', 'CONS_TDS', 'DEV_NAME', 'TDS', 'METHOD', \n",
    "                     'CONSTRUCTION_DATE', 'BLDG_AGE', 'STORIES', 'BLDG_COVERAGE_SQFT', 'OPEN_SPACE_RATIO', 'SCATTERED_SITE_FLAG']\n",
    "\n",
    "    def make_dates(date_col):\n",
    "        date = str(date_col).split('/')\n",
    "        try:\n",
    "            if int(date[2]) > 18:\n",
    "                return datetime.date(int(f'19{date[2]}'), int(date[0]), int(date[1]))\n",
    "            else:\n",
    "                return datetime.date(int(f'20{date[2]}'), int(date[0]), int(date[1]))\n",
    "        except IndexError:\n",
    "            return datetime.date(1900,1,1)\n",
    "\n",
    "    typ_2['CONSTRUCTION_DATE'] = typ_2['CONSTRUCTION_DATE'].apply(lambda x: make_dates(x))\n",
    "    typ_2['SCATTERED_SITE_FLAG'] = typ_2['SCATTERED_SITE_FLAG'].apply(lambda x: x == 'YES')\n",
    "    typ_2.loc[typ_2['SCATTERED_SITE_FLAG']=='YES','SCATTERED_SITE_FLAG'] = 1\n",
    "\n",
    "    typology = typ_1.merge(typ_2[['CONS_TDS', 'TDS', 'METHOD',\n",
    "                                 'CONSTRUCTION_DATE', 'BLDG_AGE', \n",
    "                                 'STORIES', 'BLDG_COVERAGE_SQFT', \n",
    "                                 'OPEN_SPACE_RATIO', 'SCATTERED_SITE_FLAG']], how='left', on='TDS')\n",
    "\n",
    "    typology['CONS_TDS'] = typology['CONS_TDS'].apply(lambda x: str(int(x)).zfill(3))\n",
    "    typology['PREWAR'] = typology['CONSTRUCTION_DATE'].apply(lambda x: x < datetime.date(1945,1,1))\n",
    "\n",
    "    #Adding Typology Icons\n",
    "\n",
    "    typ_icons = [r'\\rootpath/IMAGES/typology_earlytower.png', r'\\rootpath/IMAGES/typology_towerpark.png', r'\\rootpath/IMAGES/typology_prewar.png', r'\\rootpath/IMAGES/typology_scatteredsite.png']\n",
    "    typ_dict = {}\n",
    "    [typ_dict.setdefault(key, '') for key in typology['TYPOLOGY'].unique().tolist()]\n",
    "\n",
    "    typ_dict['1 - High-rise in the park'] = typ_icons[1]\n",
    "    typ_dict['2 - Mid-rise in the park'] = typ_icons[1]\n",
    "    typ_dict['3 - Low-rise in the park'] = typ_icons[0]\n",
    "    typ_dict['4 - Context Towers'] = typ_icons[3]\n",
    "    typ_dict['5 - Context Mid-rises'] = typ_icons[2]\n",
    "    typ_dict['6 - Walkups & Brownstones'] = typ_icons[2]\n",
    "\n",
    "    typ_header = re.compile(r'\\d\\s-\\s')\n",
    "\n",
    "    typology['TYP_NAME'] = typology['TYPOLOGY'].apply(lambda x: typ_header.sub('', str(x)))\n",
    "    typology['IMAGE_PATH'] = typology['TYPOLOGY'].apply(lambda x: typ_dict[x])\n",
    "    \n",
    "    return typology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_typology_table_block(cons_tds, typ_data):\n",
    "    cons_data = typ_data[typ_data['CONS_TDS'] == cons_tds]\n",
    "    num_devs = cons_data.shape[0]\n",
    "    \n",
    "    if num_devs < 5:\n",
    "        block_1 = cons_data\n",
    "    \n",
    "    elif num_devs >=5 and num_devs < 7:\n",
    "        block_1 = cons_data.iloc[0:3]\n",
    "        block_2 = cons_data.iloc[3:]\n",
    "    \n",
    "    else:\n",
    "        block_1 = cons_data.iloc[0:4]\n",
    "        block_2 = cons_data.iloc[4:]\n",
    "    \n",
    "    len_1 = block_1.shape[0]\n",
    "    \n",
    "    try:\n",
    "        len_2 = block_2.shape[0]\n",
    "    except:\n",
    "        len_2 = 0\n",
    "    \n",
    "    headers = {1:r\"\\begin{tabular}{m{1.5in} m{2in}\"+'\\n',\n",
    "              2:r\"\\begin{tabular}{m{1.25in} m{2in} m{.1in} m{1.25in} m{2in}}\"+'\\n',\n",
    "              3:r\"\\begin{tabular}{m{1.25in} m{1.5in} m{.2in} m{1.25in} m{1.5in} m{.2in} m{1.25in} m{1.5in}}\"+'\\n',\n",
    "              4:r\"\\begin{tabular}{m{1.25in} m{1.25in} m{.2in} m{1.25in} m{1.25in} m{.2in} m{1.25in} m{1.25in} m{.2in} m{1.25in} m{1.25in}}\"+'\\n'}\n",
    "         \n",
    "    lines = {1:r'''\\textbf{%s:} {%s} & \\includegraphics[height=2in]{%s}'''+'\\n'+r'\\end{tabular}',\n",
    "            2:r'''\\textbf{%s:} {%s} & \\includegraphics[height=2in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=2in]{%s}'''+'\\n'+r'\\end{tabular}',\n",
    "            3:r'''\\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s}'''+'\\n'+r'\\end{tabular}',\n",
    "            4:r'''\\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s}& & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s}'''+'\\n'+r'\\end{tabular}'}\n",
    "    \n",
    "    \n",
    "    data_1 = []\n",
    "    data_2 = []\n",
    "    \n",
    "    for row in block_1.itertuples():\n",
    "        data_1.append(str(row.DEV_NAME).title())\n",
    "        data_1.append(str(row.TYP_NAME).replace('&', '\\&'))\n",
    "        data_1.append(row.IMAGE_PATH)\n",
    "    \n",
    "    if len_2 > 0:\n",
    "        for row in block_2.itertuples():\n",
    "            data_2.append(str(row.DEV_NAME.title()))\n",
    "            data_2.append(str(row.TYP_NAME).replace('&', '\\&'))\n",
    "            data_2.append(row.IMAGE_PATH)\n",
    "    \n",
    "    # Assembling Nested Tables\n",
    "    latex_block = ''\n",
    "    latex_block += r'''\\begin{table}[H]\n",
    "    \\resizebox{\\textwidth}{!}{\n",
    "    \\begin{tabular}{c}\n",
    "    '''\n",
    "    \n",
    "    latex_block += headers[len_1]\n",
    "    latex_block += lines[len_1] % tuple(data_1)\n",
    "    \n",
    "    if len_2 > 0:\n",
    "        latex_block += r'''\\\\\n",
    "        '''\n",
    "        latex_block += headers[len_2]\n",
    "        latex_block += lines[len_2] % tuple(data_2)\n",
    "    \n",
    "    latex_block += r'''\\end{tabular}}\n",
    "    \\end{table}'''\n",
    "    \n",
    "    with open(f'TABLES/typology_table/{cons_tds}_typology.tex', 'w') as file_handle:\n",
    "        file_handle.write(latex_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_typology_table_block('073', load_typology_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = []\n",
    "for tds in overview_data['CONS_TDS'].unique().tolist():\n",
    "    result = make_typology_table_block(tds, typology)\n",
    "    len_list.append(result)\n",
    "\n",
    "len_df = pd.DataFrame(data=len_list, columns=['CONS_TDS', 'NUM_DEVS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONS_TDS</th>\n",
       "      <th>NUM_DEVS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>091</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>359</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>530</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>167</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>127</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>351</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>308</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>003</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>342</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CONS_TDS  NUM_DEVS\n",
       "121      091        14\n",
       "100      359         8\n",
       "8        530         8\n",
       "34       167         8\n",
       "119      127         8\n",
       "50       351         7\n",
       "1        308         7\n",
       "94       003         6\n",
       "92       100         6\n",
       "11       342         6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_cons_tds = {'091':'Baisley Park. Isolate important developments.',\n",
    "                   '359':'Skip for now.'}\n",
    "len_df.sort_values('NUM_DEVS', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waste Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_waste_cols(overview_data=overview_data):\n",
    "    conversion_factors = {'units_to_tons_day': 0.0025,\n",
    "                         'cy_per_ton': {'trash': 21.05,\n",
    "                                        'trash_actual': 0,\n",
    "                                       'MGP': 18.02,\n",
    "                                       'cardboard': 26.67,\n",
    "                                       'paper': 6.19,\n",
    "                                       'organics': 4.32,\n",
    "                                       'ewaste': 5.65,\n",
    "                                       'textiles': 13.33},\n",
    "                         'gallons_per_cy': 201.974,\n",
    "                         'gallons_per_64gal': 64,\n",
    "                         'gallons_per_40lb_bag': 44,\n",
    "                         'cy_per_44gal_bag':0.174,\n",
    "                         'cy_per_cardboard_bale':0.193}\n",
    "\n",
    "    waste_percentages = {'trash': .26,\n",
    "                         'trash_actual':.894,\n",
    "                        'MGP': .19,\n",
    "                        'cardboard': .07,\n",
    "                        'paper': .07,\n",
    "                        'organics':.32,\n",
    "                        'ewaste': .01,\n",
    "                        'textiles': .08}\n",
    "\n",
    "    capture_rates = {'trash_primary': .75,\n",
    "                    'trash_secondary': .25,\n",
    "                    'mgp': .30,\n",
    "                    'cardboard': .50,\n",
    "                    'paper': .20}\n",
    "\n",
    "    overview_data['WASTE_TONS_DAY'] = overview_data['CURRENT_APTS'].apply(lambda x: x * conversion_factors['units_to_tons_day'])\n",
    "\n",
    "    for key, value in waste_percentages.items():\n",
    "        overview_data[f'{key.upper()}_CY'] = overview_data['WASTE_TONS_DAY'].apply(lambda x: x * value * conversion_factors['cy_per_ton'][key])\n",
    "        overview_data[f'{key.upper()}_TONS'] = overview_data['WASTE_TONS_DAY'].apply(lambda x: x * value)\n",
    "    \n",
    "    overview_data['TRASH_ACTUAL_CY'] = (overview_data['TRASH_CY']+\n",
    "                                           overview_data['MGP_CY']+\n",
    "                                           overview_data['CARDBOARD_CY']+\n",
    "                                           overview_data['PAPER_CY']+\n",
    "                                           overview_data['ORGANICS_CY']+\n",
    "                                           overview_data['EWASTE_CY']+\n",
    "                                           overview_data['TEXTILES_CY'])-(overview_data['MGP_CY']*capture_rates['mgp']+\n",
    "                                                                         overview_data['CARDBOARD_CY']*capture_rates['cardboard']+\n",
    "                                                                         overview_data['PAPER_CY']*capture_rates['paper'])\n",
    "\n",
    "    overview_data['TRASH_CHUTE_CY'] = overview_data['TRASH_ACTUAL_CY']*capture_rates['trash_primary']\n",
    "    overview_data['TRASH_CHUTE_TONS'] = overview_data['TRASH_ACTUAL_TONS']*capture_rates['trash_primary']\n",
    "    overview_data['TRASH_CHUTE_SAUSAGE'] = ((overview_data['TRASH_CHUTE_CY'])/conversion_factors['cy_per_ton']['trash'])*(2000/40)\n",
    "    overview_data['TRASH_DROP_CY'] = overview_data['TRASH_ACTUAL_CY']*capture_rates['trash_secondary']\n",
    "    overview_data['TRASH_DROP_TONS'] = overview_data['TRASH_ACTUAL_TONS']*capture_rates['trash_secondary']\n",
    "    overview_data['TRASH_DROP_BINS'] = overview_data['TRASH_DROP_CY']*conversion_factors['gallons_per_cy']/64\n",
    "    overview_data['CAPTURED_MGP_TONS_WEEK'] = overview_data['MGP_TONS']*capture_rates['mgp']*7\n",
    "    overview_data['CAPTURED_CARDBOARD_TONS_WEEK'] = overview_data['CARDBOARD_TONS']*capture_rates['cardboard']*7\n",
    "    overview_data['CAPTURED_PAPER_TONS_WEEK'] = overview_data['PAPER_TONS']*capture_rates['paper']*7\n",
    "    overview_data['MGP_BAGS_WEEK'] = overview_data['MGP_CY']*capture_rates['mgp']*7/conversion_factors['cy_per_44gal_bag']\n",
    "    overview_data['PAPER_BAGS_WEEK'] = overview_data['PAPER_CY']*capture_rates['paper']*7/conversion_factors['cy_per_44gal_bag']\n",
    "    overview_data['CARDBOARD_BALES_WEEK'] = overview_data['CARDBOARD_CY']*capture_rates['cardboard']*7/conversion_factors['cy_per_cardboard_bale']\n",
    "    \n",
    "    return overview_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_data = add_waste_cols(overview_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_waste_distribution_table(cons_tds, overview_data=overview_data):\n",
    "    cons_data = overview_data[overview_data['CONS_TDS'] == cons_tds]\n",
    "    num_devs = cons_data.shape[0]\n",
    "    \n",
    "    if num_devs > 1:\n",
    "        num_cols = num_devs+1\n",
    "    else:\n",
    "        num_cols = num_devs\n",
    "\n",
    "    dev_col_format = r'X|'\n",
    "\n",
    "    opening = r'''\n",
    "    \\begin{tabularx}{\\textwidth}{V{1.5in}|%s}\n",
    "    \\cline{2-%s}\n",
    "    ''' % (dev_col_format*num_cols, (num_cols+1))\n",
    "\n",
    "    top_row = r'''\n",
    "                                                                   '''+(r\"& \\multicolumn{1}{l|}{\\cellcolor{ccorange}%s}\"*(num_cols))+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    standard_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s}                 \"+(r\"& %s                                    \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    captured_row = r\"\\multicolumn{1}{|Y{1.5in}|}{\\cellcolor{ccorangelight}Captured / Week (tons)\\tnote{4}}                        \"+(r\"& %s                                    \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    chute_row = r\"\\multicolumn{1}{|Y{1.5in}|}{\\cellcolor{ccorangelight}Trash Chutes\\tnote{2}}                 \"+(r\"& %s tons or (%s) 40 lbs. sausage bags      \"*num_cols)+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    dropsite_row = r\"\\multicolumn{1}{|Y{1.5in}|}{\\cellcolor{ccorangelight}Drop Sites\\tnote{3}}                 \"+(r\"& %s tons or (%s) 64-gallon bins      \"*num_cols)+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    OET_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s / Day (CY)\\tnote{5}}              \"+(r\"& %s                                    \"*num_cols)+r\"\\tnhl\"+'\\n'\n",
    "    \n",
    "    recycling_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s}                 \"+(r\"& %s tons or (%s) 44-gallon bags                                   \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "    \n",
    "    cardboard_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s}                 \"+(r\"& %s tons or (%s) bales                                   \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "    \n",
    "    def make_waste_distribution_table_block(cons_data, num_cols):\n",
    "        if num_cols != 1:\n",
    "            cons_data.loc['Total']= cons_data.sum(numeric_only=True, axis=0)\n",
    "            cons_data.loc['Total','DEV_NAME'] = 'Total'\n",
    "\n",
    "        def make_trash_text(row, text_var, cy_col, other_col):\n",
    "            text_var.append(round(row[cy_col],2))\n",
    "            text_var.append(round(row[other_col], 2))\n",
    "            pass\n",
    "\n",
    "        latex_block = opening\n",
    "        latex_block += top_row % tuple(cons_data['DEV_NAME'].apply(lambda x: str(x).title()).tolist())\n",
    "        latex_block += standard_row % tuple([r\"Waste Generated / Day (Tons)\\tnote{1}\"]+[round(item, 2) for item in cons_data['WASTE_TONS_DAY'].tolist()])\n",
    "        latex_block += standard_row % tuple([r\"Trash / Day (tons)\\tnote{2}\"]+cons_data['TRASH_ACTUAL_TONS'].apply(lambda x: str(round(x,2))).tolist())\n",
    "\n",
    "        trash_chute_text = []\n",
    "        dropsite_text = []\n",
    "\n",
    "        cons_data.apply(lambda row: make_trash_text(row, trash_chute_text, 'TRASH_CHUTE_TONS', 'TRASH_CHUTE_SAUSAGE'), axis=1)\n",
    "        cons_data.apply(lambda row: make_trash_text(row, dropsite_text, 'TRASH_DROP_TONS', 'TRASH_DROP_BINS'), axis=1)\n",
    "\n",
    "        latex_block += chute_row % tuple(trash_chute_text)\n",
    "        latex_block += dropsite_row % tuple(dropsite_text)\n",
    "        \n",
    "        latex_block += r\"\\end{tabularx}\\bigskip\"\n",
    "        \n",
    "        latex_block += opening\n",
    "        latex_block += top_row % tuple(cons_data['DEV_NAME'].apply(lambda x: str(x).title()).tolist())\n",
    "        \n",
    "        mgp_text = []\n",
    "        cardboard_text= []\n",
    "        paper_text = []\n",
    "        \n",
    "        cons_data.apply(lambda row: make_trash_text(row, mgp_text, 'CAPTURED_MGP_TONS_WEEK', 'MGP_BAGS_WEEK'), axis=1)\n",
    "\n",
    "        cons_data.apply(lambda row: make_trash_text(row, cardboard_text, 'CAPTURED_CARDBOARD_TONS_WEEK', 'CARDBOARD_BALES_WEEK'), axis=1)\n",
    "\n",
    "        cons_data.apply(lambda row: make_trash_text(row, paper_text, 'CAPTURED_PAPER_TONS_WEEK', 'PAPER_BAGS_WEEK'), axis=1)\n",
    "\n",
    "\n",
    "        \n",
    "        latex_block += recycling_row % tuple([r\"Metal, Glass, Plastic Captured / Week (tons)\"]+mgp_text)\n",
    "        #latex_block += captured_row % tuple(cons_data['CAPTURED_MGP_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        latex_block += cardboard_row % tuple([r\"Cardboard Captured / Week (tons)\"]+cardboard_text)\n",
    "        #latex_block += captured_row % tuple(cons_data['CAPTURED_CARDBOARD_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        latex_block += recycling_row % tuple([r\"Paper Captured / Week (tons)\"]+paper_text)\n",
    "        #latex_block += captured_row % tuple(cons_data['CAPTURED_PAPER_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "\n",
    "        #latex_block += OET_row % tuple(['Organics']+cons_data['ORGANICS_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        #latex_block += OET_row % tuple(['E-Waste']+cons_data['EWASTE_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        #latex_block += OET_row % tuple(['Textiles']+cons_data['TEXTILES_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "\n",
    "        latex_block += r\"\\end{tabularx}\"\n",
    "\n",
    "        return latex_block\n",
    "    \n",
    "    \n",
    "    latex_block = make_waste_distribution_table_block(cons_data, num_cols)\n",
    "    \n",
    "    with open(f'TABLES/waste_distribution_table/{cons_tds}_wd_table.tex', 'w') as file_handle:\n",
    "        file_handle.write(latex_block)\n",
    "    \n",
    "    \n",
    "    text_block = r''''''\n",
    "    \n",
    "    text_line_multi = r\"\\bf{%s}: This development has %s apartment units and %s stairhalls.\\\\\"\n",
    "\n",
    "    text_line_singular = r\"\\bf{%s}: This development has %s apartment units and one stairhall.\\\\\"\n",
    "    \n",
    "    for row in cons_data.itertuples():\n",
    "    \n",
    "        if int(row.STAIRHALLS) == 1:\n",
    "            text_block += text_line_singular % (row.DEV_NAME.title(), int(row.CURRENT_APTS))\n",
    "        else:\n",
    "            text_block += text_line_multi % (row.DEV_NAME.title(), int(row.CURRENT_APTS), int(row.STAIRHALLS))\n",
    "\n",
    "    \n",
    "    with open(f'TEXT/waste_distribution_bottom/{cons_tds}_wd_bottom.tex', 'w') as file_handle:\n",
    "        file_handle.write(text_block)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "make_waste_distribution_table('073')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Capital Improvements Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_asset_data():\n",
    "    asset_data = {'fwd': ['In-Sink Food Grinders', pd.read_csv('DATA/capital_fwd.csv')],\n",
    "                  'ehd': ['Enlarged Hopper Doors', pd.read_csv('DATA/capital_ehd.csv')],\n",
    "                  'int_compactor':['Interior Compactor Replacement', pd.read_csv('DATA/capital_intcom.csv')],\n",
    "                  'wasteyard':['Waste Yard Redesign', pd.read_csv('DATA/capital_wasteyard.csv')]}\n",
    "\n",
    "    for value in asset_data.values():\n",
    "        value[1].columns = [item.strip() for item in value[1].columns]\n",
    "\n",
    "    asset_data['wasteyard'][1]['ESTIMATE'] = asset_data['wasteyard'][1]['TOT_EST']\n",
    "    asset_data['wasteyard'][1]['COST'] = np.nan\n",
    "    \n",
    "    return asset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_capital_table(cons_tds, asset_data, overview_data=overview_data):\n",
    "    cons_data = overview_data[overview_data['CONS_TDS'] == cons_tds]\n",
    "    num_devs = cons_data.shape[0]\n",
    "\n",
    "    dev_col_format = r'X|'\n",
    "    header = r'''\n",
    "    \\begin{tabularx}{\\textwidth}{r|%s}\n",
    "    \\cline{2-%s}\n",
    "    ''' % ((dev_col_format*num_devs), num_devs)\n",
    "\n",
    "    top_row = r\"\\multicolumn{1}{l|}{}                                                        \"+r\"& \\cellcolor{ccorange}{\\color[HTML]{FFFFFF}%s} \"*num_devs+r\"\\\\ \\hline\"+\"\\n\"\n",
    "\n",
    "    project_block = r\"\\multicolumn{1}{|V{.2\\columnwidth}|}{\\cellcolor{ccorangelight}%s}          \"+(r\"&                                                                  \"*num_devs)+r\"\\\\\"+r'''\n",
    "    \\multicolumn{1}{|r|}{\\cellcolor{ccorangelight}\\textit{Status}}                '''+(r\"& %s                                                         \"*num_devs)+r'''\\\\\n",
    "    \\multicolumn{1}{|r|}{\\cellcolor{ccorangelight}\\textit{%s}}                  '''+(\"& %s                                                     \"*num_devs)+r\"\\\\ \\hline\"+\"\\n\"\n",
    "    \n",
    "    def make_capital_table_block(cons_data):\n",
    "        devs = cons_data['DEV_NAME'].apply(lambda x: str(x).upper()).tolist()\n",
    "        devs_title = cons_data['DEV_NAME'].apply(lambda x: str(x).title()).tolist()\n",
    "        latex_block = ''\n",
    "        latex_block += header\n",
    "        latex_block += top_row % tuple(cons_data['DEV_NAME'].apply(lambda x: str(x).title()).tolist())\n",
    "\n",
    "        for asset in asset_data.keys():\n",
    "            asset_df = asset_data[asset][1]\n",
    "            #print(asset_data[asset][0])\n",
    "            #print(devs)\n",
    "            #print(asset_df['DEVELOPMENT'].tolist())\n",
    "            if any((dev in asset_df['DEVELOPMENT'].tolist()) for dev in devs):\n",
    "                status_list = []\n",
    "                cost_title = []\n",
    "                cost_list = []\n",
    "\n",
    "                for dev in devs:\n",
    "                    if dev in asset_df['DEVELOPMENT'].tolist():\n",
    "                        #print(dev)\n",
    "                        if pd.isna(asset_df.loc[asset_df['DEVELOPMENT']== dev,'STATUS'].iloc[0]):\n",
    "                            status_list.append('Estimate')\n",
    "                        else:\n",
    "                            status_list.append(str(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'STATUS'].iloc[0]).title())\n",
    "\n",
    "                        #print(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'STATUS'])\n",
    "                        #print(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'COST'])\n",
    "\n",
    "                        if (str(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'COST'].iloc[0]).strip() == '$-') or (pd.isna(asset_df.loc[asset_df['DEVELOPMENT'] == dev, 'COST'].iloc[0])):\n",
    "                            if (str(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'ESTIMATE'].iloc[0]).strip() == '$-' or pd.isna(asset_df.loc[asset_df['DEVELOPMENT']==dev, 'ESTIMATE'].iloc[0])):\n",
    "                                cost_list.append(' ')\n",
    "                            else:\n",
    "                                cost_list.append('\\\\'+str(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'ESTIMATE'].iloc[0])+r\" (est.)\")\n",
    "                        else:\n",
    "                            if (str(asset_df.loc[asset_df['DEVELOPMENT']==dev, 'COST'].iloc[0]).strip()== '$-' or pd.isna(asset_df.loc[asset_df['DEVELOPMENT']==dev, 'COST'].iloc[0])):\n",
    "                                cost_list.append(' ')                    \n",
    "                            else: \n",
    "                                cost_list.append('\\\\'+asset_df.loc[asset_df['DEVELOPMENT']==dev, 'COST'].iloc[0])\n",
    "\n",
    "                    else:\n",
    "                        status_list.append('N/A')\n",
    "                        cost_list.append(' ')\n",
    "\n",
    "                if all((item == ' ') for item in cost_list):\n",
    "                    cost_title.append(' ')\n",
    "                else:\n",
    "                    cost_title.append('Cost')\n",
    "\n",
    "                asset_block = project_block % tuple([asset_data[asset][0]]+status_list+cost_title+cost_list)\n",
    "\n",
    "                latex_block += asset_block\n",
    "\n",
    "        latex_block += r\"\\end{tabularx}\"\n",
    "\n",
    "        return latex_block\n",
    "    \n",
    "    capital_block = make_capital_table_block(cons_data)\n",
    "    \n",
    "    with open(f\"TABLES/capital_projects_table/{cons_tds}_capital_projects.tex\", 'w') as file_handle:\n",
    "        file_handle.write(make_capital_table_block(cons_data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_capital_table('073', load_asset_data(), load_overview_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Staff Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_staff_data():\n",
    "    # Read consolidation name data\n",
    "    cons_ids = pd.read_csv('DATA/CONS_NAME_TDS.csv')\n",
    "    cons_ids['CONS_TDS'] = cons_ids['CONS_TDS'].apply(lambda x: str(x).zfill(3))\n",
    "\n",
    "    #Read budgeted staff and formula allocation\n",
    "    dev_staff = pd.read_csv('DATA/staff_for_table.csv')\n",
    "    dev_staff.dropna(inplace=True)\n",
    "    dev_staff['Consolidation'] = dev_staff['Consolidation'].apply(lambda x: str(x).upper())\n",
    "    #Note: Staff list missing for Armstrong, Ft. Washington, and Williams Plaza, as well as scatter-site third-party-managed consolidations\n",
    "    dev_staff = dev_staff.merge(cons_ids, left_on='Consolidation', right_on='CONS_NAME', how='inner', indicator=False)\n",
    "\n",
    "    #Read budgeted staff and actuals\n",
    "    actuals_data = pd.read_csv('DATA/Staffing_Analysis/DEVHC.csv')\n",
    "    actuals_data.fillna(0, inplace=True)\n",
    "    actuals_data = actuals_data[actuals_data['RC Name'].apply(lambda x: \"total\" not in str(x).lower()) & actuals_data['Department'].apply(lambda x: \"total\" not in str(x).lower())]\n",
    "\n",
    "    def convert_neg(x):\n",
    "        try:\n",
    "            return int(x)\n",
    "        except:\n",
    "            return int('-'+str(x).replace('(','').replace(')',''))\n",
    "\n",
    "    actuals_data['VARIANCE'] = actuals_data['Unnamed: 5'].apply(lambda x: convert_neg(x))\n",
    "    actuals_data['ACT'] = actuals_data['13']\n",
    "    \n",
    "    table_frame = pd.read_csv('DATA/Table_Keys.csv')\n",
    "    actuals_keys = pd.read_csv('DATA/Staffing_Analysis/DEVHC_CODES.csv')\n",
    "    \n",
    "    actuals_data = actuals_data.merge(actuals_keys, how='left', left_on='CST_NAME', right_on='TITLE_NAME')\n",
    "    for column in ['Current Modified', 'ACT', 'VARIANCE']:\n",
    "        actuals_data[column] = actuals_data[column].astype(int)\n",
    "        \n",
    "\n",
    "    \n",
    "    return (cons_ids, dev_staff, actuals_data, table_frame, actuals_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_staff_table(cons_tds, cons_ids, dev_staff, actuals_data, table_frame, actuals_keys):\n",
    "    cons_id = cons_ids['CONS_NAME'].loc[cons_ids['CONS_TDS'] == cons_tds].iloc[0]\n",
    "    \n",
    "    #Fetching staff data for consolidation\n",
    "    cons_data = dev_staff.loc[dev_staff['Consolidation'] == cons_id]\n",
    "    \n",
    "    # Isolate and process actuals data for consolidation\n",
    "    try:\n",
    "        cons_actuals = actuals_data[actuals_data['RC Name'].apply(lambda x: str(x).lower() == cons_id.lower())]\n",
    "    except:\n",
    "        print(f'{cons_id} not found in actuals.')\n",
    "        return np.NaN\n",
    "    \n",
    "    cons_actuals = cons_actuals[['RC Name', 'Current Modified', 'ACT', \n",
    "                                 'CODE_KEY', 'CODE_NAME']].groupby(by='CODE_KEY', as_index=False).agg({'RC Name': 'first',\n",
    "                                                                                                     'Current Modified':sum,\n",
    "                                                                                                     'ACT':sum,\n",
    "                                                                                                     'CODE_NAME':'first'})\n",
    "    cons_actuals\n",
    "    cons_actuals.loc['Total']= cons_actuals.sum(numeric_only=True, axis=0)\n",
    "    cons_actuals.loc['Total','CODE_KEY'] = 11\n",
    "    cons_actuals.loc['Total','CODE_NAME'] = 'TOT'\n",
    "    \n",
    "    for row in cons_actuals.itertuples():\n",
    "        cons_data[f'{row.CODE_NAME}_ACT'] = row.ACT\n",
    "\n",
    "    #Setting up table and transposing data\n",
    "    cons_table_frame = table_frame\n",
    "    cons_table_frame['Formula'] = cons_table_frame['FORMULA_KEY'].iloc[:-1].apply(lambda key: cons_data[key].iloc[0])\n",
    "    cons_table_frame['Budgeted'] = cons_table_frame['BUDG_KEY'].apply(lambda key: cons_data[key].iloc[0])\n",
    "    cons_table_frame['Actual'] = cons_table_frame['ACTUALS_KEY'].iloc[:-2].apply(lambda key: cons_data[key].iloc[0])\n",
    "\n",
    "    \n",
    "    #Simplifying table\n",
    "    cons_table = cons_table_frame[['CHART_LINE', 'Formula', 'Budgeted', 'Actual']]\n",
    "    print(cons_table)\n",
    "    \n",
    "    #Defining LaTeX table format\n",
    "    \n",
    "    def make_staff_table_block(staff_data):\n",
    "    \n",
    "        table_template = r'''\n",
    "        \\begin{tabular}{l|c|c|c|}\n",
    "        \\cline{2-4}\n",
    "                                                                                     & \\cellcolor{ccfuschia}{\\color[HTML]{FFFFFF} Formula Allocation} & \\cellcolor{ccfuschia}{\\color[HTML]{FFFFFF} Budgeted} & \\cellcolor{ccfuschia}{\\color[HTML]{FFFFFF} Actual} \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Employees}                      & %s                                                      & %s                                                                & %s                                                        \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Property Manager}               & %s                                                      & %s                                                                & %s                                                       \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Asst. Property Manager}         & %s                                                      & %s                                                                & %s                                                       \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Secretaries}                    & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Housing Assistants}             & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Superintendent}                 & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Assistant Superintendent}       & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Supervisor of Caretakers (SOC)} & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Supervisor of Grounds (SOG)}    & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Maintenance Workers}            & %s                                                      & %s                                                                & %s                                                       \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Caretakers X}                   & %s                                                      & %s                                                                &                                                       \\\\ \\hline  \\cline{1-3}\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Caretakers J\\tnote{1}}                   &                                                       & %s                                                                &                                                         \\\\ \\cline{1-1} \\cline{3-3}\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Caretakers G}                   & \\multirow{-2}{*}{%s}                                                      & %s                                     & \\multirow{-3}{*}{%s}                           \\\\ \\hline\n",
    "        \\end{tabular}\n",
    "        \n",
    "        '''\n",
    "\n",
    "        values = []\n",
    "\n",
    "        def extract_data_through_mw(row):\n",
    "            [values.append(item) for item in [str(int(row['Formula'])), \n",
    "                                              str(int(row['Budgeted'])), \n",
    "                                              str(int(row['Actual']))]]\n",
    "            pass\n",
    "\n",
    "        #Processing through Maintenance Worker\n",
    "        staff_data.iloc[0:-3].apply(lambda row: extract_data_through_mw(row), axis=1)\n",
    "\n",
    "        #Processing Caretakers\n",
    "        values.append(str(int(staff_data.iloc[-3, 1])))\n",
    "        values.append(str(int(staff_data.iloc[-3, 2])))\n",
    "        values.append(str(int(staff_data.iloc[-2, 2])))\n",
    "        values.append(str(int(staff_data.iloc[-2, 1])))\n",
    "        values.append(str(int(staff_data.iloc[-1, 2])))\n",
    "        values.append(str(int(staff_data.iloc[-3, 3])))\n",
    "\n",
    "        return table_template % tuple(values)\n",
    "    \n",
    "    #Make and export LaTeX code\n",
    "    with open(f'TABLES/staff_table/{cons_tds}_staff_table.tex', 'w') as file_handle:\n",
    "        file_handle.write(make_staff_table_block(cons_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        CHART_LINE  Formula  Budgeted  Actual\n",
      "0                        Employees     45.0      46.0    41.0\n",
      "1                 Property Manager      1.0       1.0     1.0\n",
      "2           Asst. Property Manager      1.0       1.0     1.0\n",
      "3   Secretaries and Clerical Staff      2.0       2.0     2.0\n",
      "4               Housing Assistants      4.0       4.0     4.0\n",
      "5                   Superintendent      1.0       1.0     1.0\n",
      "6             Asst. Superintendent      2.0       2.0     2.0\n",
      "7   Supervisor of Caretakers (SOC)      1.0       1.0     1.0\n",
      "8      Supervisor of Grounds (SOG)      1.0       1.0     1.0\n",
      "9              Maintenance Workers      6.0       6.0     3.0\n",
      "10                    Caretakers X      5.0       5.0    25.0\n",
      "11                    Caretakers J     21.0      20.0     NaN\n",
      "12                    Caretakers G      NaN       2.0     NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "make_staff_table('073', *load_staff_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
