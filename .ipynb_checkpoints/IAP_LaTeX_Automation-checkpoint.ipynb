{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaTeX Automation for NYCHA Waste Individual Action Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import math\n",
    "import subprocess\n",
    "import shutil\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from pylatexenc.latexencode import unicode_to_latex\n",
    "from pylatexenc.latexencode import UnicodeToLatexEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Global Vars and Options\n",
    "os.chdir('/Users/kyleslugg/Documents/NYCHA/Production')\n",
    "cons_tds = '073'\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standardized_names():\n",
    "    databook_names = pd.read_csv('DATA/name_tables/dev_data_book_name.csv')\n",
    "    databook_names['CONS_TDS'] = databook_names['CONS_TDS'].apply(lambda x: str(int(x)).zfill(3))\n",
    "    databook_names['TDS'] = databook_names['TDS'].apply(lambda x: str(int(x)).zfill(3))\n",
    "\n",
    "    staff_names = pd.read_csv('DATA/name_tables/staff_cons_name.csv')\n",
    "    staff_names['RC_Name'] = staff_names['RC Name']\n",
    "    \n",
    "    consolidations = {}\n",
    "    developments = {}\n",
    "\n",
    "    for row in databook_names.itertuples():\n",
    "        consolidations[row.CONS_TDS] = {'name':row.CONS_NAME, 'alternates':[row.MANAGED_BY]}\n",
    "        developments[row.TDS] = {'name':row.DEV_NAME, 'name_alternates':[], 'cons_tds':row.CONS_TDS}\n",
    "        \n",
    "    def find_closest_fuzzy_match(name, comp_df, comp_col_name, return_col_name):\n",
    "        values = comp_df[comp_col_name].unique()\n",
    "        comp_df_copy = pd.DataFrame(data=values, index=[i for i in range(0,len(values))], columns=[comp_col_name])\n",
    "\n",
    "        '''\n",
    "        def strip_name(x):\n",
    "            string = str(x).lower()\n",
    "            string = string.replace('consolidated','')\n",
    "            string = string.replace('consolidation', '')\n",
    "            string = string.replace('houses', '')\n",
    "            return string\n",
    "\n",
    "        comp_df_copy['partial_ratio'] = comp_df_copy[comp_col_name].apply(lambda x: fuzz.partial_ratio(strip_name(name), strip_name(x)))\n",
    "        highest_match = comp_df_copy['partial_ratio'].max()\n",
    "\n",
    "        matches = comp_df_copy.loc[comp_df_copy['partial_ratio']==highest_match, 'CONS_NAME']\n",
    "\n",
    "        if matches.shape[0] == 1:\n",
    "            return matches.iloc[0]\n",
    "        else:\n",
    "            print(matches)\n",
    "            return 'ZZZ MULTIPLE MATCHES FOUND'\n",
    "\n",
    "        '''\n",
    "        return process.extractOne(str(name).lower(), values.tolist())[0]\n",
    "    \n",
    "    staff_names['NAME_MATCH'] = staff_names['RC Name'].apply(lambda x: find_closest_fuzzy_match(x, databook_names, 'CONS_NAME', 'CONS_NAME'))\n",
    "\n",
    "    match_corrections = {'Justice Sonia Sotomayor  Consolidated': 'SOTOMAYOR HOUSES CONSOLIDATED',\n",
    "                        'Murphy Consolidated': 'ZZZUNKNOWN'\n",
    "                        }\n",
    "\n",
    "    def make_corrections(row, index_col, data_col, dictionary):\n",
    "        if str(row[index_col]).strip() in dictionary.keys():\n",
    "            return dictionary[row[index_col]]\n",
    "        else:\n",
    "            return row[data_col]\n",
    "\n",
    "    staff_names['AMENDED_MATCHES'] = staff_names.apply(lambda row: make_corrections(row, 'RC Name', 'NAME_MATCH', match_corrections), axis=1)\n",
    "\n",
    "    staff_names = staff_names.merge(databook_names[['CONS_NAME', 'CONS_TDS']], left_on='AMENDED_MATCHES', right_on='CONS_NAME', how='left')\n",
    "\n",
    "    for row in staff_names.itertuples():\n",
    "        try:\n",
    "            consolidations[row.CONS_TDS]['alternates'].append(row.RC_Name)\n",
    "        except:\n",
    "            print(f'TDS #{row.CONS_TDS} raised an exception.')\n",
    "    \n",
    "    #From vehicle data...\n",
    "    consolidation_corrections = {'Brooklyn Borough Management':'N/A',\n",
    "                            'LaGuardia Houses':'LA GUARDIA CONSOLIDATED',\n",
    "                            'Hylan':'BUSHWICK CONSOLIDATED',\n",
    "                            'Manhattan Property Management':'N/A',\n",
    "                            'NYCHA - Brooklyn Property Mgmt':'N/A',\n",
    "                            'Queens-Staten Island Borough Manag':'N/A',\n",
    "                            'Webster-Morrisania Houses': 'WEBSTER CONSOLIDATED',\n",
    "                            'NGO':'N/A',\n",
    "                            'Millbrook Houses':'MILL BROOK CONSOLIDATED',\n",
    "                            'Van Dyke Houses':'VAN DYKE I',\n",
    "                            'UPACA':'JACKIE ROBINSON CONSOLIDATED',\n",
    "                            'Department of Mixed Finance Asset':'N/A',\n",
    "                            'Ocean Hill-Saratoga Village':'OCEAN HILL CONSOLIDATED',\n",
    "                            'nan':'N/A',\n",
    "                                'L.E.S. II/Campos':'LOWER EAST SIDE CONSOLIDATED',\n",
    "                                'St. Marys Park/Moore': \"SAINT MARY'S PARK CONSOLIDATED\",\n",
    "                                'Seth Low/Glenmore Plaza':'SETH LOW CONSOLIDATED',\n",
    "                                'Woodson/Van Dyke II':'WOODSON',\n",
    "                                'Beach 41st Street/Oceanside':'BEACH 41ST STREET-BEACH CHANNEL DRIVE'}\n",
    "    consolidations['NaN'] = {'name':'N/A',\n",
    "                            'alternates':[]}\n",
    "    for key, value in consolidation_corrections.items():\n",
    "        for key_c, value_c in consolidations.items():\n",
    "            if value_c['name'] == value: \n",
    "                try:\n",
    "                    consolidations[key_c]['alternates'].append(key)\n",
    "                except:\n",
    "                    consolidations[key_c]['alternates'] = key\n",
    "    \n",
    "    for key, value in consolidations.items():\n",
    "        for key_dev, value_dev in developments.items():\n",
    "            if key == value_dev['cons_tds']:\n",
    "                try:\n",
    "                    value['developments'].append(key_dev)\n",
    "                except:\n",
    "                    value['developments'] = [key_dev]\n",
    "    \n",
    "    return(consolidations, developments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDS #nan raised an exception.\n"
     ]
    }
   ],
   "source": [
    "consolidations, developments = get_standardized_names()\n",
    "\n",
    "counts ={}\n",
    "for key, value in developments.items():\n",
    "    if value['cons_tds'] not in counts.keys():\n",
    "        counts[value['cons_tds']] = {'developments':[key],\n",
    "                             'count':1}\n",
    "    else:\n",
    "        counts[value['cons_tds']]['developments'].append(key)\n",
    "        counts[value['cons_tds']]['count']+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['167', '359', '091', '530', '127']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_list = [value['count'] for key, value in counts.items()]\n",
    "high_count_cons = [key for key, value in counts.items() if value['count']>=8]\n",
    "high_count_cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_overview_data():#Load Data\n",
    "    overview_data = pd.read_csv('DATA/overview_table_data.csv')\n",
    "    overview_data['CONS_TDS'] = overview_data['CONS_TDS'].apply(lambda x: str(x).zfill(3))\n",
    "    overview_data['TDS'] = overview_data['TDS'].apply(lambda x: str(x).zfill(3))\n",
    "    \n",
    "    return overview_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_data = load_overview_data()\n",
    "cons_list = overview_data['CONS_TDS'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and Process Text Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lightly modified version of example found at http://etienned.github.io/posts/extract-text-from-word-docx-simply/\n",
    "\n",
    "try:\n",
    "    from xml.etree.cElementTree import XML\n",
    "except ImportError:\n",
    "    from xml.etree.ElementTree import XML\n",
    "import zipfile\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Module that extract text from MS XML Word document (.docx).\n",
    "(Inspired by python-docx <https://github.com/mikemaccana/python-docx>)\n",
    "\"\"\"\n",
    "\n",
    "WORD_NAMESPACE = '{http://schemas.openxmlformats.org/wordprocessingml/2006/main}'\n",
    "PARA = WORD_NAMESPACE + 'p'\n",
    "TEXT = WORD_NAMESPACE + 't'\n",
    "\n",
    "\n",
    "def get_docx_text(path):\n",
    "    \"\"\"\n",
    "    Take the path of a docx file as argument, return the text in unicode.\n",
    "    \"\"\"\n",
    "    document = zipfile.ZipFile(path)\n",
    "    try:\n",
    "        xml_content = document.read('word/document.xml')\n",
    "    except:\n",
    "        xml_content = document.read('word/document2.xml')\n",
    "        \n",
    "    document.close()\n",
    "    tree = XML(xml_content)\n",
    "\n",
    "    paragraphs = []\n",
    "    for paragraph in tree.getiterator(PARA):\n",
    "        texts = [node.text\n",
    "                 for node in paragraph.getiterator(TEXT)\n",
    "                 if node.text]\n",
    "        if texts:\n",
    "            paragraphs.append(''.join(texts))\n",
    "\n",
    "    return '\\n\\n'.join(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Character Substitutions for LaTeX -- set and define \"clean\" method\n",
    "def clean_text(text):\n",
    "    substitutions = {'“':\"``\",\n",
    "                '”': \"''\",\n",
    "                '’':\"'\",\n",
    "                ' ':' ',\n",
    "                '–':'--',\n",
    "                ' ':' ',\n",
    "                '\\xa0':' ',\n",
    "                '&':r'\\&'}\n",
    "    \n",
    "    for key, value in substitutions.items():\n",
    "        text = text.replace(key, value)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preface -- What is an IAP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preface_data():\n",
    "    staff_names = pd.read_excel('DATA/Dev_Staff_Names.xlsx')\n",
    "    candidate_list = []\n",
    "\n",
    "    for key, value in consolidations.items():\n",
    "        candidate_list.append(str(value['name']).upper())\n",
    "        for item in value['alternates']:\n",
    "            candidate_list.append(item.upper())\n",
    "\n",
    "    def get_cons_name(name):\n",
    "        match = process.extractOne(str(name).upper(), candidate_list)[0]\n",
    "        #print(match)\n",
    "        for key, value in consolidations.items():\n",
    "            if (match.upper() == value['name'].upper()) or (match.upper() in [val.upper() for val in value['alternates']]):\n",
    "                return value['name']\n",
    "\n",
    "        return '!!!NOT FOUND'\n",
    "\n",
    "    def get_tds_from_name(x):\n",
    "        for key, value in consolidations.items():\n",
    "            if str(value['name']).upper().strip() == x.upper().strip():\n",
    "                return key\n",
    "\n",
    "        return 'N/A'\n",
    "\n",
    "    staff_names['CONS_MATCH'] = staff_names['CONS'].apply(lambda x: get_cons_name(x))\n",
    "    staff_names['CONS_TDS'] = staff_names['CONS_MATCH'].apply(lambda x: get_tds_from_name(x))\n",
    "    \n",
    "    return staff_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preface_text(tds, preface_data):\n",
    "    cons_data = preface_data[preface_data['CONS_TDS'] == tds]\n",
    "    \n",
    "    latex_block = r'''\\chapter{Preface}\n",
    "\n",
    "    \\section{Letter from the Chair}\\label{sec:Section1}\n",
    "    \\clearpage\n",
    "    {\\fontfamily{phv}\\selectfont\n",
    "    \\section{What is an Individual Action Plan?}\n",
    "\n",
    "    The Individual Action Plans (IAPs) were born out of the collaboration between Capital Planning, Strategic Planning, Operations, and the Federal Monitor during the Fall of 2019. For years, NYCHA residents have faced waste-strewn campuses caused by insufficient staffing and equipment. The waste situation on our properties is not only an issue of poor sanitation and safety but also of human dignity -- everyone deserves a home they can feel proud of that is not covered with litter. It is also important to highlight that improperly handled waste is a leading non-point source pollutant contributing to the degradation of our waterways and harming the natural environment. We want the IAPs to be a stepping-stone towards project-based property management as no two consolidations are the same. \n",
    "\n",
    "    We have three main goals for the IAPs: \n",
    "    \\begin{enumerate}\n",
    "    \\item We hope that the IAPs will empower the consolidation staff who run developments to better coordinate and communicate with Central Office by having the proper resources. \n",
    "    \\item We want the IAPs to serve as an educational tool for all stakeholders to understand the complex system of waste management at consolidations. \n",
    "    \\item We aim to use these plans to understand and learn from the changing assets and flows at each consolidation to make life cleaner, safer, healthier, and happier for our NYCHA residents and employees. \n",
    "    \\end{enumerate}\n",
    "\n",
    "    The IAP is a living, breathing document that will be modified as information and data change. We strive to create the most transparent and accurate IAP as possible, but there is room for error, and we cannot guarantee that all information is correct at this point in the process. That is why this document will be updated every quarter, and in each iteration, the goal is to create a more robust IAP. The IAPs will be printed out and distributed to each consolidation via mail. They will be available for all staff at the Property Managers office. They will also be made available digitally. Please feel free to contact us if you think there has been a mistake or information needs updating, and we will act accordingly. \n",
    "\n",
    "\n",
    "    Please feel free to contact Jane Doe with any questions or concerns at: jane.doe@nycha.nyc.gov\n",
    "\n",
    "    Below is a list of %s Management Personnel as of August 2020:\n",
    "    \\begin{itemize}\n",
    "    \\item Operations VP: %s\n",
    "    \\item %s Borough Director: %s\n",
    "    \\item Regional Asset Manager: %s\n",
    "    \\item Property Manager: %s\n",
    "    \\item Superintendent: %s\n",
    "    \\end{itemize}\n",
    "    }'''\n",
    "    \n",
    "    #data = [cons name, ops vp, borough name, borough dir, RAM, PM, super]\n",
    "    preface_data = []\n",
    "    \n",
    "    preface_data.append(str(cons_data['CONS_MATCH'].iloc[0]).title())\n",
    "    \n",
    "    for col in ['OPS_VP', 'BORO', 'BORO_DIR', 'RAM', 'PM', 'PMS']:\n",
    "        preface_data.append(cons_data[col].iloc[0])\n",
    "    \n",
    "    with open(f'TEXT/preface_text/{tds}_preface.tex', 'w') as file_handle:\n",
    "        file_handle.write(clean_text(latex_block % tuple(preface_data)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359 raised an exception\n",
      "210 raised an exception\n",
      "530 raised an exception\n",
      "341 raised an exception\n",
      "128 raised an exception\n",
      "NaN raised an exception\n"
     ]
    }
   ],
   "source": [
    "preface_data = load_preface_data()\n",
    "for tds in consolidations.keys():\n",
    "    try:\n",
    "        make_preface_text(tds, preface_data)\n",
    "    except:\n",
    "        print(f'{tds} raised an exception')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_overview_text(cons_tds):\n",
    "    u = UnicodeToLatexEncoder(non_ascii_only = True, unknown_char_policy = (lambda x: ' '))\n",
    "    header = re.compile(r'((\\w*\\s)*(Overview))\\s*:?\\s*')\n",
    "    \n",
    "    overview_text = get_docx_text(f'TEXT/overview_text/{cons_tds}_Overview.docx')\n",
    "    overview_text = clean_text(overview_text)\n",
    "    \n",
    "    if len(header.findall(overview_text)) == 0:\n",
    "            overview_text = overview_text\n",
    "    else:\n",
    "        try:\n",
    "            overview_text = overview_text.replace(header.findall(overview_text)[0],'')\n",
    "        except:\n",
    "            overview_text = overview_text.replace(header.findall(overview_text)[0][0],'')\n",
    "    \n",
    "    with open(f'TEXT/overview_text/{cons_tds}_overview.tex', 'w') as file_handle:\n",
    "        file_handle.write(u.unicode_to_latex(overview_text))\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tds in consolidations.keys():\n",
    "    try:\n",
    "        make_overview_text(tds)\n",
    "    except FileNotFoundError:\n",
    "            pass\n",
    "    #except:\n",
    "     #   print(f\"{tds} raised error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_analysis_text(cons_tds):\n",
    "    analysis_text = get_docx_text(f'TEXT/analysis_text/{cons_tds}_Analysis.docx')\n",
    "\n",
    "    header = re.compile(r'([\\w\\s]*:)')\n",
    "    \n",
    "    analysis_text = clean_text(analysis_text)\n",
    "\n",
    "    section_headings = {'Inspection and Collection Requirement':['Inspection and Collection Requirements',\n",
    "                                                                 'Inspection and Collection Requirement',\n",
    "                                                                 'Collection and Inspection Requirements',\n",
    "                                                                'Collection and Inspection Requirement'],\n",
    "                        'Removal or Storage Requirement':['Removal or Storage Requirements',\n",
    "                                                          'Removal or Storage Requirement',\n",
    "                                                          'Removal and Storage Requirements',\n",
    "                                                         'Removal and Storage Requirement',\n",
    "                                                         'Storage or Removal Requirement',\n",
    "                                                          'Storage and Removal Requirements',\n",
    "                                                         'Storage and Removal Requirement',\n",
    "                                                         'Removal or Storage Requirement '],\n",
    "                       'Additional Context':['Additional Context']}\n",
    "    \n",
    "    for heading, variants in section_headings.items():\n",
    "        for variant in variants:\n",
    "            if variant in analysis_text:\n",
    "                analysis_text = analysis_text.replace(variant, r'\\textbf{%s}' % (heading))\n",
    "                break\n",
    "\n",
    "    if len(header.findall(analysis_text)) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        analysis_text = analysis_text.replace(header.findall(analysis_text)[0]+'\\n','')\n",
    "\n",
    "    latex_block = analysis_text\n",
    "\n",
    "    with open(f'TEXT/analysis_text/{cons_tds}_analysis.tex', 'w') as file_handle:\n",
    "        file_handle.write(latex_block)\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tds in consolidations.keys():\n",
    "    try:\n",
    "        make_analysis_text(tds)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    #except:\n",
    "     #   print(f\"{tds} raised error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and Prepare Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Set asset map path\n",
    "asset_map_path = f\"MAPS/asset_maps/{cons_tds}_asset_map.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Split context map into two pages\n",
    "def process_context_map(cons_tds):\n",
    "    image = Image.open(f'MAPS/context_maps/{cons_tds}_context_map.png')\n",
    "    width, height = image.size\n",
    "\n",
    "    bb1 = (0,0,width/2,height)\n",
    "    bb2 = (width/2, 0, width, height)\n",
    "\n",
    "    img_1 = image.crop(bb1)\n",
    "    img_2 = image.crop(bb2)\n",
    "\n",
    "    img_1.save(f'MAPS/context_maps/{cons_tds}_context_1.png', format=\"PNG\")\n",
    "    img_2.save(f'MAPS/context_maps/{cons_tds}_context_2.png', format=\"PNG\")\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for tds in consolidations.keys():\n",
    "    try:\n",
    "        process_context_map(tds)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO COME:\n",
    "- Consolidation Assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Overview Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_overview_table(cons_tds, overview_data=overview_data):\n",
    "    \n",
    "    cons_data = overview_data.loc[overview_data['CONS_TDS']== cons_tds]\n",
    "    \n",
    "    overview_table = ''\n",
    "\n",
    "    overview_frame = r'''\n",
    "    \\resizebox{\\textwidth}{!}{\n",
    "    \\begin{tabular}{l|c|c|c|c|}\n",
    "    \\cline{2-5}\n",
    "                                                                           & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} TDS \\#} & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} Total Households} & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} Official Population} & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} Average Family Size} \\\\ \\hline\n",
    "\n",
    "    '''\n",
    "\n",
    "    development_template = r'''\\multicolumn{1}{|l|}{\\cellcolor{ccteallight}%s}        & %s                                                   & %s                                                           & %s                                                                & %s                                                                \\\\ \\hline'''\n",
    "\n",
    "\n",
    "    overview_table += overview_frame\n",
    "\n",
    "    for row in cons_data.itertuples():\n",
    "        dev_name = clean_text(row.DEV_NAME.title())\n",
    "        dev_tds = row.TDS\n",
    "        total_hhs = row.TOTAL_HH\n",
    "        official_population = row.TOTAL_POP\n",
    "        avg_family_size = row.AVG_FAMILY_SIZE\n",
    "\n",
    "        overview_table += development_template % (dev_name, dev_tds, total_hhs, official_population, avg_family_size)\n",
    "\n",
    "    overview_table += r'''\n",
    "    \\end{tabular}\n",
    "    }\n",
    "    '''\n",
    "    \n",
    "    with open(f'TABLES/overview_table/{cons_tds}_overview_table.tex', 'w') as file_handle:\n",
    "        file_handle.write(overview_table)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for tds in consolidations.keys():\n",
    "    make_overview_table(tds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Typology Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_typology_data():\n",
    "    #Cleaning and Shaping Data\n",
    "    typ_1 = pd.read_csv('DATA/typologies_1.csv')\n",
    "    typ_2 = pd.read_csv('DATA/typologies_2.csv')\n",
    "\n",
    "    typ_1.columns = ['CONS_NAME', 'DEV_NAME', 'TDS', 'TYPOLOGY']\n",
    "    typ_2.columns = ['CONS_NAME', 'CONS_TDS', 'DEV_NAME', 'TDS', 'METHOD', \n",
    "                     'CONSTRUCTION_DATE', 'BLDG_AGE', 'STORIES', 'BLDG_COVERAGE_SQFT', 'OPEN_SPACE_RATIO', 'SCATTERED_SITE_FLAG']\n",
    "\n",
    "    def make_dates(date_col):\n",
    "        date = str(date_col).split('/')\n",
    "        try:\n",
    "            if int(date[2]) > 18:\n",
    "                return datetime.date(int(f'19{date[2]}'), int(date[0]), int(date[1]))\n",
    "            else:\n",
    "                return datetime.date(int(f'20{date[2]}'), int(date[0]), int(date[1]))\n",
    "        except IndexError:\n",
    "            return datetime.date(1900,1,1)\n",
    "\n",
    "    typ_2['CONSTRUCTION_DATE'] = typ_2['CONSTRUCTION_DATE'].apply(lambda x: make_dates(x))\n",
    "    typ_2['SCATTERED_SITE_FLAG'] = typ_2['SCATTERED_SITE_FLAG'].apply(lambda x: x == 'YES')\n",
    "    typ_2.loc[typ_2['SCATTERED_SITE_FLAG']=='YES','SCATTERED_SITE_FLAG'] = 1\n",
    "\n",
    "    typology = typ_1.merge(typ_2[['CONS_TDS', 'TDS', 'METHOD',\n",
    "                                 'CONSTRUCTION_DATE', 'BLDG_AGE', \n",
    "                                 'STORIES', 'BLDG_COVERAGE_SQFT', \n",
    "                                 'OPEN_SPACE_RATIO', 'SCATTERED_SITE_FLAG']], how='left', on='TDS')\n",
    "\n",
    "    typology['CONS_TDS'] = typology['CONS_TDS'].apply(lambda x: str(int(x)).zfill(3))\n",
    "    typology['PREWAR'] = typology['CONSTRUCTION_DATE'].apply(lambda x: x < datetime.date(1945,1,1))\n",
    "\n",
    "    #Adding Typology Icons\n",
    "\n",
    "    typ_icons = [r'\\rootpath/IMAGES/typology_earlytower.png', r'\\rootpath/IMAGES/typology_towerpark.png', r'\\rootpath/IMAGES/typology_prewar.png', r'\\rootpath/IMAGES/typology_scatteredsite.png']\n",
    "    typ_dict = {}\n",
    "    [typ_dict.setdefault(key, '') for key in typology['TYPOLOGY'].unique().tolist()]\n",
    "\n",
    "    typ_dict['1 - High-rise in the park'] = typ_icons[1]\n",
    "    typ_dict['2 - Mid-rise in the park'] = typ_icons[1]\n",
    "    typ_dict['3 - Low-rise in the park'] = typ_icons[0]\n",
    "    typ_dict['4 - Context Towers'] = typ_icons[3]\n",
    "    typ_dict['5 - Context Mid-rises'] = typ_icons[2]\n",
    "    typ_dict['6 - Walkups & Brownstones'] = typ_icons[2]\n",
    "\n",
    "    typ_header = re.compile(r'\\d\\s-\\s')\n",
    "\n",
    "    typology['TYP_NAME'] = typology['TYPOLOGY'].apply(lambda x: typ_header.sub('', str(x)))\n",
    "    typology['IMAGE_PATH'] = typology['TYPOLOGY'].apply(lambda x: typ_dict[x])\n",
    "    \n",
    "    return typology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "typology = load_typology_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_typology_table_block(cons_tds, typ_data):\n",
    "    cons_data = typ_data[typ_data['CONS_TDS'] == cons_tds]\n",
    "    num_devs = cons_data.shape[0]\n",
    "    \n",
    "    if num_devs < 5:\n",
    "        block_1 = cons_data\n",
    "    \n",
    "    elif num_devs >=5 and num_devs < 7:\n",
    "        block_1 = cons_data.iloc[0:3]\n",
    "        block_2 = cons_data.iloc[3:]\n",
    "    \n",
    "    else:\n",
    "        block_1 = cons_data.iloc[0:4]\n",
    "        block_2 = cons_data.iloc[4:]\n",
    "    \n",
    "    len_1 = block_1.shape[0]\n",
    "    \n",
    "    try:\n",
    "        len_2 = block_2.shape[0]\n",
    "    except:\n",
    "        len_2 = 0\n",
    "    \n",
    "    headers = {1:r\"\\begin{tabular}{m{1.5in} m{2in}}s\"+'\\n',\n",
    "              2:r\"\\begin{tabular}{m{1.25in} m{2in} m{.1in} m{1.25in} m{2in}}\"+'\\n',\n",
    "              3:r\"\\begin{tabular}{m{1.25in} m{1.5in} m{.2in} m{1.25in} m{1.5in} m{.2in} m{1.25in} m{1.5in}}\"+'\\n',\n",
    "              4:r\"\\begin{tabular}{m{1.25in} m{1.25in} m{.2in} m{1.25in} m{1.25in} m{.2in} m{1.25in} m{1.25in} m{.2in} m{1.25in} m{1.25in}}\"+'\\n'}\n",
    "         \n",
    "    lines = {1:r'''\\textbf{%s:} {%s} & \\includegraphics[height=2in]{%s}'''+'\\n'+r'\\end{tabular}',\n",
    "            2:r'''\\textbf{%s:} {%s} & \\includegraphics[height=2in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=2in]{%s}'''+'\\n'+r'\\end{tabular}',\n",
    "            3:r'''\\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s}'''+'\\n'+r'\\end{tabular}',\n",
    "            4:r'''\\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s}& & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s}'''+'\\n'+r'\\end{tabular}'}\n",
    "    \n",
    "    \n",
    "    data_1 = []\n",
    "    data_2 = []\n",
    "    \n",
    "    for row in block_1.itertuples():\n",
    "        data_1.append(clean_text(str(row.DEV_NAME).title()))\n",
    "        data_1.append(str(row.TYP_NAME).replace('&', '\\&'))\n",
    "        data_1.append(row.IMAGE_PATH)\n",
    "    \n",
    "    if len_2 > 0:\n",
    "        for row in block_2.itertuples():\n",
    "            data_2.append(clean_text(str(row.DEV_NAME.title())))\n",
    "            data_2.append(str(row.TYP_NAME).replace('&', '\\&'))\n",
    "            data_2.append(row.IMAGE_PATH)\n",
    "    \n",
    "    # Assembling Nested Tables\n",
    "    latex_block = ''\n",
    "    latex_block += r'''\\begin{table}[H]\n",
    "    \\resizebox{\\textwidth}{!}{\n",
    "    \\begin{tabular}{c}\n",
    "    '''\n",
    "    \n",
    "    latex_block += headers[len_1]\n",
    "    latex_block += lines[len_1] % tuple(data_1)\n",
    "    \n",
    "    if len_2 > 0:\n",
    "        latex_block += r'''\\\\\n",
    "        '''\n",
    "        latex_block += headers[len_2]\n",
    "        latex_block += lines[len_2] % tuple(data_2)\n",
    "    \n",
    "    latex_block += r'''\\end{tabular}}\n",
    "    \\end{table}'''\n",
    "    \n",
    "    with open(f'TABLES/typology_table/{cons_tds}_typology.tex', 'w') as file_handle:\n",
    "        file_handle.write(latex_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 raised an exception.\n",
      "091 raised an exception.\n",
      "128 raised an exception.\n",
      "NaN raised an exception.\n"
     ]
    }
   ],
   "source": [
    "typology = load_typology_data()\n",
    "\n",
    "for tds in consolidations.keys():\n",
    "    try:\n",
    "        make_typology_table_block(tds, typology)\n",
    "    except:\n",
    "        print(f'{tds} raised an exception.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "problem_cons_tds = {'091':'Baisley Park. Isolate important developments.',\n",
    "                   '359':'Skip for now.'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waste Services and Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wsa_data():\n",
    "    wsa_data = pd.read_csv('DATA/WASTE_SERVICES_ASSETS.csv')\n",
    "    wsa_data['TDS'] = wsa_data['DEV_TDS'].apply(lambda x: str(x).zfill(3))\n",
    "    wsa_data['INT_COMP_DATE'] = pd.to_datetime(wsa_data['INT_COMP_INSTALL_DATE'], errors='ignore')\n",
    "\n",
    "    return wsa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_waste_services_table(cons_tds, wsa_data, counts_dict=counts):\n",
    "    dev_list = counts_dict[cons_tds]['developments']\n",
    "    cons_data = wsa_data.query(f\"TDS in {dev_list}\")\n",
    "    num_devs = counts_dict[cons_tds]['count']\n",
    "    \n",
    "    def make_waste_services_block(num_cols, block_data):\n",
    "    \n",
    "        col_format = r'X|'\n",
    "        header = r'\\begin{tabularx}{\\textwidth}{V{1.5in}|'+col_format*(num_cols)+r'''}\n",
    "    \\cline{2-%s}\n",
    "                                                                                       '''% (num_cols)+r'& \\cellcolor{ccorange}{\\color[HTML]{FFFFFF} %s}'*num_cols+r' \\\\ \\hline'+'\\n'\n",
    "        hh_waste_line = r'\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}Household Waste (DSNY)}               '+r'& %s'*num_cols+r'\\\\ \\hline'+'\\n'\n",
    "        bulk_waste_line = r'\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}Bulk Waste}                  '+r'& %s'*num_cols+r' \\\\ \\hline'+'\\n'\n",
    "        norm_recycling_line = r'\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s}                   '+r'& DSNY Curb Setout'*num_cols + r'\\\\ \\hline'+'\\n'\n",
    "        special_recycling_line = r'\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s}                   '+r'& %s'*num_cols +r'\\\\ \\hline' + '\\n'\n",
    "        \n",
    "        latex_block = r''''''\n",
    "        latex_block += header % tuple(block_data['DEV_NAME'].apply(lambda x: clean_text(str(x).title())).tolist())\n",
    "        \n",
    "        \n",
    "        hh_waste_data = []\n",
    "        bulk_waste_data = []\n",
    "        ewaste_data = []\n",
    "        textiles_data = []\n",
    "        \n",
    "        for dev in block_data.itertuples():\n",
    "            if dev.CURBSIDE == 1:\n",
    "                hh_waste_data.append('Curbside Pickup')\n",
    "            elif dev.SHARE == 1:\n",
    "                hh_waste_data.append(f'Transfer to {clean_text(str(dev.SHARE_SITE).title())}')\n",
    "            else:\n",
    "                if (dev.EXT_COMP_BE == 1) and (dev.COMPACTOR_YARDS == 1):\n",
    "                    hh_waste_data.append(f'{int(dev.EXT_COMP_BE)} exterior compactor in {int(dev.COMPACTOR_YARDS)} waste yard')\n",
    "                elif (dev.COMPACTOR_YARDS == 1):\n",
    "                    hh_waste_data.append(f'{int(dev.EXT_COMP_BE)} exterior compactors in {int(dev.COMPACTOR_YARDS)} waste yard')\n",
    "                else:\n",
    "                    hh_waste_data.append(f'{int(dev.EXT_COMP_BE)} exterior compactors in {int(dev.COMPACTOR_YARDS)} waste yards')\n",
    "                \n",
    "            if pd.isna(dev.BULK_HAULER):\n",
    "                if int(dev.BULK_SITES) == 0:\n",
    "                    bulk_waste_data.append(\"Transferred for Pickup\")\n",
    "                elif int(dev.BULK_SITES) == 1:\n",
    "                    bulk_waste_data.append(\"One Bulk Drop Site; Transferred for Pickup\")\n",
    "                else:\n",
    "                    bulk_waste_data.append(f\"{dev.BULK_SITES} Bulk Drop Sites; Transferred for Pickup\")\n",
    "            else:\n",
    "                if int(dev.BULK_SITES) == 1:\n",
    "                    bulk_waste_data.append(f\"One Bulk Drop Site; Picked up by {dev.BULK_HAULER}\")\n",
    "                elif int(dev.BULK_SITES) > 1:\n",
    "                    bulk_waste_data.append(f\"{dev.BULK_SITES} Bulk Drop Sites; Picked up by {dev.BULK_HAULER}\")\n",
    "                else:\n",
    "                    bulk_waste_data.append(f\"Picked up by {dev.BULK_HAULER}\")\n",
    "            \n",
    "            if dev.ECYCLE == 1:\n",
    "                ewaste_data.append('Previously available through ECycle')\n",
    "            else:\n",
    "                ewaste_data.append('N/A')\n",
    "            \n",
    "            if dev.REFASHION == 1:\n",
    "                textiles_data.append('Previously available through Refashion')\n",
    "            else:\n",
    "                textiles_data.append('N/A')\n",
    "        \n",
    "        latex_block += hh_waste_line % tuple(hh_waste_data)\n",
    "        latex_block += bulk_waste_line % tuple(bulk_waste_data)\n",
    "        latex_block += norm_recycling_line % 'Recycling: Paper and Cardboard'\n",
    "        latex_block += norm_recycling_line % 'Recycling: Metal, Glass, and Plastic'\n",
    "        latex_block += special_recycling_line % tuple(['Recycling: Mattresses']+['N/A' for i in range(0, num_cols)])\n",
    "        latex_block += special_recycling_line % tuple(['Recycling: E-Waste']+ewaste_data)\n",
    "        latex_block += special_recycling_line % tuple(['Recycling: Textiles']+textiles_data)\n",
    "        latex_block += r'\\end{tabularx}'\n",
    "        \n",
    "        return latex_block\n",
    "    \n",
    "    if num_devs <= 4:\n",
    "        num_cols = num_devs\n",
    "        block_data = cons_data\n",
    "        \n",
    "        with open(f'TABLES/waste_services/{cons_tds}_waste_services.tex', 'w') as file_handle:\n",
    "            file_handle.write(make_waste_services_block(num_cols, block_data))\n",
    "        \n",
    "    elif num_devs > 4:\n",
    "        num_cols_1 = math.ceil(num_devs/2)\n",
    "        num_cols_2 = (num_devs-num_cols_1)\n",
    "        block_data_1 = cons_data.iloc[0:num_cols_1]\n",
    "        block_data_2 = cons_data.iloc[num_cols_1:]\n",
    "        \n",
    "        with open(f'TABLES/waste_services/{cons_tds}_waste_services_1.tex', 'w') as file_handle:\n",
    "            file_handle.write(make_waste_services_block(num_cols_1, block_data_1))\n",
    "            \n",
    "        with open(f'TABLES/waste_services/{cons_tds}_waste_services_2.tex', 'w') as file_handle:\n",
    "            file_handle.write(make_waste_services_block(num_cols_2, block_data_2))\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN raised exception\n"
     ]
    }
   ],
   "source": [
    "wsa_data = load_wsa_data()\n",
    "\n",
    "for tds in consolidations.keys():\n",
    "    try:\n",
    "        make_waste_services_table(tds, wsa_data)\n",
    "    except:\n",
    "        print(f'{tds} raised exception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_waste_assets_table(cons_tds, wsa_data, counts_dict=counts):\n",
    "    dev_list = counts_dict[cons_tds]['developments']\n",
    "    cons_data = wsa_data.query(f\"TDS in {dev_list}\")\n",
    "    num_devs = counts_dict[cons_tds]['count']\n",
    "    \n",
    "    header = r'''\n",
    "    \\begin{tabular}{V{.25\\columnwidth}|V{.15\\columnwidth}|V{.15\\columnwidth}|V{.25\\columnwidth}|V{.15\\columnwidth}|}\n",
    "\\cline{2-5}\n",
    "                                                                                              & \\cellcolor{ccorangelight}{\\color[HTML]{000000} Internal Compactors} & \\cellcolor{ccorangelight}{\\color[HTML]{000000} External Compactors} & \\cellcolor{ccorangelight}{\\color[HTML]{000000} Other External Assets}   & \\cellcolor{ccorangelight}{\\color[HTML]{000000} Recycling Bins\\tnote{1}} \\\\ \\hline'''+'\\n'\n",
    "    line_format = r'\\multicolumn{1}{|V{.25\\columnwidth}|}{\\cellcolor{ccorange}{\\color[HTML]{FFFFFF} %s}}        & %s                                                & %s                                                                  & %s & %s                                                            \\\\ \\hline'+'\\n'\n",
    "    \n",
    "    latex_block = r''''''\n",
    "    latex_block += header\n",
    "    \n",
    "    for dev in cons_data.itertuples():\n",
    "        line_data = []\n",
    "        line_data.append(clean_text(str(dev.DEV_NAME).title()))\n",
    "        \n",
    "        if (dev.INT_COMP == 0):\n",
    "            int_comp_string = '0'\n",
    "        elif pd.isna(dev.INT_COMP_DATE):\n",
    "            int_comp_string = str(int(dev.INT_COMP))\n",
    "        else:\n",
    "            int_comp_string = f'{str(int(dev.INT_COMP))}; last replaced {str(dev.INT_COMP_DATE.year)}'\n",
    "        \n",
    "        line_data.append(int_comp_string)\n",
    "        line_data.append(str(int(dev.EXT_COMP_BE)))\n",
    "        \n",
    "        #if (dev.BULK_CRUSHERS == 0) and (dev.BALERS == 0)... REDO THIS ONCE DATA ARE COMPLETE\n",
    "        line_data.append('PLACEHOLDER UNTIL DATA ARE COMPLETE')\n",
    "        line_data.append(str(int(dev.RECYCLING_BINS)))\n",
    "        \n",
    "        latex_block += line_format % tuple(line_data)\n",
    "    \n",
    "    latex_block += r'\\end{tabular}'\n",
    "    \n",
    "    with open(f'TABLES/waste_assets/{cons_tds}_waste_assets.tex', 'w') as file_handle:\n",
    "        file_handle.write(latex_block)    \n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN raised exception\n"
     ]
    }
   ],
   "source": [
    "wsa_data = load_wsa_data()\n",
    "for tds in consolidations.keys():\n",
    "    try:\n",
    "        make_waste_assets_table(tds, wsa_data)\n",
    "    except:\n",
    "        print(f'{tds} raised exception')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consolidation Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IN DEVELOPMENT\n",
    "\n",
    "def load_vehicle_data():\n",
    "    vehicle_data = pd.read_excel('DATA/vehicle_inventory.xlsx')\n",
    "    vehicle_data['CONS'] = vehicle_data['WORK LOCATION'].apply(lambda x: str(x).replace('NYCHA-',''))\n",
    "\n",
    "    candidate_list = []\n",
    "    for key, value in consolidations.items():\n",
    "        candidate_list.append(str(value['name']).upper())\n",
    "        for item in value['alternates']:\n",
    "            candidate_list.append(item.upper())\n",
    "\n",
    "    def get_cons_name(name):\n",
    "        match = process.extractOne(str(name).upper(), candidate_list)[0]\n",
    "        #print(match)\n",
    "        for key, value in consolidations.items():\n",
    "            if (match.upper() == value['name'].upper()) or (match.upper() in [val.upper() for val in value['alternates']]):\n",
    "                return value['name']\n",
    "\n",
    "        return '!!!NOT FOUND'\n",
    "\n",
    "\n",
    "    def get_tds_from_name(x):\n",
    "        for key, value in consolidations.items():\n",
    "            if str(value['name']).upper().strip() == x.upper().strip():\n",
    "                return key\n",
    "\n",
    "        return 'N/A'\n",
    "    \n",
    "    \n",
    "    def get_vehicle_type(x):\n",
    "        \n",
    "        if type(x) != str:\n",
    "            return 'N/A'\n",
    "        \n",
    "        van_keys = ['VAN', 'SPRINTER', 'ECONOLINE', 'TRANSIT']\n",
    "        truck_keys = ['PICK-UP', 'F250', 'F450', 'SIERRA', 'RANGER', 'Pick-Up']\n",
    "        for key in van_keys:\n",
    "            if key in x:\n",
    "                return 'VAN'\n",
    "\n",
    "        for key in truck_keys:\n",
    "            if key in x:\n",
    "                return 'TRUCK'\n",
    "\n",
    "        return 'OTHER'\n",
    "    \n",
    "    vehicle_data['CONS_MATCH'] = vehicle_data['CONS'].apply(lambda x: get_cons_name(str(x)))\n",
    "\n",
    "    vehicle_data['TDS'] = vehicle_data['CONS_MATCH'].apply(lambda x: get_tds_from_name(str(x)))\n",
    "    #vehicle_data['CONS_TDS'] = vehicle_data['TDS'].apply(lambda x: developments[x]['cons_tds'] if x in developments.keys() else np.NaN)\n",
    "    vehicle_data['TYPE'] = vehicle_data['DESCRIPTION'].apply(lambda x: get_vehicle_type(x))\n",
    "    \n",
    "    return vehicle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_consolidation_assets_table(cons_tds, vehicle_data):\n",
    "    cons_data = vehicle_data[vehicle_data['TDS'] == cons_tds]\n",
    "    block_template = r'''\\begin{tabular}{m{.33\\columnwidth}m{.33\\columnwidth}m{.33\\columnwidth}}\n",
    "    {\\color{ccorange} %s Trucks} & {\\color{ccorange} %s Vans} & {\\color{ccorange} %s Other Vehicles} \\\\\n",
    "    \\includegraphics[width=.25\\columnwidth]{\\rootpath/IMAGES/truck.png}                            & \\includegraphics[width=.25\\columnwidth]{\\rootpath/IMAGES/bobcat.png}                             & \\includegraphics[width=.25\\columnwidth]{\\rootpath/IMAGES/van.png}                          \n",
    "    \\end{tabular}'''\n",
    "    \n",
    "    num_trucks = cons_data[cons_data['TYPE'] == 'TRUCK'].shape[0]\n",
    "    num_vans = cons_data[cons_data['TYPE'] == 'VAN'].shape[0]\n",
    "    num_bobcats = 'TBD'\n",
    "    \n",
    "    \n",
    "    block_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_data = load_vehicle_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waste Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_waste_cols(overview_data):\n",
    "    conversion_factors = {'units_to_tons_day': 0.0025,\n",
    "                         'cy_per_ton': {'trash': 21.05,\n",
    "                                        'trash_actual': 0,\n",
    "                                       'MGP': 18.02,\n",
    "                                       'cardboard': 26.67,\n",
    "                                       'paper': 6.19,\n",
    "                                       'organics': 4.32,\n",
    "                                       'ewaste': 5.65,\n",
    "                                       'textiles': 13.33},\n",
    "                         'gallons_per_cy': 201.974,\n",
    "                         'gallons_per_64gal': 64,\n",
    "                         'gallons_per_40lb_bag': 44,\n",
    "                         'cy_per_44gal_bag':0.174,\n",
    "                         'cy_per_cardboard_bale':0.193}\n",
    "\n",
    "    waste_percentages = {'trash': .26,\n",
    "                         'trash_actual':.894,\n",
    "                        'MGP': .19,\n",
    "                        'cardboard': .07,\n",
    "                        'paper': .07,\n",
    "                        'organics':.32,\n",
    "                        'ewaste': .01,\n",
    "                        'textiles': .08}\n",
    "\n",
    "    capture_rates = {'trash_primary': .75,\n",
    "                    'trash_secondary': .25,\n",
    "                    'mgp': .30,\n",
    "                    'cardboard': .50,\n",
    "                    'paper': .20}\n",
    "\n",
    "    overview_data['WASTE_TONS_DAY'] = overview_data['CURRENT_APTS'].apply(lambda x: x * conversion_factors['units_to_tons_day'])\n",
    "\n",
    "    for key, value in waste_percentages.items():\n",
    "        overview_data[f'{key.upper()}_CY'] = overview_data['WASTE_TONS_DAY'].apply(lambda x: x * value * conversion_factors['cy_per_ton'][key])\n",
    "        overview_data[f'{key.upper()}_TONS'] = overview_data['WASTE_TONS_DAY'].apply(lambda x: x * value)\n",
    "    \n",
    "    overview_data['TRASH_ACTUAL_CY'] = (overview_data['TRASH_CY']+\n",
    "                                           overview_data['MGP_CY']+\n",
    "                                           overview_data['CARDBOARD_CY']+\n",
    "                                           overview_data['PAPER_CY']+\n",
    "                                           overview_data['ORGANICS_CY']+\n",
    "                                           overview_data['EWASTE_CY']+\n",
    "                                           overview_data['TEXTILES_CY'])-(overview_data['MGP_CY']*capture_rates['mgp']+\n",
    "                                                                         overview_data['CARDBOARD_CY']*capture_rates['cardboard']+\n",
    "                                                                         overview_data['PAPER_CY']*capture_rates['paper'])\n",
    "\n",
    "    overview_data['TRASH_CHUTE_CY'] = overview_data['TRASH_ACTUAL_CY']*capture_rates['trash_primary']\n",
    "    overview_data['TRASH_CHUTE_TONS'] = overview_data['TRASH_ACTUAL_TONS']*capture_rates['trash_primary']\n",
    "    overview_data['TRASH_CHUTE_SAUSAGE'] = ((overview_data['TRASH_CHUTE_CY'])/conversion_factors['cy_per_ton']['trash'])*(2000/40)\n",
    "    overview_data['TRASH_DROP_CY'] = overview_data['TRASH_ACTUAL_CY']*capture_rates['trash_secondary']\n",
    "    overview_data['TRASH_DROP_TONS'] = overview_data['TRASH_ACTUAL_TONS']*capture_rates['trash_secondary']\n",
    "    overview_data['TRASH_DROP_BINS'] = overview_data['TRASH_DROP_CY']*conversion_factors['gallons_per_cy']/64\n",
    "    overview_data['CAPTURED_MGP_TONS_WEEK'] = overview_data['MGP_TONS']*capture_rates['mgp']*7\n",
    "    overview_data['CAPTURED_CARDBOARD_TONS_WEEK'] = overview_data['CARDBOARD_TONS']*capture_rates['cardboard']*7\n",
    "    overview_data['CAPTURED_PAPER_TONS_WEEK'] = overview_data['PAPER_TONS']*capture_rates['paper']*7\n",
    "    overview_data['MGP_BAGS_WEEK'] = overview_data['MGP_CY']*capture_rates['mgp']*7/conversion_factors['cy_per_44gal_bag']\n",
    "    overview_data['PAPER_BAGS_WEEK'] = overview_data['PAPER_CY']*capture_rates['paper']*7/conversion_factors['cy_per_44gal_bag']\n",
    "    overview_data['CARDBOARD_BALES_WEEK'] = overview_data['CARDBOARD_CY']*capture_rates['cardboard']*7/conversion_factors['cy_per_cardboard_bale']\n",
    "    \n",
    "    return overview_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_waste_distribution_table(cons_tds, overview_data):\n",
    "    cons_data = overview_data[overview_data['CONS_TDS'] == cons_tds]\n",
    "    num_devs = cons_data.shape[0]\n",
    "    \n",
    "    if num_devs == 1:\n",
    "        num_cols = num_devs\n",
    "    elif num_devs > 4:\n",
    "        num_cols_1 = math.ceil(num_devs/2)\n",
    "        num_cols_2 = (num_devs-num_cols_1)+1\n",
    "    else:\n",
    "        num_cols = num_devs+1\n",
    "    \n",
    "    if num_devs != 1:\n",
    "        cons_data.loc['Total']= cons_data.sum(numeric_only=True, axis=0)\n",
    "        cons_data.loc['Total','DEV_NAME'] = 'Total'\n",
    "    \n",
    "    def make_waste_distribution_table_block(cons_data, num_cols):\n",
    "        dev_col_format = r'X|'\n",
    "\n",
    "        opening = r'''\n",
    "        \\begin{tabularx}{\\textwidth}{V{1.5in}|%s}\n",
    "        \\cline{2-%s}\n",
    "        ''' % (dev_col_format*num_cols, (num_cols+1))\n",
    "\n",
    "        top_row = r'''\n",
    "                                                                       '''+(r\"& \\multicolumn{1}{V{1.5in}|}{\\cellcolor{ccorange}%s}\"*(num_cols))+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "        standard_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s}                 \"+(r\"& %s                                    \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "        captured_row = r\"\\multicolumn{1}{|Y{1.5in}|}{\\cellcolor{ccorangelight}Captured / Week (tons)\\tnote{4}}                        \"+(r\"& %s                                    \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "        chute_row = r\"\\multicolumn{1}{|Y{1.5in}|}{\\cellcolor{ccorangelight}Trash Chutes\\tnote{2}}                 \"+(r\"& %s tons or (%s) 40 lbs. sausage bags      \"*num_cols)+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "        dropsite_row = r\"\\multicolumn{1}{|Y{1.5in}|}{\\cellcolor{ccorangelight}Drop Sites\\tnote{3}}                 \"+(r\"& %s tons or (%s) 64-gallon bins      \"*num_cols)+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "        OET_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s / Day (CY)\\tnote{5}}              \"+(r\"& %s                                    \"*num_cols)+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "        recycling_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s}                 \"+(r\"& %s tons or (%s) 44-gallon bags                                   \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "        cardboard_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s}                 \"+(r\"& %s tons or (%s) bales                                   \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "\n",
    "        def make_trash_text(row, text_var, cy_col, other_col):\n",
    "            text_var.append(round(row[cy_col],2))\n",
    "            text_var.append(round(row[other_col], 2))\n",
    "            pass\n",
    "\n",
    "        latex_block = opening\n",
    "        latex_block += top_row % tuple(cons_data['DEV_NAME'].apply(lambda x: clean_text(str(x).title())).tolist())\n",
    "        latex_block += standard_row % tuple([r\"Waste Generated / Day (Tons)\\tnote{1}\"]+[round(item, 2) for item in cons_data['WASTE_TONS_DAY'].tolist()])\n",
    "        latex_block += standard_row % tuple([r\"Trash / Day (tons)\\tnote{2}\"]+cons_data['TRASH_ACTUAL_TONS'].apply(lambda x: str(round(x,2))).tolist())\n",
    "\n",
    "        trash_chute_text = []\n",
    "        dropsite_text = []\n",
    "\n",
    "        cons_data.apply(lambda row: make_trash_text(row, trash_chute_text, 'TRASH_CHUTE_TONS', 'TRASH_CHUTE_SAUSAGE'), axis=1)\n",
    "        cons_data.apply(lambda row: make_trash_text(row, dropsite_text, 'TRASH_DROP_TONS', 'TRASH_DROP_BINS'), axis=1)\n",
    "\n",
    "        latex_block += chute_row % tuple(trash_chute_text)\n",
    "        latex_block += dropsite_row % tuple(dropsite_text)\n",
    "\n",
    "        latex_block += r\"\\end{tabularx}\\bigskip\"\n",
    "\n",
    "        latex_block += opening\n",
    "        latex_block += top_row % tuple(cons_data['DEV_NAME'].apply(lambda x: clean_text(str(x).title())).tolist())\n",
    "\n",
    "        mgp_text = []\n",
    "        cardboard_text= []\n",
    "        paper_text = []\n",
    "\n",
    "        cons_data.apply(lambda row: make_trash_text(row, mgp_text, 'CAPTURED_MGP_TONS_WEEK', 'MGP_BAGS_WEEK'), axis=1)\n",
    "\n",
    "        cons_data.apply(lambda row: make_trash_text(row, cardboard_text, 'CAPTURED_CARDBOARD_TONS_WEEK', 'CARDBOARD_BALES_WEEK'), axis=1)\n",
    "\n",
    "        cons_data.apply(lambda row: make_trash_text(row, paper_text, 'CAPTURED_PAPER_TONS_WEEK', 'PAPER_BAGS_WEEK'), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        latex_block += recycling_row % tuple([r\"Metal, Glass, Plastic Captured / Week (tons)\"]+mgp_text)\n",
    "        #latex_block += captured_row % tuple(cons_data['CAPTURED_MGP_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        latex_block += cardboard_row % tuple([r\"Cardboard Captured / Week (tons)\"]+cardboard_text)\n",
    "        #latex_block += captured_row % tuple(cons_data['CAPTURED_CARDBOARD_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        latex_block += recycling_row % tuple([r\"Paper Captured / Week (tons)\"]+paper_text)\n",
    "        #latex_block += captured_row % tuple(cons_data['CAPTURED_PAPER_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "\n",
    "        #latex_block += OET_row % tuple(['Organics']+cons_data['ORGANICS_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        #latex_block += OET_row % tuple(['E-Waste']+cons_data['EWASTE_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        #latex_block += OET_row % tuple(['Textiles']+cons_data['TEXTILES_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "\n",
    "        latex_block += r\"\\end{tabularx}\"\n",
    "\n",
    "        return latex_block\n",
    "    \n",
    "    if num_devs<= 4:\n",
    "        latex_block = make_waste_distribution_table_block(cons_data, num_cols)\n",
    "\n",
    "        with open(f'TABLES/waste_distribution_table/{cons_tds}_wd_table.tex', 'w') as file_handle:\n",
    "            file_handle.write(latex_block)\n",
    "    \n",
    "    else:\n",
    "        latex_block_1 = make_waste_distribution_table_block(cons_data.iloc[0:num_cols_1], num_cols_1)\n",
    "        latex_block_2 = make_waste_distribution_table_block(cons_data.iloc[num_cols_1:], num_cols_2)\n",
    "        \n",
    "        with open(f'TABLES/waste_distribution_table/{cons_tds}_wd_table_1.tex', 'w') as file_handle:\n",
    "            file_handle.write(latex_block_1)\n",
    "        with open(f'TABLES/waste_distribution_table/{cons_tds}_wd_table_2.tex', 'w') as file_handle:\n",
    "            file_handle.write(latex_block_2)\n",
    "\n",
    "    text_block = r''''''\n",
    "\n",
    "    text_line_multi = r\"{%s}: This development has %s apartment units and %s stairhalls.\\\\\"\n",
    "\n",
    "    text_line_singular = r\"{%s}: This development has %s apartment units and one stairhall.\\\\\"\n",
    "\n",
    "    for row in cons_data.itertuples():\n",
    "\n",
    "        if int(row.STAIRHALLS) == 1:\n",
    "            text_block += text_line_singular % (clean_text(row.DEV_NAME.title()), int(row.CURRENT_APTS))\n",
    "        else:\n",
    "            text_block += text_line_multi % (clean_text(row.DEV_NAME.title()), int(row.CURRENT_APTS), int(row.STAIRHALLS))\n",
    "\n",
    "\n",
    "    with open(f'TEXT/waste_distribution_bottom/{cons_tds}_wd_bottom.tex', 'w') as file_handle:\n",
    "        file_handle.write(text_block)\n",
    "        \n",
    "    top_block_template = r'''\n",
    "    By understanding how much waste is generated at each consolidation, planners and managers\n",
    "    can better determine how well current assets and services serve current needs, and what additional \n",
    "    elements are necessary in order for each consolidation to operate as efficiently as possible. \n",
    "\n",
    "    %s has (%s) 30-CY external compactors, each with a footprint of 192 square feet. Given the rate at which waste is produced at NYCHA properties, these containers will fill\n",
    "    up in about (%s) days.'''\n",
    "    \n",
    "    wsa_data = load_wsa_data()\n",
    "    wsa_data = wsa_data.query(f\"TDS in {counts[cons_tds]['developments']}\")\n",
    "    extcomp_total = int(wsa_data['EXT_COMP_BE'].sum())\n",
    "    #print(cons_data['TRASH_ACTUAL_CY'])\n",
    "    #print(cons_data['TRASH_ACTUAL_CY'].sum())\n",
    "    days_to_fill = extcomp_total*(cons_data['TRASH_ACTUAL_CY'].sum())/(30)\n",
    "    \n",
    "    top_block_data = []\n",
    "    top_block_data.append(clean_text(str(consolidations[cons_tds]['name']).title()))\n",
    "    top_block_data.append(str(extcomp_total))\n",
    "    top_block_data.append(str(round(days_to_fill, 1)))\n",
    "    \n",
    "    with open(f'TEXT/waste_distribution_top/{cons_tds}_wd_top.tex', 'w') as file_handle:\n",
    "        file_handle.write(top_block_template % tuple(top_block_data))\n",
    "    \n",
    "    #print(top_block_data)\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception raised by 091\n",
      "Exception raised by NaN\n"
     ]
    }
   ],
   "source": [
    "overview_data = add_waste_cols(load_overview_data())\n",
    "for tds in consolidations.keys():\n",
    "    try:\n",
    "        make_waste_distribution_table(tds, overview_data)\n",
    "    except:\n",
    "        print(f'Exception raised by {tds}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Capital Improvements Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_asset_data():\n",
    "    asset_data = {'fwd': ['In-Sink Food Grinders', pd.read_csv('DATA/capital_fwd.csv')],\n",
    "                  'ehd': ['Enlarged Hopper Doors', pd.read_csv('DATA/capital_ehd.csv')],\n",
    "                  'int_compactor':['Interior Compactor Replacement', pd.read_csv('DATA/capital_intcom.csv')],\n",
    "                  'wasteyard':['Waste Yard Redesign', pd.read_csv('DATA/capital_wasteyard.csv')]}\n",
    "\n",
    "    for value in asset_data.values():\n",
    "        value[1].columns = [item.strip() for item in value[1].columns]\n",
    "\n",
    "    asset_data['wasteyard'][1]['ESTIMATE'] = asset_data['wasteyard'][1]['TOT_EST']\n",
    "    asset_data['wasteyard'][1]['COST'] = np.nan\n",
    "    \n",
    "    def year_to_string(year):\n",
    "        if pd.isna(year):\n",
    "            return 'N/A'\n",
    "        else:\n",
    "            if int(year) <= 2022:\n",
    "                return str(int(year))\n",
    "            elif (int(year) > 2022) & (int(year) <= 2025):\n",
    "                return '2023-2025'\n",
    "            elif (int(year)>2025) and (int(year)<=2030):\n",
    "                return '2026-2030'\n",
    "            else:\n",
    "                return 'After 2030'\n",
    "    \n",
    "    asset_data['fwd'][1]['_YEAR'] = asset_data['fwd'][1]['EST_YEAR'].apply(lambda x: year_to_string(x))\n",
    "    asset_data['ehd'][1]['_YEAR'] = asset_data['fwd'][1]['CYEAR'].apply(lambda x: year_to_string(x))\n",
    "    asset_data['int_compactor'][1]['_YEAR'] = asset_data['int_compactor'][1]['CYEAR'].apply(lambda x: year_to_string(x))\n",
    "    asset_data['wasteyard'][1]['_YEAR'] = asset_data['wasteyard'][1]['CONS_CYEAR'].apply(lambda x: year_to_string(x))\n",
    "    return asset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_capital_table(cons_tds, asset_data, overview_data=overview_data):\n",
    "    cons_data = overview_data[overview_data['CONS_TDS'] == cons_tds]\n",
    "    num_devs = cons_data.shape[0]\n",
    "\n",
    "    def make_capital_table_block(block_data, num_devs):\n",
    "        dev_col_format = r'X|'\n",
    "        header = r'''\n",
    "        \\begin{tabularx}{\\textwidth}{r|%s}\n",
    "        \\cline{2-%s}\n",
    "        ''' % ((dev_col_format*num_devs), num_devs)\n",
    "\n",
    "        top_row = r\"\\multicolumn{1}{l|}{}                                                        \"+r\"& \\cellcolor{ccorange}{\\color[HTML]{FFFFFF}%s} \"*num_devs+r\"\\\\ \\hline\"+\"\\n\"\n",
    "\n",
    "        project_block = r\"\\multicolumn{1}{|V{.2\\columnwidth}|}{\\cellcolor{ccorangelight}%s}          \"+(r\"&                                                                  \"*num_devs)+r\"\\\\\"+r'''\n",
    "        \\multicolumn{1}{|r|}{\\cellcolor{ccorangelight}\\textit{Status}}                '''+(r\"& %s                                                         \"*num_devs)+r'''\\\\\n",
    "        \\multicolumn{1}{|r|}{\\cellcolor{ccorangelight}\\textit{%s}}                  '''+(\"& %s                                                     \"*num_devs)+r\"\\\\ \\hline\"+\"\\n\"\n",
    "\n",
    "        devs = block_data['DEV_NAME'].apply(lambda x: str(x).upper()).tolist()\n",
    "        devs_title = block_data['DEV_NAME'].apply(lambda x: clean_text(str(x).title())).tolist()\n",
    "        latex_block = ''\n",
    "        latex_block += header\n",
    "        latex_block += top_row % tuple(block_data['DEV_NAME'].apply(lambda x: clean_text(str(x).title())).tolist())\n",
    "\n",
    "        for asset in asset_data.keys():\n",
    "            asset_df = asset_data[asset][1]\n",
    "            #print(asset_data[asset][0])\n",
    "            #print(devs)\n",
    "            #print(asset_df['DEVELOPMENT'].tolist())\n",
    "            if any((dev in asset_df['DEVELOPMENT'].tolist()) for dev in devs):\n",
    "                status_list = []\n",
    "                year_list = []\n",
    "\n",
    "                for dev in devs:\n",
    "                    if dev in asset_df['DEVELOPMENT'].tolist():\n",
    "                        #print(dev)\n",
    "                        if pd.isna(asset_df.loc[asset_df['DEVELOPMENT']== dev,'STATUS'].iloc[0]):\n",
    "                            status_list.append('Not Yet Scheduled')\n",
    "                        else:\n",
    "                            status_list.append(str(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'STATUS'].iloc[0]).title())\n",
    "\n",
    "                        #print(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'STATUS'])\n",
    "                        #print(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'COST'])\n",
    "                        #try:\n",
    "                        year_list.append(str(asset_df.loc[asset_df['DEVELOPMENT']== dev,'_YEAR'].iloc[0]))\n",
    "                    #except:\n",
    "                            #year_list.append('TBD')\n",
    "\n",
    "                    else:\n",
    "                        status_list.append('N/A')\n",
    "                        year_list.append(' ')\n",
    "\n",
    "                asset_block = project_block % tuple([asset_data[asset][0]]+status_list+['Year Planned']+year_list)\n",
    "\n",
    "                latex_block += asset_block\n",
    "\n",
    "        latex_block += r\"\\end{tabularx}\"\n",
    "\n",
    "        return latex_block\n",
    "    \n",
    "    \n",
    "    if num_devs <= 4:\n",
    "        num_cols = num_devs\n",
    "        block_data = cons_data\n",
    "        \n",
    "        with open(f\"TABLES/capital_projects_table/{cons_tds}_capital_projects.tex\", 'w') as file_handle:\n",
    "            file_handle.write(make_capital_table_block(block_data, num_cols))\n",
    "        \n",
    "    elif num_devs > 4:\n",
    "        num_cols_1 = math.ceil(num_devs/2)\n",
    "        num_cols_2 = (num_devs-num_cols_1)\n",
    "        block_data_1 = cons_data.iloc[0:num_cols_1]\n",
    "        block_data_2 = cons_data.iloc[num_cols_1:]\n",
    "        \n",
    "        with open(f\"TABLES/capital_projects_table/{cons_tds}_capital_projects_1.tex\", 'w') as file_handle:\n",
    "            file_handle.write(make_capital_table_block(block_data_1, num_cols_1))\n",
    "            \n",
    "        with open(f\"TABLES/capital_projects_table/{cons_tds}_capital_projects_2.tex\", 'w') as file_handle:\n",
    "            file_handle.write(make_capital_table_block(block_data_2, num_cols_2))\n",
    "    \n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_data= load_asset_data()\n",
    "overview_data = load_overview_data()\n",
    "for tds in consolidations.keys(): \n",
    "    make_capital_table(tds, asset_data, overview_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Staff Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_staff_data(name_dict):\n",
    "    #Read budgeted staff and formula allocation\n",
    "    dev_staff = pd.read_csv('DATA/staff_for_table.csv')\n",
    "    dev_staff.fillna(0,inplace=True)\n",
    "    \n",
    "    def find_cons_tds(name, name_dict):\n",
    "        for key, value in name_dict.items():\n",
    "            if (name == value['name']) | (name in value['alternates']):\n",
    "                return key\n",
    "            \n",
    "    dev_staff['CONS_TDS'] = dev_staff['Consolidation'].apply(lambda x: find_cons_tds(x, name_dict))\n",
    "    dev_staff['CONS_NAME'] = dev_staff['CONS_TDS'].apply(lambda x: name_dict[x]['name'] if x is not None else 'NO NAME FOUND')\n",
    "    #Note: Staff list missing for Armstrong, Ft. Washington, and Williams Plaza, as well as scatter-site third-party-managed consolidations\n",
    " \n",
    "    #Read budgeted staff and actuals\n",
    "    actuals_data = pd.read_csv('DATA/Staffing_Analysis/DEVHC.csv')\n",
    "    actuals_data.fillna(0, inplace=True)\n",
    "    actuals_data = actuals_data[actuals_data['RC Name'].apply(lambda x: \"total\" not in str(x).lower()) & actuals_data['Department'].apply(lambda x: \"total\" not in str(x).lower())]\n",
    "    actuals_data['CONS_TDS'] = actuals_data['RC Name'].apply(lambda x: find_cons_tds(x, name_dict))\n",
    "    actuals_data['CONS_NAME'] = actuals_data['CONS_TDS'].apply(lambda x: name_dict[x]['name'] if x is not None else 'NO NAME FOUND')\n",
    "\n",
    "    def convert_neg(x):\n",
    "        try:\n",
    "            return int(x)\n",
    "        except:\n",
    "            return int('-'+str(x).replace('(','').replace(')',''))\n",
    "\n",
    "    actuals_data['VARIANCE'] = actuals_data['Unnamed: 5'].apply(lambda x: convert_neg(x))\n",
    "    actuals_data['ACT'] = actuals_data['13']\n",
    "    \n",
    "    table_frame = pd.read_csv('DATA/Table_Keys.csv')\n",
    "    actuals_keys = pd.read_csv('DATA/Staffing_Analysis/DEVHC_CODES.csv')\n",
    "    \n",
    "    actuals_data = actuals_data.merge(actuals_keys, how='left', left_on='CST_NAME', right_on='TITLE_NAME')\n",
    "    for column in ['Current Modified', 'ACT', 'VARIANCE']:\n",
    "        actuals_data[column] = actuals_data[column].astype(int)\n",
    "        \n",
    "\n",
    "    \n",
    "    return (dev_staff, actuals_data, table_frame, actuals_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_staff_table(cons_tds, dev_staff, actuals_data, table_frame, actuals_keys):\n",
    "    #Fetching staff data for consolidation\n",
    "    cons_data = dev_staff.loc[dev_staff['CONS_TDS'] == cons_tds]\n",
    "    if cons_data.shape[0] == 0:\n",
    "        return(f'Consolidation {cons_tds} not found in staffing data.')\n",
    "    #print(cons_tds)\n",
    "    #print(dev_staff)\n",
    "    \n",
    "    # Isolate and process actuals data for consolidation\n",
    "    try:\n",
    "        cons_actuals = actuals_data[actuals_data['CONS_TDS'] == cons_tds]\n",
    "    except:\n",
    "        print(f'{cons_tds} not found in actuals.')\n",
    "        return np.NaN\n",
    "    \n",
    "    cons_actuals = cons_actuals[['CONS_NAME', 'CONS_TDS', 'Current Modified', 'ACT', \n",
    "                                 'CODE_KEY', 'CODE_NAME']].groupby(by='CODE_KEY', as_index=False).agg({'CONS_NAME': 'first',\n",
    "                                                                                                       'CONS_TDS': 'first',\n",
    "                                                                                                     'Current Modified':sum,\n",
    "                                                                                                     'ACT':sum,\n",
    "                                                                                                     'CODE_NAME':'first'})\n",
    "    cons_actuals\n",
    "    cons_actuals.loc['Total']= cons_actuals.sum(numeric_only=True, axis=0)\n",
    "    cons_actuals.loc['Total','CODE_KEY'] = 11\n",
    "    cons_actuals.loc['Total','CODE_NAME'] = 'TOT'\n",
    "    \n",
    "    for row in cons_actuals.itertuples():\n",
    "        cons_data[f'{row.CODE_NAME}_ACT'] = row.ACT\n",
    "    #print(cons_data)\n",
    "    #Setting up table and transposing data\n",
    "    cons_table_frame = table_frame\n",
    "    cons_table_frame['Formula'] = cons_table_frame['FORMULA_KEY'].iloc[:-1].apply(lambda key: cons_data[key].iloc[0])\n",
    "    cons_table_frame['Budgeted'] = cons_table_frame['BUDG_KEY'].apply(lambda key: cons_data[key].iloc[0])\n",
    "    cons_table_frame['Actual'] = cons_table_frame['ACTUALS_KEY'].iloc[:-2].apply(lambda key: cons_data[key].iloc[0] if key in cons_data.columns else 0)\n",
    "\n",
    "    \n",
    "    #Simplifying table\n",
    "    cons_table = cons_table_frame[['CHART_LINE', 'Formula', 'Budgeted', 'Actual']]\n",
    "    #print(cons_table)\n",
    "    \n",
    "    #Defining LaTeX table format\n",
    "    \n",
    "    def make_staff_table_block(staff_data):\n",
    "    \n",
    "        table_template = r'''\n",
    "        \\begin{tabular}{l|c|c|c|}\n",
    "        \\cline{2-4}\n",
    "                                                                                     & \\cellcolor{ccfuschia}{\\color[HTML]{FFFFFF} Formula Allocation} & \\cellcolor{ccfuschia}{\\color[HTML]{FFFFFF} Budgeted} & \\cellcolor{ccfuschia}{\\color[HTML]{FFFFFF} Actual} \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Employees}                      & %s                                                      & %s                                                                & %s                                                        \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Property Manager}               & %s                                                      & %s                                                                & %s                                                       \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Asst. Property Manager}         & %s                                                      & %s                                                                & %s                                                       \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Secretaries}                    & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Housing Assistants}             & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Superintendent}                 & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Assistant Superintendent}       & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Supervisor of Caretakers (SOC)} & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Supervisor of Grounds (SOG)}    & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Maintenance Workers}            & %s                                                      & %s                                                                & %s                                                       \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Caretakers X}                   & %s                                                      & %s                                                                &                                                       \\\\ \\cline{1-3}\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Caretakers J\\tnote{1}}                   &                                                       & %s                                                                &                                                         \\\\ \\cline{1-1} \\cline{3-3}\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Caretakers G}                   & \\multirow{-2}{*}{%s}                                                      & %s                                     & \\multirow{-3}{*}{%s}                           \\\\ \\hline\n",
    "        \\end{tabular}\n",
    "        \n",
    "        '''\n",
    "\n",
    "        values = []\n",
    "\n",
    "        def extract_data_through_mw(row):\n",
    "            [values.append(item) for item in [str(int(row['Formula'])), \n",
    "                                              str(int(row['Budgeted'])), \n",
    "                                              str(int(row['Actual']))]]\n",
    "            pass\n",
    "\n",
    "        #Processing through Maintenance Worker\n",
    "        staff_data.iloc[0:-3].apply(lambda row: extract_data_through_mw(row), axis=1)\n",
    "\n",
    "        #Processing Caretakers\n",
    "        values.append(str(int(staff_data.iloc[-3, 1])))\n",
    "        values.append(str(int(staff_data.iloc[-3, 2])))\n",
    "        values.append(str(int(staff_data.iloc[-2, 2])))\n",
    "        values.append(str(int(staff_data.iloc[-2, 1])))\n",
    "        values.append(str(int(staff_data.iloc[-1, 2])))\n",
    "        values.append(str(int(staff_data.iloc[-3, 3])))\n",
    "\n",
    "        return table_template % tuple(values)\n",
    "    \n",
    "    #Make and export LaTeX code\n",
    "    with open(f'TABLES/staff_table/{cons_tds}_staff_table.tex', 'w') as file_handle:\n",
    "        file_handle.write(make_staff_table_block(cons_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kyleslugg/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "staff_data = load_staff_data(consolidations)\n",
    "\n",
    "for tds in consolidations.keys():\n",
    "    make_staff_table(tds, *staff_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Analysis Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process File Names\n",
    "def process_analysis_graphic_paths():\n",
    "    \n",
    "    def clean_paths(path_list):\n",
    "        clean_path_list = []\n",
    "        for path in path_list:\n",
    "            if ' ' in path.split('/')[-1]:\n",
    "                os.rename(path, path.replace(' ','-'))\n",
    "                clean_path_list.append(path)\n",
    "            else:\n",
    "                clean_path_list.append(path)\n",
    "            \n",
    "        return clean_path_list\n",
    "            \n",
    "    cons_bar_charts_raw = list(glob.glob('WORK_ORDER_ANALYSIS/Consolidation_BarCharts/png/*'))\n",
    "    cons_bar_charts = clean_paths(cons_bar_charts_raw)\n",
    "    \n",
    "    tds_nums = [path.split('/')[-1].split('_')[0].zfill(3) for path in cons_bar_charts]\n",
    "\n",
    "    cons_chart_paths = {}\n",
    "    for pair in list(zip(tds_nums, cons_bar_charts)):\n",
    "        cons_chart_paths[pair[0]] = pair[1]\n",
    "    \n",
    "    dev_chart_paths = {}\n",
    "\n",
    "    dev_bar_charts_raw = glob.glob('WORK_ORDER_ANALYSIS/Development_BarCharts/png/*')\n",
    "    dev_bar_charts = clean_paths(dev_bar_charts_raw)\n",
    "    \n",
    "    dev_tds_nums = [path.split('/')[-1].split('_')[0].zfill(3) for path in dev_bar_charts]\n",
    "\n",
    "    for pair in list(zip(dev_tds_nums, dev_bar_charts)):\n",
    "        dev_chart_paths[pair[0]] = {'Development_BarCharts': pair[1]}\n",
    "\n",
    "    for directory in ['Dev_Interior_Comp_Repair_BarCharts', 'Dev_Exterior_Comp_Repair_BarCharts']:\n",
    "        paths_raw = glob.glob(f'WORK_ORDER_ANALYSIS/{directory}/png/*')\n",
    "        paths = clean_paths(paths_raw)\n",
    "        tds_nums = [path.split('/')[-1].split('_')[3].zfill(3) for path in paths]\n",
    "\n",
    "        for pair in list(zip(tds_nums, paths)):\n",
    "            try:\n",
    "                dev_chart_paths[pair[0]][directory] = pair[1]\n",
    "            except:\n",
    "                dev_chart_paths[pair[0]] = {directory: pair[1]}\n",
    "                \n",
    "    return (cons_chart_paths, dev_chart_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_layout(tds, cons_chart_paths, dev_chart_paths, cons_dict):\n",
    "    analysis_image_layout = r''''''\n",
    "    \n",
    "    cons_devs = cons_dict[tds]['developments']\n",
    "    \n",
    "    dev_bar_paths = []\n",
    "    dev_int_paths = []\n",
    "    dev_ext_paths = []\n",
    "    \n",
    "    for dev in cons_devs:\n",
    "        try:\n",
    "            dev_bar_paths.append(dev_chart_paths[dev]['Development_BarCharts'])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            dev_int_paths.append(dev_chart_paths[dev]['Dev_Interior_Comp_Repair_BarCharts'])\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            dev_ext_paths.append(dev_chart_paths[dev]['Dev_Exterior_Comp_Repair_BarCharts'])\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #Adding consolidation and development bar charts\n",
    "    bar_charts_heading = r'''\\begin{figure}[h]\n",
    "                                \\sf\n",
    "                                The following bar charts show how frequently various types of maintenance issue -- including compactor-related problems, pest problems, and plumbing issues -- occur in compactor locations consolidation-wide as well as at major developments.\n",
    "                                \\raggedright\n",
    "                                \\begin{subfigure}{\\textwidth}\n",
    "                                \\includegraphics{\\rootpath/'''+cons_chart_paths[tds]+r'''}\n",
    "                                \\end{subfigure}\n",
    "                                '''\n",
    "    \n",
    "    if len(dev_bar_paths) > 1:\n",
    "        analysis_image_layout += bar_charts_heading\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(dev_bar_paths):\n",
    "            if ((len(dev_bar_paths)-i)%2 == 0):\n",
    "                analysis_image_layout += r'''\n",
    "                                        \\begin{subfigure}{0.45\\textwidth}\n",
    "                                        \\includegraphics[width=\\textwidth]{\\rootpath/'''+dev_bar_paths[i]+r'''}\n",
    "                                        \\end{subfigure}\n",
    "                                        ~\n",
    "                                        \\begin{subfigure}{0.45\\textwidth}\n",
    "                                        \\includegraphics[width=\\textwidth]{\\rootpath/'''+dev_bar_paths[i+1]+r'''}\n",
    "                                        \\end{subfigure}\n",
    "                                        \n",
    "                                        '''\n",
    "            else:\n",
    "                analysis_image_layout += r'''\\begin{subfigure}{0.45\\textwidth}\n",
    "                                        \\includegraphics[width=\\textwidth]{\\rootpath/'''+dev_bar_paths[i]+r'''}\n",
    "                                        \\end{subfigure}\n",
    "                                        '''\n",
    "            \n",
    "            i += 2\n",
    "        analysis_image_layout += r'\\end{figure}'+'\\n'\n",
    "        \n",
    "    elif len(dev_bar_paths) == 1:\n",
    "        analysis_image_layout += bar_charts_heading\n",
    "        analysis_image_layout += r'''\\begin{subfigure}{\\textwidth}\n",
    "                                    \\includegraphics{\\rootpath/'''+dev_bar_paths[0]+r'''}\n",
    "                                    \\end{subfigure}\n",
    "                                    \\end{figure}'''\n",
    "    else:\n",
    "        analysis_image_layout += bar_charts_heading.replace(' as well as at major developments','').replace('bar charts show','bar chart shows')\n",
    "        analysis_image_layout += r'\\end{figure}'+'\\n'\n",
    "        \n",
    "    \n",
    "    #Adding interior compactor section, including tables\n",
    "    int_comp_heading = r'''\\begin{figure}[h]\n",
    "                                \\raggedright\n",
    "                                \\sf\n",
    "                                The following figures highlight repairs conducted in interior compactor locations at each major development, as well as within up to five buildings at each development.\\\\\n",
    "                                '''\n",
    "    if len(dev_int_paths) > 1:\n",
    "        analysis_image_layout += int_comp_heading\n",
    "        i = 0\n",
    "        while i < len(dev_int_paths):\n",
    "            if ((len(dev_int_paths)-i)%2 == 0):\n",
    "                analysis_image_layout += r'''\\begin{subfigure}{0.45\\textwidth}\n",
    "                                        \\includegraphics[width=\\textwidth]{\\rootpath/'''+dev_int_paths[i]+r'''}\n",
    "                                        \\end{subfigure}\n",
    "                                        ~\n",
    "                                        \\begin{subfigure}{0.45\\textwidth}\n",
    "                                        \\includegraphics[width=\\textwidth]{\\rootpath/'''+dev_int_paths[i+1]+r'''}\n",
    "                                        \\end{subfigure}\n",
    "                                        \n",
    "                                        '''\n",
    "            else:\n",
    "                analysis_image_layout += r'''\\begin{subfigure}{0.45\\textwidth}\n",
    "                                        \\includegraphics[width=\\textwidth]{\\rootpath/'''+dev_int_paths[i]+r'''}\n",
    "                                        \\end{subfigure}\n",
    "                                        '''\n",
    "            \n",
    "            i += 2\n",
    "        \n",
    "        analysis_image_layout += r'\\input{\\rootpath/WORK_ORDER_ANALYSIS/Dev_Interior_Comp_Repair_Tables/\\tds_repair_table}'+'\\n'\n",
    "        analysis_image_layout += r'\\end{figure}'+'\\n'\n",
    "        \n",
    "    elif len(dev_bar_paths) == 1:\n",
    "        analysis_image_layout += int_comp_heading\n",
    "        analysis_image_layout += r'''\\begin{subfigure}{\\textwidth}\n",
    "                                    \\includegraphics{\\rootpath/'''+dev_int_paths[0]+r'''}\n",
    "                                    \\end{subfigure}\n",
    "                                    \\input{\\rootpath/WORK_ORDER_ANALYSIS/Dev_Interior_Comp_Repair_Tables/\\tds_repair_table}\n",
    "                                    \\end{figure}'''\n",
    "    else:\n",
    "        analysis_image_layout += int_comp_heading.replace('at each major development, as well as within','in').replace('figures highlight','tables highlight')\n",
    "        analysis_image_layout += r'\\input{\\rootpath/WORK_ORDER_ANALYSIS/Dev_Interior_Comp_Repair_Tables/\\tds_repair_table}'+'\\n'\n",
    "        analysis_image_layout += r'\\end{figure}'+'\\n'\n",
    "    \n",
    "    #Adding exterior compactor charts\n",
    "    ext_comp_heading = r'''\\begin{figure}[h]\n",
    "                                \\sf\n",
    "                                \\raggedright\n",
    "                                The following charts examine repairs made at exterior compactor locations at major developments.\n",
    "                                \\sf\n",
    "                                '''\n",
    "    if len(dev_ext_paths) > 1:\n",
    "        analysis_image_layout += ext_comp_heading\n",
    "        i = 0\n",
    "        while i < len(dev_ext_paths):\n",
    "            if ((len(dev_ext_paths)-i)%2 == 0):\n",
    "                analysis_image_layout += r'''\\begin{subfigure}{0.45\\textwidth}\n",
    "                                        \\includegraphics[width=\\textwidth]{\\rootpath/'''+dev_ext_paths[i]+r'''}\n",
    "                                        \\end{subfigure}\n",
    "                                        ~\n",
    "                                        \\begin{subfigure}{0.45\\textwidth}\n",
    "                                        \\includegraphics[width=\\textwidth]{\\rootpath/'''+dev_ext_paths[i+1]+r'''}\n",
    "                                        \\end{subfigure}\n",
    "                                        \n",
    "                                        '''\n",
    "            else:\n",
    "                analysis_image_layout += r'''\\begin{subfigure}{0.45\\textwidth}\n",
    "                                        \\includegraphics[width=\\textwidth]{\\rootpath/'''+dev_ext_paths[i]+r'''}\n",
    "                                        \\end{subfigure}\n",
    "                                        '''\n",
    "            \n",
    "            i += 2\n",
    "        \n",
    "        analysis_image_layout += r'\\end{figure}'+'\\n'\n",
    "        \n",
    "    elif len(dev_bar_paths) == 1:\n",
    "        analysis_image_layout += ext_comp_heading.replace('charts examine', 'chart examines').replace(' at major developments','')\n",
    "        analysis_image_layout += r'''\\begin{subfigure}{\\textwidth}\n",
    "                                    \\includegraphics{\\rootpath/'''+dev_int_paths[0]+r'''}\n",
    "                                    \\end{subfigure}\n",
    "                                    \\end{figure}'''\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    with open(f'WORK_ORDER_ANALYSIS/image_layouts/{tds}_layout.tex', 'w') as file_handle:\n",
    "        file_handle.write(analysis_image_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 raised exception\n",
      "530 raised exception\n",
      "128 raised exception\n",
      "NaN raised exception\n"
     ]
    }
   ],
   "source": [
    "cons_chart_paths, dev_chart_paths = process_analysis_graphic_paths()\n",
    "for tds in consolidations.keys():\n",
    "    try:\n",
    "        make_image_layout(tds, cons_chart_paths, dev_chart_paths, consolidations)\n",
    "    except:\n",
    "        print(f'{tds} raised exception')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assembling Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Site Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPENDICES/Site Plans w.r.t Boroughs/Bronx/East 180th Street- Monteret Avenue/East 180th Street-Monterey Ave Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Forest/Forest Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Middletown Plaza/Middletown Plaza Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Morris I & II/Morris I and II Site Plan with Utilities_COLOR.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Morris I & II/Morris I and II Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Morris I & II/Cellar Plan Bldg 6.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Morris I & II/Morris II Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Morris I & II/Morris I and II Site Plan 2-36x24.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Morris I & II/Morris I and II Site Plan 2-Model.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Morris I & II/Cellar Plan Bldg 17.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Morris I & II/Morris I  Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Morris I & II/Morris I and II Site Plan with Utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Morris I & II/Morris II Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Morris I & II/Morris_Letter_SitePlan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Boston Sector/Site Plan Boston Secor.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Claremont Parkway- Frankin Avenue/Claremont Pkwy-Franklin Ave_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Claremont Parkway- Frankin Avenue/Claremont Parkway-Franklin Ave_Dev Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Webster/Webster Houses Site Plan utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Webster/Webster Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/ParkSide/Parkside Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Melrose/Drainage Original.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Melrose/Melrose Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Melrose/Stairs at 321 E 153-Lawyer.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Melrose/Utilities Original.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Melrose/Entrance at 321 E 153-Lawyer.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Teller Avenue- East 166 Street/Teller Ave_Planting site plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Eastchester Gardens/Eastchester Utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Eastchester Gardens/Eastchester Gardens Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/South Bronx Area Site 402/South Bronx Area Site 402_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/South Bronx Area Site 402/South Bronx Area Site 402_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Eagle Avenue- East 163rd Street/Eagle Avenue-East 163rd Street_Rental Drawing.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Eagle Avenue- East 163rd Street/Eagle Avenue-East 163rd Street_Dev Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Eagle Avenue- East 163rd Street/Eagle Avenue-East 163rd Street_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Castle Hill/Castle Hill Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Monroe/Site Plan Monroe Houses utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Monroe/Site Plan Monroe Houses.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Bronx River/Bronx River Sketch for SHPO 2 17 2016.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Bronx River/Bronx River Houses Site-Plan-no utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Bronx River/Bronx River Houses Site-Plan-03-24-2010.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Bronx River/Bronx River Possible Mini Soccer site.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/College Ave- East 165th Street/ECRMS Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/College Ave- East 165th Street/College Ave-East 165th Street.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Gun Hill/Gun Hill Site Plan 2017.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Gun Hill/Gun Hill Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Union Avenue- East 163 Street/Union Ave 163_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Stebbins Avenue- Hewitt Pl/Stebbins Hewitt_Detailed Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Stebbins Avenue- Hewitt Pl/Stebbins Hewitt_Detailed Site Plan noU.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Mitchel/Mitchel Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Mitchel/Mitchel Site Plan_Play Eq.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Patterson/Corner of143 and Morris Ave.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Patterson/Patterson Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Patterson/Patterson Dev Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Patterson/Patterson Site Plan Mural.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Patterson/Patterson Site Plan_Play Eq.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Patterson/Patterson-corner of 143rd and Morris.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Patterson/RFI # 7 NYCHA response 10 14 2014.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Patterson/JOC Proposal 1.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Bronx River Addition/Bronx River Addition Site Plan with Elevations.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Highbridge Gardens/Highbridge_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Edenwald/Edenwald Site Plan 2016.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Edenwald/Edenwald Site Plan 2016 utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Twins Parks East Site 9/Twin Parks East Site 9_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Twins Parks East Site 9/Twin Parks East Site 9_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Union Avenue- East 166 Street/Union Ave-166th St Dimension Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Union Avenue- East 166 Street/Union Ave-166th St  Materials Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Boston Road Plaza/Boston Road Plaza_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Boston Road Plaza/Site Plan Boston Road Plaza.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Adams/Adams Site Plan v2.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Soundview/Soundview Site Plan with utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Soundview/Soundview Survey Plan from Developer.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Soundview/Site Plan -D for D Developer and CC Play Areas.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Soundview/Site Plan -REDD and DEVELOPER.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Marble Hill/Marble Hill Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/1010 East 178 Street/1010 East 178th Street Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Morrisania Air Rights/Morrisania Air Rights Site Plan V2.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Morrisania Air Rights/Morrisania Air Rights Bulk Crusher in Parking Lot.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Morrisania Air Rights/Morrisania Air Rights Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Butler/Butler_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Butler/Butler Houses Site Plan 1.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Butler/Butler Houses Site Plan 2.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Randall-Balcom/Randall Balcom_Satellite Images.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Randall-Balcom/Randall Balcom_Planting Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Randall-Balcom/Randall-Balcom Dev Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Randall-Balcom/Randall Balcom_Site Plan.pdf',\n",
       " \"APPENDICES/Site Plans w.r.t Boroughs/Bronx/St Marys Park/St Mary's Site Plan.pdf\",\n",
       " \"APPENDICES/Site Plans w.r.t Boroughs/Bronx/St Marys Park/St Mary's Possible Mini Soccer Sites.pdf\",\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Boyton Avenue Rehab/Boynton Avenue Rehab e-mail 2013 Dec 23.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Boyton Avenue Rehab/Boynton Avenue Rehab e-mail 2017 Aug 04.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Boyton Avenue Rehab/Boynton Schematic 2003 option 2.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Boyton Avenue Rehab/Boynton Schematic 2003 option 1.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Mill Brook/Mill Brook Site Plan no utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Mill Brook/Mill Brook Parking Modifications REDD.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Mill Brook/Mill Brook Site Plan_Play Eq.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Mill Brook/Mill Brook Site Plan with Utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/1471 Watson Avenue/SITE PLAN 2 19 2020.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Clason Point Gardens/Clason Point Sketch for SHPO 2 11 2016.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Clason Point Gardens/Clason Point Key Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Clason Point Gardens/Clason Point Gardens Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Clason Point Gardens/schematic Steam Lines.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Moore/GameTime Play Equipment Moore Houses.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Moore/Moore Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Moore/Materials Plan GD9900055.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Moore/Parks Image with notations.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Moore/Elec, Plumbing Grading Site Plan 1999.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Pelham Parkway 1 & 2/Pelham Parkway Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Sack-Wern/Site Plan 2012.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Sack-Wern/Sack Wern Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Glebe Avenue- Westchester Avenue/Glebe Westchester Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Sedgwick/Sedgewick Houses_Materials Plan_2.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Sedgwick/Sedgewick Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/McKinley/McKinley Site.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Throggs Neck 1 & 2 & Add/Throggs Neck 1, 2 & Addition Dev Map.pdf',\n",
       " \"APPENDICES/Site Plans w.r.t Boroughs/Bronx/Throggs Neck 1 & 2 & Add/Throgg's Neck Site Plan.pdf\",\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Throggs Neck 1 & 2 & Add/Throggs Neck Houses Site Plan-36x24.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Throggs Neck 1 & 2 & Add/Site Plan Bldgs 24 to 29.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Mott Haven/Mott Haven Site Plan_Play Eq.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Mott Haven/Mott Haven Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Jackson/Jackson Site Plan bball.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Jackson/1 floor building 4.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Jackson/Jackson Site Plan utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Bronx/Jackson/Jackson Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Mariners Harbor/Mariners Harbor Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Stapleton/Stapleton Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Stapleton/Capital Funding for Stapleton Playground.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Stapleton/Stapleton Play Equipment Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Stapleton/Stapleton Site Plan Water Issue.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Cassidy-Lafayette/Cassidy Lafayette East Planting.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Cassidy-Lafayette/Cassidy Lafayette West Planting.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Cassidy-Lafayette/Cassidy-Lafayette Hs Site Plan-36x24.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Cassidy-Lafayette/Cassidy WEST.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Cassidy-Lafayette/Cassidy Lafayette Plant List.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Cassidy-Lafayette/Cassidy  EAST.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/New Lane Area/New Lane Apts Site Plan 190329-34X44.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/New Lane Area/New Lane Area.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Richmond Terrace/Richmond Terrace_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Richmond Terrace/Richmond Terrace_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Berry/Plumbing.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Berry/BerryHouses_Letter_SitePlan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Berry/Berry Site Plan-36x24.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/South Beach/Site Plan_South Beach.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/South Beach/Site Plan_South Beach_Proposed Greenhouse Area.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Todt Hill/Todt Hill_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Todt Hill/PEH-10_Todt Hill_UtilPlan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Todt Hill/Todt Hill_Site Plan CAD.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Staten Island/Todt Hill/Play Equipment 2001.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Holmes Towers/Holmes Day Care Area-Dimensions.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Holmes Towers/Holmes Towers sketch for SHPO.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Holmes Towers/Holmes Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Baruch/New Area Map Baruch Houses.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Baruch/Baruch Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Baruch/Key Plan of Baruch Houses.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Baruch/Repairs to Baruch Drive.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Harlem River/Harlem River Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Fulton/GD9800018 Site Plan North.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Fulton/Fulton Houses Site Plan EXISTING.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Fulton/GD9800018 Site Plan South.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Wald/Wald Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Manhattanville/Manhattanville  Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Chelsea/Chelsea Compactors Site Plans MAY  25 2010.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Chelsea/ChelseaElliot_Letter_SitePlan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Chelsea/Property.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Chelsea/Chelsea and Chelsea Addition_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Chelsea/L002-Chelsea Compactors Site Plans MAY 2010.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Chelsea/Chelsea-Elliott Houses Site Plan 36x24 (1).pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Chelsea/Chelsea Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Wilson/Wilson - Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Gompers/Gompers Houses Site Plan all.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Vladeck I/Van Dyke Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/45 Allen Street/45 Allen Street Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/45 Allen Street/57 Allen Street-Modified 1 7 2019.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Washington/WashingtonTotalSite.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Washington/Washington_Pink&Green.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Washington/Washington Sketch for SHPO 2 17 2016.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/335 East 111 Street/Materials Plan Sheet 2.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/La Guardia/La Guardia Site PlanV2.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/La Guardia/LaGuardia Site Plan West 1999.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/La Guardia/La Guardia proposed relocated compactors .pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Bracetti Gardens/Bracetti Plaza Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/WSUR (Site A) 120 W 94 Street/WSURsite.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/WSUR (Site A) 120 W 94 Street/WSUR A Site Planl.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Jefferson/Jefferson Site Plan_Union Set.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Jefferson/Jefferson Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Baruch Addition/Baruch Addition Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Seward Park Extension/Seward Park Extension Site Plans .pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Seward Park Extension/Broome Street Site undone.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Seward Park Extension/Essex Street Site DONE .pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Seward Park Extension/Essex Street Site 2 DONE.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Seward Park Extension/Broome Street Site 2 undone.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Meltzer Tower/Meltzer Tower Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Smith/GovSmith Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Smith/GovSmith Houses Site.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Smith/GovSmith Site Plan utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Smith/GovSmith_House Sewer & Yard Drainage_P-6.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Smith/GovSmith_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lexington/Lexington Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Wagner/Wagner Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Wagner/Wagner Site Plan utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Elliott/Chelsea-Elliott Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Elliott/Elliot Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Elliott/NYCHA Play Equipment Steam Line Replacement.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Elliott/Proposed GameTime replacement Elliot Steam Line.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/WSUR (Site C) 589 Amsterdam Avenue/WSUR C Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Taft/Taft SitePlan_w.Steam.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Straus/Strauss_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/East River/East River Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/East River/East River -site.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lower East Side Rehab (Group 5)/A100_Title.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lower East Side Rehab (Group 5)/LES Rehab Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/De Hostos Apartments/DeHostos Apartments Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Rangel/Rangel Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Isaacs/Isaacs Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Isaacs/Isaacs Holmes Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Isaacs/Isaacs Holmes Site Plan_utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lehman Village/Lehman Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lower East Side I Infill/LES Infill I SITE PLAN-36.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lower East Side I Infill/LES Infill Bldg 2,3,4 and 5 .pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lower East Side I Infill/LES_Infill_Letter_SitePlan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lower East Side I Infill/LES Infill I SITE PLAN-36x24.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lower East Side I Infill/LES Infill I SITE PLAN.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Robinson/Robinson_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lincoin/Lincoln Plumbing Drawing P-5.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lincoin/Lincoln Houses - Site Plan (trees).pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lincoin/Lincoln Houses - Site Plan_hatch.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lincoin/Lincoln Houses - Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Rutgers/GENERAL sITE.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Rutgers/Rutgers Hs Compactor Area Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Rutgers/Rutgers Dvlpment map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Rutgers/Rutgers Hs Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Rutgers/Location.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Corsi Houses/Corsi Houses.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Corsi Houses/Corsi Houses Site Plan Utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Corsi Houses/Corsi Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Drew-Hamilton/Drew Hamilton Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lower East Side II/Lower East Side II_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Lower East Side II/SD 2 Drainage and Utility Plan Bldgs 4 and 5.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/830 Amsterdam Avenue/830 Amsterdam sketch for Contractor INCOMPLETE.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/830 Amsterdam Avenue/830 Amsterdam Ave Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/830 Amsterdam Avenue/Existing Play Equipment 2015.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/830 Amsterdam Avenue/830 Amsterdam Sketch for SHPO 2 12 2016.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Bethune Gardens/Bethune Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Wise Towers/WISE TOWERS B-ball and Play Area.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Wise Towers/Wise Tower Site Plan-Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Wise Towers/WISE TOWERS Site Plan Layout Basketball (1).pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Wise Towers/WISE TOWERS Sketch for SHPO 2 12 2016.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Saint Nicholas/parking lot 2.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Saint Nicholas/parking lot 3.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Saint Nicholas/parking lot 1.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Saint Nicholas/St. Nicholas North and South Playground Lease - 2 Parcels.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Saint Nicholas/Saint Nicholas Houses_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Saint Nicholas/Saint Nicholas Site Plan trees.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/RIIS/Riis I_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/RIIS/Riis Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Metro North Plaza/Metro North Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/UPACA (Site 6)/UPACA (Site 5) & (Site 6)_Development Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/UPACA (Site 6)/UPACA SITE 6_site plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Douglass Addition/Douglass Addition Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Douglass Addition/Douglass Addition Key Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Polo Grounds Towers/Polo Grounds Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Polo Grounds Towers/Net Area Map 1962 Polo Grounds Towers.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Polo Grounds Towers/Polo Grounds Site Plan with Utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/131 Saint Nicholas Ave/Materials Plan Sheet 2.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/UPACA (Site 5)/UPACA (Site 5) & (Site 6)_Development Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/UPACA (Site 5)/UPACA SITE 5_site plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Douglass I & II/Douglass Houses_Site Plan utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Douglass I & II/Douglass Key Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Douglass I & II/Douglass Houses_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/WSUR (Site B) 74 W 92 Street/WSUR Site B.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/WSUR (Site B) 74 W 92 Street/WSUR B  Site Plan from Qweb.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Amsterdam/Amsterdam Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Amsterdam/Amsterdam Sketch for SHPO 2 12 2016.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Johnson/Johnson Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/White/Plumbing Site Plan P-1.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/White/White Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/White/White Houses Site Plan_Union Set.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/White/White_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Clinton/Clinton Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Samuel (City)/Typical 2nd thru 5th floor West 144th St.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Samuel (City)/Typical 2nd thru 5th floor West 144th St V2.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Robbins Plaza/Robbins Plaza Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Two Bridges URA (Site 7)/Two Bridges Landscape.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Two Bridges URA (Site 7)/Drawing 2BR L1 play area plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Two Bridges URA (Site 7)/Two Bridges Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Two Bridges URA (Site 7)/Two Bridges site plan 8.5 x 11.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Grant/GenGrantTotalSite Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Dyckman/Dyckman Site Plan 36x24.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Dyckman/Dyckman Site Plan-36x24.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Dyckman/Dyckman Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/344 East 28 Street/344_East_28 Street_site.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/344 East 28 Street/Tree Removal at 344 East 28th Street.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/344 East 28 Street/3 trees at 344 E 28th Street.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Carver/Carver Site Plans.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Carver/Carver Site Plan no sub-grade.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Carver/Carver Sketch for SHPO 2 17 2016.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Harborview Terrace/Harborview_Site Grading & Drainage Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Manhattan/Harborview Terrace/Harborview_Site Location Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Brown/Brown Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Roosevelt I & II/Site Plans Roosevelt I & II.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Park Rock Rehab/Park Rock Rehab_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Glenmore Plaza/Glenmore Plaza Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Howard Avenue- Park Place/Howard Avenue Park Place Site Plan Parcel C.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Howard Avenue- Park Place/Howard Avenue Park Place Site Plan Parcel A+B.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Tilden/Tilden Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Breukelen/Breukelen Site Plan.pdf',\n",
       " \"APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/O'Dwyer Gardens/O'Dwyer Site Plan 8 2011.pdf\",\n",
       " \"APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/O'Dwyer Gardens/O'Dwyer Site Plan 8 2010.pdf\",\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Gowanaus/Gowanus Houses Site Plan Utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Gowanaus/Gowanus Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Kingsborough/Kingsborough Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Kingsborough/GKNC15-02 Ph 1_NYCHA_Geotech Data Report-Issue_electronic (1).pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Kingsborough/Kingsborough Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Farragut/A2-BuildingLocationPlan_1948.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Farragut/General Site Plan Y-11A.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Farragut/Farragut Net Area Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Farragut/E-11_FarragutElectrical.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Farragut/Farragut Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Farragut/A2-BuildingLocationPlan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Farragut/Farragut Houses Site Plan utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Marlboro/Marlboro Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Marlboro/Marlboro Site Plan utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Marlboro/1st floor plan A-202t.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Bay View/Bay View Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Pennsylvania Ave-Wortman Ave/PWA p1 plot.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Pennsylvania Ave-Wortman Ave/Site Plan Penn Wortman.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Wyckoff Gardens/Wyckoff Gardens Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Red Hook East & West/Red Hook East&West Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Red Hook East & West/Planting Plan portion of Red Hook.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Garvey (Group A)/Garvey Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Independence/Independence Towers Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Marcy/Marcy Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Marcy/Marcy possible Mini Soccer Sites.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Coney Island (Site 4 & 5)/Coney Island 4 and 5 Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Ocean Hill Apartments/Ocean Hill Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Ocean Hill Apartments/OceanHill_Letter_SitePlan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Surfside Gardens/Surfside south Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Surfside Gardens/Surfside north Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Berry Street- South 9th Street/BerrySt South9th SitePlan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Belmont-Sutter Area/BELMONT SUTTER SITE PLAN.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Van Dyke I/underground steam pipe spec.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Van Dyke I/Vandyke I Site Lighting 4-17-15.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Van Dyke I/Van Dyke Basketball Drains.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Van Dyke I/Van Dyke and Woodson Site Plans_COLOR.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Van Dyke I/Vandyke Site Lighting V2.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Van Dyke I/Van Dyke Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Van Dyke I/Van Dyke Review Drawings 6 29 2018.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Cypress Hills/Cypress Hills Site Plan with Exterior Compactor.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Cypress Hills/Cypress Hills Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Unity Plaza 4-27/Unity Plaza 4-27_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/572 Warren Street/blow up of play equipment.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/572 Warren Street/572 Warren Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/572 Warren Street/Materials Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/572 Warren Street/play area dimensions.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Atlantic Terminal Site 4B/Atlantic Terminal Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Atlantic Terminal Site 4B/AtlanticTerm_Letter_SitePlan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Atlantic Terminal Site 4B/SITE PLAN Atlantic Terminal.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Reid Apartments/Reid Apartments Site Plan-36x24.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Cooper Park/Cooper Park Community Center Exhibit A OMB.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Cooper Park/Cooper Park_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Cooper Park/Cooper Park Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Williams Plaza/Site Plan 2009.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Carey Gardens/Carey Gardens Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Whitman/Whitman Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Pink/Pink_General Site Plan 1957.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Pink/Pink Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Pink/Pink Houses Pink & Green.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Pink/Combined Utilites for Urban Farm 2015.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Pink/Utilities Location Plan for Urban Farm.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Pink/Pink Possible Mini Soccer Site.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Howard/Howard Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Armstrong I/A-3  Kitchen Armstrong I Houses.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Armstrong I/SY-1 CN#1 Site Fencing Plan for Legal.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Glenwood/Glennwood Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Sumner/Sumner Houses Site Plan with Catch Basins indicated.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Sumner/SUMNER HOUSES SITE PLAN.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Sumner/Bushwick City Farm site at Sumner Houses.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Sumner/Sumner Play Equipment Details for Legal 1 30 2017.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Woodson/Woodson Sketch for SHPO.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Woodson/WOODSON COMPACTOR  11.2018.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Woodson/Site Plan- Woodson.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Gravesend/Gravesend Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Borinquen Plaza I/Borinquen Plaza I Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Hughes Apartments/Hughes Apts_3 Layout Plan 1992.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Hughes Apartments/Hughes Apts_Declaration of Trust.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Hughes Apartments/Hughes Apts_2 Materials Plan 1992.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Hughes Apartments/Hughes Apts_General Site Plan 1967.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Hughes Apartments/Hughes Apts_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Hughes Apartments/Hughes Apts_Portion of Landscape Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Bushwick/bLDG 6 BASEMENT PLUMB.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Bushwick/L003_Bushwick_Electrical_Plumbing_Grading_Dimension.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Bushwick/Bushwick Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Albany I & II/location of exterior compactors and bulk area.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Albany I & II/Albany I and II Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Albany I & II/Albany I and II Site Plan 36x24 (1).pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Hylan/Hylan Exhibit A for OMB.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Hylan/Hylan Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Hylan/Sketch for SHPO Aug 2016.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Hylan/Hylan Site Plan V2.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Borinquen Plaza II/Borinquen Plaza II_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Borinquen Plaza II/Borinquen Plaza II_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Sheepshead Bay/Sheepshead Bay Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Tompkins/Tompkins Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Tompkins/Tompkins Site Plan trees_uti.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Lafayette/Lafayette Gardens Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/303 Vernon Avenue/303 Vernon Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Coney Island/Coney Island Site for KaBOOM.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Coney Island/Coney Island General Site Plan A-1.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Boulevard/Boulevard Site Plans.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Taylor St- Wythe Ave/Taylor Wythe Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Haber/Haber_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Haber/Haber_Site Plan A-1.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Haber/Haber_Planting Plan TP-10.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Haber/Haber_Development Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Unity Plaza Sites 17,24, 25A/Unity Plaza 17, 24, 25A P&G.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Unity Plaza Sites 17,24, 25A/Unity Plaza 17, 24, 25A Site Plan QWEB.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/East NewYork City Lane/East New York City Line Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Brevoort/Brevoort Site Plan V8.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Brevoort/Brevoort Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Fiorentino Plaza/Fiorentino Plaza Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Stuyesant Gardens 1 & 2/Stuyvesant Gardens II_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Stuyesant Gardens 1 & 2/Styvesant Gardens_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Williamsburg/Williamburg Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Williamsburg/Williamburg Houses Site Plan with Utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Linden/Linden Houses Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Linden/Site Plan- Linden Community Center Grounds 2007.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Howard Avenue/Howard Avenue Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Rutland Towers/Rutland Towers Site Plan from Qweb.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Saratoga Village/Saratoga Village (33-35 Saratoga Ave) Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Brownsville/Brownsville Site Plan with Utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Brownsville/Brownsville Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Coney Island (Site 1B)/Updated survey CONEY ISLAND SITE 1B-NAVD88-9-5-14f.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Vandalia Avenue/Vandalia Ave_site plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Ingersoll/Ingersoll Double Basketball Court .pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Ingersoll/IngersolHouses_Letter_SitePlan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Ingersoll/Steam Line Distribution H-5.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Ingersoll/Detail Sheet 23.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Brooklyn/Ingersoll/Site Plan Ingersoll .pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Beach 41st Street- Beach Channel Drive/Beach 41st Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Conlon Lihfe Tower/L006_Planting.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Conlon Lihfe Tower/Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Redfern/Redfern Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Astoria/Astoria Existing Site Plan-36x24-2.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Astoria/Astoria Existing Site Plan-36x24.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Astoria/Astoria Houses Total Site.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/South Jamaica I & II/South Jamaica I&II Possible Mini Soccer Site.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/South Jamaica I & II/South Jamaica Site Plan BBall.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/South Jamaica I & II/South Jamaica Sketch for SHPO.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/South Jamaica I & II/South Jamaica I&II Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Queensbridge North/Queensbridge North and South Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Woodside/Woodside Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Woodside/Woodside Site Plan with utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Woodside/Woodside Site Plan Play Areas.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Ravenswood/Ravenswood Site Plan with Utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Ravenswood/Ravenswood Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Ravenswood/Ravenswood Site Plan v.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Ravenswood/Ravenswood Develpoment Map.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Hammel/Hammel - Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Bland/Bland_Grounds Materials Plan Dwg 3.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Bland/Bland_Plumbing Detail Site & Utility Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Bland/Site Plan Bland Houses utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Bland/Bland Site Plan Qweb.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Bland/Bland Rental Drawing Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Bland/Bland_Composite Utility Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Bland/Detail Site Plan SY-10a.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Bland/Site Plan Bland Houses.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Ocean Bay Apartments (Oceanside)/Ocean Hill Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Ocean Bay Apartments (Oceanside)/OceanHill_Letter_SitePlan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Queensbridge South/Plumbing Plot Plan P-350.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Queensbridge South/Queensbridge South.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Queensbridge South/Queensbridge North and South Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Queensbridge South/General Site Plan Drawing A-1.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Latimer Gardens/Latimer Gardens_Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Leavitt Street- 34th Ave/site plan_Leavitt street.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Pomonok/Pomonok Site Plan in progress 2018.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Pomonok/Pomonok Site Plan utilities.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Pomonok/Pomonok possible Mini Soccer Site.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Pomonok/Pomonok Site Plan.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Baisley Park/Detail Sheet  9 from 92.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Baisley Park/Blow up of Baisley B Ball Court 20200629.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Baisley Park/Site Plan Basketball Court for Knicks 20200629.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Baisley Park/Plumbing Cellar Plan Bldgs 3 and 4.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Baisley Park/Grading Sheet 8.pdf',\n",
       " 'APPENDICES/Site Plans w.r.t Boroughs/Queens/Baisley Park/Baisley Park_PDF.pdf']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_plan_pdf_candidates = glob.glob('APPENDICES/*/*/*/*.pdf')\n",
    "site_plan_pdf_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Floorplans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor_plan_paths = glob.glob('APPENDICES/floorplans/*')\n",
    "\n",
    "candidate_list = []\n",
    "for key, value in developments.items():\n",
    "    candidate_list.append(str(value['name']).upper())\n",
    "    for item in value['name_alternates']:\n",
    "        candidate_list.append(item.upper())\n",
    "\n",
    "def get_dev_name(name):\n",
    "    match = process.extractOne(str(name).upper(), candidate_list)[0]\n",
    "    #print(match)\n",
    "    for key, value in developments.items():\n",
    "        if (match.upper() == value['name'].upper()) or (match.upper() in [val.upper() for val in value['name_alternates']]):\n",
    "            return value['name']\n",
    "\n",
    "    return '!!!NOT FOUND'\n",
    "\n",
    "\n",
    "def get_tds_from_name(x):\n",
    "    for key, value in developments.items():\n",
    "        if x == value['name']:\n",
    "            return key\n",
    "        \n",
    "    return 'N/A'\n",
    "\n",
    "floor_plan_names = [get_dev_name(path.split('/')[-1].replace('.pdf','')) for path in floor_plan_paths]\n",
    "floor_plan_tds = [get_tds_from_name(name) for name in floor_plan_names]\n",
    "\n",
    "floor_plans = pd.DataFrame(data=list(zip(floor_plan_tds, floor_plan_names, floor_plan_paths)), columns=['TDS', 'NAME', 'PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "floor_plans.to_csv('APPENDICES/floorplans/floor_plans_for_screening.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making and Compiling LaTeX Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_latex_file(tds, counts=counts):\n",
    "    #SET UTILITY PATHS HERE\n",
    "    pdflatex_path = '/usr/local/texlive/2018/bin/x86_64-darwin/pdflatex'\n",
    "    ghostscript_path = '/usr/local/bin/gs'\n",
    "    \n",
    "    if counts[tds]['count'] <= 4:\n",
    "        with open('REPORT_TEMPLATE/report.tex', 'r') as file_handle:\n",
    "            text = file_handle.read()\n",
    "            \n",
    "        new_text = text.replace('$tds_number$', str(tds))\n",
    "\n",
    "        with open(f'REPORTS/LaTeX/{tds}_report.tex', 'w') as outfile:\n",
    "            outfile.write(new_text)\n",
    "    \n",
    "    else:\n",
    "        with open('REPORT_TEMPLATE/report_long.tex', 'r') as file_handle:\n",
    "            text = file_handle.read()\n",
    "            \n",
    "        new_text = text.replace('$tds_number$', str(tds))\n",
    "\n",
    "        with open(f'REPORTS/LaTeX/{tds}_report.tex', 'w') as outfile:\n",
    "            outfile.write(new_text)\n",
    "\n",
    "    subprocess.check_call([pdflatex_path, '-output-directory', 'REPORTS/LaTeX', f'REPORTS/LaTeX/{tds}_report.tex'])\n",
    "    subprocess.check_call([pdflatex_path, '-output-directory', 'REPORTS/LaTeX', f'REPORTS/LaTeX/{tds}_report.tex'])\n",
    "    \n",
    "    #Be sure to install ghostscript (to compress pdfs), or comment out next line. Available via homebrew.\n",
    "    subprocess.check_call([ghostscript_path, '-sDEVICE=pdfwrite', '-dCompatibilityLevel=1.5', '-dNOPAUSE', '-dQUIET', '-dBATCH', f'-sOutputFile=REPORTS/{tds}_report.pdf', f'REPORTS/LaTeX/{tds}_report.pdf'])\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists('REPORTS'):\n",
    "    os.makedirs('REPORTS')\n",
    "\n",
    "if not os.path.exists('REPORTS/LaTeX'):\n",
    "    os.makedirs('REPORTS/LaTeX')\n",
    "\n",
    "os.system(\"cp REPORT_TEMPLATE/content.tex REPORTS/LaTeX\")\n",
    "os.system(\"cp REPORT_TEMPLATE/preface.tex REPORTS/LaTeX\")\n",
    "os.system(\"cp REPORT_TEMPLATE/content_long.tex REPORTS/LaTeX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consolidation_list = consolidations.keys()\n",
    "consolidation_list = ['003']\n",
    "for tds in consolidation_list:\n",
    "    try:\n",
    "        compile_latex_file(tds)\n",
    "    except:\n",
    "        print(f'{tds} raised exception: {sys.exc_info()[0]}')\n",
    "\n",
    "filelist = [f for f in os.listdir('REPORTS/LaTeX') if not f.endswith(\".tex\")]\n",
    "for f in filelist:\n",
    "    #os.remove(os.path.join('REPORTS/LaTeX', f))\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
