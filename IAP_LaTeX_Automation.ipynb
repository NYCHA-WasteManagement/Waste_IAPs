{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaTeX Automation for NYCHA Waste Individual Action Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import docx2txt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Global Vars and Options\n",
    "os.chdir('/Users/kyleslugg/Documents/NYCHA/Production')\n",
    "cons_tds = '073'\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and Process Text Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO COME:\n",
    "- Waste Services and Assets\n",
    "- Waste Distribution (top text -- bottom accounted for below)\n",
    "- What Is an IAP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Character Substitutions for LaTeX -- set and define \"clean\" method\n",
    "def clean_text(text):\n",
    "    substitutions = {'“':\"``\",\n",
    "                '”': \"''\",\n",
    "                '’':\"'\",\n",
    "                ' ':' ',\n",
    "                '–':'--',\n",
    "                ' ':' ',\n",
    "                '\\xa0':' '}\n",
    "    \n",
    "    for key, value in substitutions.items():\n",
    "        text = text.replace(key, value)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_overview_text(cons_tds):\n",
    "    header = re.compile(r'((\\w*\\s)*(Overview)):?')\n",
    "    \n",
    "    overview_text = docx2txt.process(f'TEXT/{cons_tds}_Overview.docx')\n",
    "    try:\n",
    "        overview_text = overview_text.replace(header.findall(overview_text)[0]+'\\n','')\n",
    "    except:\n",
    "        overview_text = overview_text.replace(header.findall(overview_text)[0][0]+'\\n','')\n",
    "    overview_text = clean_text(overview_text)\n",
    "    \n",
    "    with open(f'TEXT/overview_text/{cons_tds}_overview.tex', 'w') as file_handle:\n",
    "        file_handle.write(overview_text)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "make_overview_text(cons_tds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_analysis_text(cons_tds):\n",
    "    analysis_text = docx2txt.process(f'TEXT/{cons_tds}_Analysis.docx')\n",
    "\n",
    "    header = re.compile(r'([\\w\\s]*:)')\n",
    "\n",
    "    section_headings = {'Inspection and Collection Requirement':['Inspection and Collection Requirement',\n",
    "                                                                'Inspection and Collection Requirements',\n",
    "                                                                'Collection and Inspection Requirement',\n",
    "                                                                'Collection and Inspection Requirements'],\n",
    "                        \n",
    "                        'Removal or Storage Requirement':['Removal or Storage Requirement',\n",
    "                                                          'Removal or Storage Requirements',\n",
    "                                                         'Removal and Storage Requirement',\n",
    "                                                         'Removal and Storage Requirements',\n",
    "                                                         'Storage or Removal Requirement',\n",
    "                                                         'Storage and Removal Requirement',\n",
    "                                                         'Storage and Removal Requirements']}\n",
    "    \n",
    "    for heading, variants in section_headings.items():\n",
    "        for variant in variants:\n",
    "            analysis_text = analysis_text.replace(variant, r'\\emph{%s}' % heading)\n",
    "\n",
    "    analysis_text = analysis_text.replace(header.findall(analysis_text)[0]+'\\n','')\n",
    "\n",
    "    latex_block = clean_text(analysis_text)\n",
    "\n",
    "    with open(f'TEXT/analysis_text/{cons_tds}_analysis.tex', 'w') as file_handle:\n",
    "        file_handle.write(latex_block)\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "make_analysis_text(cons_tds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and Prepare Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Set asset map path\n",
    "asset_map_path = f\"MAPS/asset_maps/{cons_tds}_asset_map.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Split context map into two pages\n",
    "def process_context_map(cons_tds):\n",
    "    image = Image.open(f'REPORT_TEMPLATE/{cons_tds}_context_map.png')\n",
    "    width, height = image.size\n",
    "\n",
    "    bb1 = (0,0,width/2,height)\n",
    "    bb2 = (width/2, 0, width, height)\n",
    "\n",
    "    img_1 = image.crop(bb1)\n",
    "    img_2 = image.crop(bb2)\n",
    "\n",
    "    img_1.save(f'MAPS/context_maps/{cons_tds}_context_1.png', format=\"PNG\")\n",
    "    img_2.save(f'MAPS/context_maps/{cons_tds}_context_2.png', format=\"PNG\")\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO COME:\n",
    "- Waste Services and Assets\n",
    "- Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "overview_data = pd.read_csv('DATA/overview_table_data.csv')\n",
    "overview_data['CONS_TDS'] = overview_data['CONS_TDS'].apply(lambda x: str(x).zfill(3))\n",
    "overview_data['TDS'] = overview_data['TDS'].apply(lambda x: str(x).zfill(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Overview Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_overview_table(cons_tds, overview_data=overview_data):\n",
    "    \n",
    "    cons_data = overview_data.loc[overview_data['CONS_TDS']== cons_tds]\n",
    "    \n",
    "    overview_table = ''\n",
    "\n",
    "    overview_frame = r'''\n",
    "    \\begin{tabular}{l|c|c|c|c|}\n",
    "    \\cline{2-5}\n",
    "                                                                           & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} TDS \\#} & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} Total Households} & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} Official Population} & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} Average Family Size} \\\\ \\hline\n",
    "\n",
    "    '''\n",
    "\n",
    "    development_template = r'''\\multicolumn{1}{|l|}{\\cellcolor{ccteallight}%s}        & %s                                                   & %s                                                           & %s                                                                & %s                                                                \\\\ \\hline'''\n",
    "\n",
    "\n",
    "    overview_table += overview_frame\n",
    "\n",
    "    for row in cons_data.itertuples():\n",
    "        dev_name = row.DEV_NAME.title()\n",
    "        dev_tds = row.TDS\n",
    "        total_hhs = row.TOTAL_HH\n",
    "        official_population = row.TOTAL_POP\n",
    "        avg_family_size = row.AVG_FAMILY_SIZE\n",
    "\n",
    "        overview_table += development_template % (dev_name, dev_tds, total_hhs, official_population, avg_family_size)\n",
    "\n",
    "    overview_table += r'''\n",
    "    \\end{tabular}\n",
    "    '''\n",
    "    \n",
    "    with open(f'TABLES/overview_table/{cons_tds}_overview_table.tex', 'w') as file_handle:\n",
    "        file_handle.write(overview_table)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Typology Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ_1 = pd.read_csv('DATA/typologies_1.csv')\n",
    "typ_2 = pd.read_csv('DATA/typologies_2.csv')\n",
    "\n",
    "typ_1.columns = ['CONS_NAME', 'DEV_NAME', 'TDS', 'TYPOLOGY']\n",
    "typ_2.columns = ['CONS_NAME', 'CONS_TDS', 'DEV_NAME', 'TDS', 'METHOD', \n",
    "                 'CONSTRUCTION_DATE', 'BLDG_AGE', 'STORIES', 'BLDG_COVERAGE_SQFT', 'OPEN_SPACE_RATIO', 'SCATTERED_SITE_FLAG']\n",
    "\n",
    "typ_2['CONSTRUCTION_DATE'] = typ_2['CONSTRUCTION_DATE'].apply(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONS_NAME</th>\n",
       "      <th>DEV_NAME</th>\n",
       "      <th>TDS</th>\n",
       "      <th>TYPOLOGY</th>\n",
       "      <th>CONS_TDS</th>\n",
       "      <th>METHOD</th>\n",
       "      <th>CONSTRUCTION_DATE</th>\n",
       "      <th>BLDG_AGE</th>\n",
       "      <th>STORIES</th>\n",
       "      <th>BLDG_COVERAGE_SQFT</th>\n",
       "      <th>OPEN_SPACE_RATIO</th>\n",
       "      <th>SCATTERED_SITE_FLAG</th>\n",
       "      <th>PREWAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1010 EAST 178TH STREET</td>\n",
       "      <td>1010 EAST 178TH STREET</td>\n",
       "      <td>180</td>\n",
       "      <td>1 - High-rise in the park</td>\n",
       "      <td>180.0</td>\n",
       "      <td>CONVENTIONAL</td>\n",
       "      <td>1971-03-31</td>\n",
       "      <td>49.0</td>\n",
       "      <td>21</td>\n",
       "      <td>14,961</td>\n",
       "      <td>0.83</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1010 EAST 178TH STREET</td>\n",
       "      <td>EAST 180TH STREET-MONTEREY AVENUE</td>\n",
       "      <td>208</td>\n",
       "      <td>5 - Context Mid-rises</td>\n",
       "      <td>180.0</td>\n",
       "      <td>CONVENTIONAL</td>\n",
       "      <td>1973-09-30</td>\n",
       "      <td>47.0</td>\n",
       "      <td>10</td>\n",
       "      <td>30,800</td>\n",
       "      <td>0.53</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010 EAST 178TH STREET</td>\n",
       "      <td>TWIN PARKS EAST (SITE 9)</td>\n",
       "      <td>287</td>\n",
       "      <td>2 - Mid-rise in the park</td>\n",
       "      <td>180.0</td>\n",
       "      <td>CONVENTIONAL</td>\n",
       "      <td>1982-04-30</td>\n",
       "      <td>38.0</td>\n",
       "      <td>14</td>\n",
       "      <td>11,388</td>\n",
       "      <td>0.82</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adams</td>\n",
       "      <td>ADAMS</td>\n",
       "      <td>118</td>\n",
       "      <td>1 - High-rise in the park</td>\n",
       "      <td>118.0</td>\n",
       "      <td>CONVENTIONAL</td>\n",
       "      <td>2064-08-31</td>\n",
       "      <td>56.0</td>\n",
       "      <td>15-21</td>\n",
       "      <td>56,283</td>\n",
       "      <td>0.86</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boston Secor</td>\n",
       "      <td>BOSTON SECOR</td>\n",
       "      <td>138</td>\n",
       "      <td>1 - High-rise in the park</td>\n",
       "      <td>138.0</td>\n",
       "      <td>CONVENTIONAL</td>\n",
       "      <td>2069-04-30</td>\n",
       "      <td>51.0</td>\n",
       "      <td>13-14-17-18</td>\n",
       "      <td>36,181</td>\n",
       "      <td>0.92</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                CONS_NAME                           DEV_NAME  TDS  \\\n",
       "0  1010 EAST 178TH STREET             1010 EAST 178TH STREET  180   \n",
       "1  1010 EAST 178TH STREET  EAST 180TH STREET-MONTEREY AVENUE  208   \n",
       "2  1010 EAST 178TH STREET           TWIN PARKS EAST (SITE 9)  287   \n",
       "3                   Adams                              ADAMS  118   \n",
       "4            Boston Secor                       BOSTON SECOR  138   \n",
       "\n",
       "                    TYPOLOGY  CONS_TDS        METHOD CONSTRUCTION_DATE  \\\n",
       "0  1 - High-rise in the park     180.0  CONVENTIONAL        1971-03-31   \n",
       "1      5 - Context Mid-rises     180.0  CONVENTIONAL        1973-09-30   \n",
       "2   2 - Mid-rise in the park     180.0  CONVENTIONAL        1982-04-30   \n",
       "3  1 - High-rise in the park     118.0  CONVENTIONAL        2064-08-31   \n",
       "4  1 - High-rise in the park     138.0  CONVENTIONAL        2069-04-30   \n",
       "\n",
       "   BLDG_AGE      STORIES BLDG_COVERAGE_SQFT  OPEN_SPACE_RATIO  \\\n",
       "0      49.0           21             14,961              0.83   \n",
       "1      47.0           10             30,800              0.53   \n",
       "2      38.0           14             11,388              0.82   \n",
       "3      56.0        15-21             56,283              0.86   \n",
       "4      51.0  13-14-17-18             36,181              0.92   \n",
       "\n",
       "  SCATTERED_SITE_FLAG  PREWAR  \n",
       "0               False   False  \n",
       "1               False   False  \n",
       "2               False   False  \n",
       "3               False   False  \n",
       "4               False   False  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typ_2['SCATTERED_SITE_FLAG'] = typ_2['SCATTERED_SITE_FLAG'].apply(lambda x: x == 'YES')\n",
    "typ_2.loc[typ_2['SCATTERED_SITE_FLAG']=='YES','SCATTERED_SITE_FLAG'] = 1\n",
    "\n",
    "typology = typ_1.merge(typ_2[['CONS_TDS', 'TDS', 'METHOD',\n",
    "                             'CONSTRUCTION_DATE', 'BLDG_AGE', \n",
    "                             'STORIES', 'BLDG_COVERAGE_SQFT', \n",
    "                             'OPEN_SPACE_RATIO', 'SCATTERED_SITE_FLAG']], how='left', on='TDS')\n",
    "\n",
    "typology['PREWAR'] = typology['CONSTRUCTION_DATE'].apply(lambda x: x < datetime.date(1945,1,1))\n",
    "\n",
    "typology.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "header_two = r\"\\begin{tabular}{m{1.25in} m{2in} m{.1in} m{1.25in} m{2in}}\"\n",
    "header_three = r\"\\begin{tabular}{m{1.25in} m{2in} m{.1in} m{1.25in} m{2in} m{1.25in} m{2in}}\"\n",
    "header_three = r\"\\begin{tabular}{m{1.25in} m{2in} m{.1in} m{1.25in} m{2in} m{1.25in} m{2in} m{1.25in} m{2in}}\"\n",
    "r'''\\begin{tabular}{m{1.25in} m{2in} m{.1in} m{1.25in} m{2in}}\n",
    "\\sf\\bf{Sumner Houses and 303 Vernon Avenue} & \\includegraphics[height=2in]{towers_in_park} & & \\sf\\bf{Bedford-Stuyvesant Rehab} & \\includegraphics[height=2in]{prewar.png}\n",
    "\\end{tabular}'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waste Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def add_waste_cols(overview_data=overview_data):\n",
    "    conversion_factors = {'units_to_tons_day': 0.0025,\n",
    "                         'cy_per_ton': {'trash': 21.05,\n",
    "                                        'trash_actual': 0,\n",
    "                                       'MGP': 18.02,\n",
    "                                       'cardboard': 26.67,\n",
    "                                       'paper': 6.19,\n",
    "                                       'organics': 4.32,\n",
    "                                       'ewaste': 5.65,\n",
    "                                       'textiles': 13.33},\n",
    "                         'gallons_per_cy': 201.974,\n",
    "                         'gallons_per_64gal': 64,\n",
    "                         'gallons_per_40lb_bag': 44,\n",
    "                         'cy_per_44gal_bag':0.174,\n",
    "                         'cy_per_cardboard_bale':0.193}\n",
    "\n",
    "    waste_percentages = {'trash': .26,\n",
    "                         'trash_actual':.894,\n",
    "                        'MGP': .19,\n",
    "                        'cardboard': .07,\n",
    "                        'paper': .07,\n",
    "                        'organics':.32,\n",
    "                        'ewaste': .01,\n",
    "                        'textiles': .08}\n",
    "\n",
    "    capture_rates = {'trash_primary': .75,\n",
    "                    'trash_secondary': .25,\n",
    "                    'mgp': .30,\n",
    "                    'cardboard': .50,\n",
    "                    'paper': .20}\n",
    "\n",
    "    overview_data['WASTE_TONS_DAY'] = overview_data['CURRENT_APTS'].apply(lambda x: x * conversion_factors['units_to_tons_day'])\n",
    "\n",
    "    for key, value in waste_percentages.items():\n",
    "        overview_data[f'{key.upper()}_CY'] = overview_data['WASTE_TONS_DAY'].apply(lambda x: x * value * conversion_factors['cy_per_ton'][key])\n",
    "        overview_data[f'{key.upper()}_TONS'] = overview_data['WASTE_TONS_DAY'].apply(lambda x: x * value)\n",
    "    \n",
    "    overview_data['TRASH_ACTUAL_CY'] = (overview_data['TRASH_CY']+\n",
    "                                           overview_data['MGP_CY']+\n",
    "                                           overview_data['CARDBOARD_CY']+\n",
    "                                           overview_data['PAPER_CY']+\n",
    "                                           overview_data['ORGANICS_CY']+\n",
    "                                           overview_data['EWASTE_CY']+\n",
    "                                           overview_data['TEXTILES_CY'])-(overview_data['MGP_CY']*capture_rates['mgp']+\n",
    "                                                                         overview_data['CARDBOARD_CY']*capture_rates['cardboard']+\n",
    "                                                                         overview_data['PAPER_CY']*capture_rates['paper'])\n",
    "\n",
    "    overview_data['TRASH_CHUTE_CY'] = overview_data['TRASH_ACTUAL_CY']*capture_rates['trash_primary']\n",
    "    overview_data['TRASH_CHUTE_TONS'] = overview_data['TRASH_ACTUAL_TONS']*capture_rates['trash_primary']\n",
    "    overview_data['TRASH_CHUTE_SAUSAGE'] = ((overview_data['TRASH_CHUTE_CY'])/conversion_factors['cy_per_ton']['trash'])*(2000/40)\n",
    "    overview_data['TRASH_DROP_CY'] = overview_data['TRASH_ACTUAL_CY']*capture_rates['trash_secondary']\n",
    "    overview_data['TRASH_DROP_TONS'] = overview_data['TRASH_ACTUAL_TONS']*capture_rates['trash_secondary']\n",
    "    overview_data['TRASH_DROP_BINS'] = overview_data['TRASH_DROP_CY']*conversion_factors['gallons_per_cy']/64\n",
    "    overview_data['CAPTURED_MGP_TONS_WEEK'] = overview_data['MGP_TONS']*capture_rates['mgp']*7\n",
    "    overview_data['CAPTURED_CARDBOARD_TONS_WEEK'] = overview_data['CARDBOARD_TONS']*capture_rates['cardboard']*7\n",
    "    overview_data['CAPTURED_PAPER_TONS_WEEK'] = overview_data['PAPER_TONS']*capture_rates['paper']*7\n",
    "    overview_data['MGP_BAGS_WEEK'] = overview_data['MGP_CY']*capture_rates['mgp']*7/conversion_factors['cy_per_44gal_bag']\n",
    "    overview_data['PAPER_BAGS_WEEK'] = overview_data['PAPER_CY']*capture_rates['paper']*7/conversion_factors['cy_per_44gal_bag']\n",
    "    overview_data['CARDBOARD_BALES_WEEK'] = overview_data['CARDBOARD_CY']*capture_rates['cardboard']*7/conversion_factors['cy_per_cardboard_bale']\n",
    "    \n",
    "    return overview_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "overview_data = add_waste_cols(overview_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_waste_distribution_table(cons_tds, overview_data=overview_data):\n",
    "    cons_data = overview_data[overview_data['CONS_TDS'] == cons_tds]\n",
    "    num_devs = cons_data.shape[0]\n",
    "    \n",
    "    if num_devs > 1:\n",
    "        num_cols = num_devs+1\n",
    "    else:\n",
    "        num_cols = num_devs\n",
    "\n",
    "    dev_col_format = r'X|'\n",
    "\n",
    "    opening = r'''\n",
    "    \\begin{tabularx}{\\textwidth}{V{1.5in}|%s}\n",
    "    \\cline{2-%s}\n",
    "    ''' % (dev_col_format*num_cols, (num_cols+1))\n",
    "\n",
    "    top_row = r'''\n",
    "                                                                   '''+(r\"& \\multicolumn{1}{l|}{\\cellcolor{ccorange}%s}\"*(num_cols))+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    standard_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s}                 \"+(r\"& %s                                    \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    captured_row = r\"\\multicolumn{1}{|Y{1.5in}|}{\\cellcolor{ccorangelight}Captured / Week (tons)\\tnote{4}}                        \"+(r\"& %s                                    \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    chute_row = r\"\\multicolumn{1}{|Y{1.5in}|}{\\cellcolor{ccorangelight}Trash Chutes\\tnote{2}}                 \"+(r\"& %s tons or (%s) 40 lbs. sausage bags      \"*num_cols)+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    dropsite_row = r\"\\multicolumn{1}{|Y{1.5in}|}{\\cellcolor{ccorangelight}Drop Sites\\tnote{3}}                 \"+(r\"& %s tons or (%s) 64-gallon bins      \"*num_cols)+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    OET_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s / Day (CY)\\tnote{5}}              \"+(r\"& %s                                    \"*num_cols)+r\"\\tnhl\"+'\\n'\n",
    "    \n",
    "    recycling_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s}                 \"+(r\"& %s tons or (%s) 44-gallon bags                                   \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "    \n",
    "    cardboard_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s}                 \"+(r\"& %s tons or (%s) bales                                   \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "    \n",
    "    def make_waste_distribution_table_block(cons_data, num_cols):\n",
    "        if num_cols != 1:\n",
    "            cons_data.loc['Total']= cons_data.sum(numeric_only=True, axis=0)\n",
    "            cons_data.loc['Total','DEV_NAME'] = 'Total'\n",
    "\n",
    "        def make_trash_text(row, text_var, cy_col, other_col):\n",
    "            text_var.append(round(row[cy_col],2))\n",
    "            text_var.append(round(row[other_col], 2))\n",
    "            pass\n",
    "\n",
    "        latex_block = opening\n",
    "        latex_block += top_row % tuple(cons_data['DEV_NAME'].apply(lambda x: str(x).title()).tolist())\n",
    "        latex_block += standard_row % tuple([r\"Waste Generated / Day (Tons)\\tnote{1}\"]+[round(item, 2) for item in cons_data['WASTE_TONS_DAY'].tolist()])\n",
    "        latex_block += standard_row % tuple([r\"Trash / Day (tons)\\tnote{2}\"]+cons_data['TRASH_ACTUAL_TONS'].apply(lambda x: str(round(x,2))).tolist())\n",
    "\n",
    "        trash_chute_text = []\n",
    "        dropsite_text = []\n",
    "\n",
    "        cons_data.apply(lambda row: make_trash_text(row, trash_chute_text, 'TRASH_CHUTE_TONS', 'TRASH_CHUTE_SAUSAGE'), axis=1)\n",
    "        cons_data.apply(lambda row: make_trash_text(row, dropsite_text, 'TRASH_DROP_TONS', 'TRASH_DROP_BINS'), axis=1)\n",
    "\n",
    "        latex_block += chute_row % tuple(trash_chute_text)\n",
    "        latex_block += dropsite_row % tuple(dropsite_text)\n",
    "        \n",
    "        latex_block += r\"\\end{tabularx}\\bigskip\"\n",
    "        \n",
    "        latex_block += opening\n",
    "        latex_block += top_row % tuple(cons_data['DEV_NAME'].apply(lambda x: str(x).title()).tolist())\n",
    "        \n",
    "        mgp_text = []\n",
    "        cardboard_text= []\n",
    "        paper_text = []\n",
    "        \n",
    "        cons_data.apply(lambda row: make_trash_text(row, mgp_text, 'CAPTURED_MGP_TONS_WEEK', 'MGP_BAGS_WEEK'), axis=1)\n",
    "\n",
    "        cons_data.apply(lambda row: make_trash_text(row, cardboard_text, 'CAPTURED_CARDBOARD_TONS_WEEK', 'CARDBOARD_BALES_WEEK'), axis=1)\n",
    "\n",
    "        cons_data.apply(lambda row: make_trash_text(row, paper_text, 'CAPTURED_PAPER_TONS_WEEK', 'PAPER_BAGS_WEEK'), axis=1)\n",
    "\n",
    "\n",
    "        \n",
    "        latex_block += recycling_row % tuple([r\"Metal, Glass, Plastic Captured / Week (tons)\"]+mgp_text)\n",
    "        #latex_block += captured_row % tuple(cons_data['CAPTURED_MGP_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        latex_block += cardboard_row % tuple([r\"Cardboard Captured / Week (tons)\"]+cardboard_text)\n",
    "        #latex_block += captured_row % tuple(cons_data['CAPTURED_CARDBOARD_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        latex_block += recycling_row % tuple([r\"Paper Captured / Week (tons)\"]+paper_text)\n",
    "        #latex_block += captured_row % tuple(cons_data['CAPTURED_PAPER_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "\n",
    "        #latex_block += OET_row % tuple(['Organics']+cons_data['ORGANICS_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        #latex_block += OET_row % tuple(['E-Waste']+cons_data['EWASTE_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        #latex_block += OET_row % tuple(['Textiles']+cons_data['TEXTILES_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "\n",
    "        latex_block += r\"\\end{tabularx}\"\n",
    "\n",
    "        return latex_block\n",
    "    \n",
    "    \n",
    "    latex_block = make_waste_distribution_table_block(cons_data, num_cols)\n",
    "    \n",
    "    with open(f'TABLES/waste_distribution_table/{cons_tds}_wd_table.tex', 'w') as file_handle:\n",
    "        file_handle.write(latex_block)\n",
    "    \n",
    "    \n",
    "    text_block = r''''''\n",
    "    \n",
    "    text_line_multi = r\"\\bf{%s}: This development has %s apartment units and %s stairhalls.\\\\\"\n",
    "\n",
    "    text_line_singular = r\"\\bf{%s}: This development has %s apartment units and one stairhall.\\\\\"\n",
    "    \n",
    "    for row in cons_data.itertuples():\n",
    "    \n",
    "        if int(row.STAIRHALLS) == 1:\n",
    "            text_block += text_line_singular % (row.DEV_NAME.title(), int(row.CURRENT_APTS))\n",
    "        else:\n",
    "            text_block += text_line_multi % (row.DEV_NAME.title(), int(row.CURRENT_APTS), int(row.STAIRHALLS))\n",
    "\n",
    "    \n",
    "    with open(f'TEXT/waste_distribution_bottom/{cons_tds}_wd_bottom.tex', 'w') as file_handle:\n",
    "        file_handle.write(text_block)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "make_waste_distribution_table('073')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Capital Improvements Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "asset_data = {'fwd': ['In-Sink Food Grinders', pd.read_csv('DATA/capital_fwd.csv')],\n",
    "              'ehd': ['Enlarged Hopper Doors', pd.read_csv('DATA/capital_ehd.csv')],\n",
    "              'int_compactor':['Interior Compactor Replacement', pd.read_csv('DATA/capital_intcom.csv')],\n",
    "              'wasteyard':['Waste Yard Redesign', pd.read_csv('DATA/capital_wasteyard.csv')]}\n",
    "\n",
    "for value in asset_data.values():\n",
    "    value[1].columns = [item.strip() for item in value[1].columns]\n",
    "\n",
    "asset_data['wasteyard'][1]['ESTIMATE'] = asset_data['wasteyard'][1]['TOT_EST']\n",
    "asset_data['wasteyard'][1]['COST'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_capital_table(cons_tds, overview_data=overview_data):\n",
    "    cons_data = overview_data[overview_data['CONS_TDS'] == cons_tds]\n",
    "    num_devs = cons_data.shape[0]\n",
    "\n",
    "    dev_col_format = r'X|'\n",
    "    header = r'''\n",
    "    \\begin{tabularx}{\\textwidth}{r|%s}\n",
    "    \\cline{2-%s}\n",
    "    ''' % ((dev_col_format*num_devs), num_devs)\n",
    "\n",
    "    top_row = r\"\\multicolumn{1}{l|}{}                                                        \"+r\"& \\cellcolor{ccorange}{\\color[HTML]{FFFFFF}%s} \"*num_devs+r\"\\\\ \\hline\"+\"\\n\"\n",
    "\n",
    "    project_block = r\"\\multicolumn{1}{|V{.2\\columnwidth}|}{\\cellcolor{ccorangelight}%s}          \"+(r\"&                                                                  \"*num_devs)+r\"\\\\\"+r'''\n",
    "    \\multicolumn{1}{|r|}{\\cellcolor{ccorangelight}\\textit{Status}}                '''+(r\"& %s                                                         \"*num_devs)+r'''\\\\\n",
    "    \\multicolumn{1}{|r|}{\\cellcolor{ccorangelight}\\textit{%s}}                  '''+(\"& %s                                                     \"*num_devs)+r\"\\\\ \\hline\"+\"\\n\"\n",
    "    \n",
    "    def make_capital_table_block(cons_data):\n",
    "        devs = cons_data['DEV_NAME'].apply(lambda x: str(x).upper()).tolist()\n",
    "        devs_title = cons_data['DEV_NAME'].apply(lambda x: str(x).title()).tolist()\n",
    "        latex_block = ''\n",
    "        latex_block += header\n",
    "        latex_block += top_row % tuple(cons_data['DEV_NAME'].apply(lambda x: str(x).title()).tolist())\n",
    "\n",
    "        for asset in asset_data.keys():\n",
    "            asset_df = asset_data[asset][1]\n",
    "            #print(asset_data[asset][0])\n",
    "            #print(devs)\n",
    "            #print(asset_df['DEVELOPMENT'].tolist())\n",
    "            if any((dev in asset_df['DEVELOPMENT'].tolist()) for dev in devs):\n",
    "                status_list = []\n",
    "                cost_title = []\n",
    "                cost_list = []\n",
    "\n",
    "                for dev in devs:\n",
    "                    if dev in asset_df['DEVELOPMENT'].tolist():\n",
    "                        #print(dev)\n",
    "                        if pd.isna(asset_df.loc[asset_df['DEVELOPMENT']== dev,'STATUS'].iloc[0]):\n",
    "                            status_list.append('Estimate')\n",
    "                        else:\n",
    "                            status_list.append(str(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'STATUS'].iloc[0]).title())\n",
    "\n",
    "                        #print(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'STATUS'])\n",
    "                        #print(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'COST'])\n",
    "\n",
    "                        if (str(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'COST'].iloc[0]).strip() == '$-') or (pd.isna(asset_df.loc[asset_df['DEVELOPMENT'] == dev, 'COST'].iloc[0])):\n",
    "                            if (str(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'ESTIMATE'].iloc[0]).strip() == '$-' or pd.isna(asset_df.loc[asset_df['DEVELOPMENT']==dev, 'ESTIMATE'].iloc[0])):\n",
    "                                cost_list.append(' ')\n",
    "                            else:\n",
    "                                cost_list.append('\\\\'+str(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'ESTIMATE'].iloc[0])+r\" (est.)\")\n",
    "                        else:\n",
    "                            if (str(asset_df.loc[asset_df['DEVELOPMENT']==dev, 'COST'].iloc[0]).strip()== '$-' or pd.isna(asset_df.loc[asset_df['DEVELOPMENT']==dev, 'COST'].iloc[0])):\n",
    "                                cost_list.append(' ')                    \n",
    "                            else: \n",
    "                                cost_list.append('\\\\'+asset_df.loc[asset_df['DEVELOPMENT']==dev, 'COST'].iloc[0])\n",
    "\n",
    "                    else:\n",
    "                        status_list.append('N/A')\n",
    "                        cost_list.append(' ')\n",
    "\n",
    "                if all((item == ' ') for item in cost_list):\n",
    "                    cost_title.append(' ')\n",
    "                else:\n",
    "                    cost_title.append('Cost')\n",
    "\n",
    "                asset_block = project_block % tuple([asset_data[asset][0]]+status_list+cost_title+cost_list)\n",
    "\n",
    "                latex_block += asset_block\n",
    "\n",
    "        latex_block += r\"\\end{tabularx}\"\n",
    "\n",
    "        return latex_block\n",
    "    \n",
    "    capital_block = make_capital_table_block(cons_data)\n",
    "    \n",
    "    with open(f\"TABLES/capital_projects_table/{cons_tds}_capital_projects.tex\", 'w') as file_handle:\n",
    "        file_handle.write(make_capital_table_block(cons_data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "make_capital_table('073')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Staff Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Read consolidation name data\n",
    "cons_ids = pd.read_csv('DATA/CONS_NAME_TDS.csv')\n",
    "cons_ids['CONS_TDS'] = cons_ids['CONS_TDS'].apply(lambda x: str(x).zfill(3))\n",
    "\n",
    "#Read budgeted staff and formula allocation\n",
    "dev_staff = pd.read_csv('DATA/staff_for_table.csv')\n",
    "dev_staff.dropna(inplace=True)\n",
    "dev_staff['Consolidation'] = dev_staff['Consolidation'].apply(lambda x: str(x).upper())\n",
    "#Note: Staff list missing for Armstrong, Ft. Washington, and Williams Plaza, as well as scatter-site third-party-managed consolidations\n",
    "dev_staff = dev_staff.merge(cons_ids, left_on='Consolidation', right_on='CONS_NAME', how='inner', indicator=False)\n",
    "\n",
    "#Read budgeted staff and actuals\n",
    "actuals_data = pd.read_csv('DATA/Staffing_Analysis/DEVHC.csv')\n",
    "actuals_data.fillna(0, inplace=True)\n",
    "actuals_data = actuals_data[actuals_data['RC Name'].apply(lambda x: \"total\" not in str(x).lower()) & actuals_data['Department'].apply(lambda x: \"total\" not in str(x).lower())]\n",
    "\n",
    "def convert_neg(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return int('-'+str(x).replace('(','').replace(')',''))\n",
    "    \n",
    "actuals_data['VARIANCE'] = actuals_data['Unnamed: 5'].apply(lambda x: convert_neg(x))\n",
    "actuals_data['ACT'] = actuals_data['13']\n",
    "\n",
    "actuals_data = actuals_data.merge(actuals_keys, how='left', left_on='CST_NAME', right_on='TITLE_NAME')\n",
    "for column in ['Current Modified', 'ACT', 'VARIANCE']:\n",
    "    actuals_data[column] = actuals_data[column].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Read column keys and table keys\n",
    "table_frame = pd.read_csv('DATA/Table_Keys.csv')\n",
    "actuals_keys = pd.read_csv('DATA/Staffing_Analysis/DEVHC_CODES.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_staff_table(cons_tds):\n",
    "    cons_id = cons_ids['CONS_NAME'].loc[cons_ids['CONS_TDS'] == cons_tds].iloc[0]\n",
    "    \n",
    "    #Fetching staff data for consolidation\n",
    "    cons_data = dev_staff.loc[dev_staff['Consolidation'] == cons_id]\n",
    "    \n",
    "    # Isolate and process actuals data for consolidation\n",
    "    try:\n",
    "        cons_actuals = actuals_data[actuals_data['RC Name'].apply(lambda x: str(x).lower() == cons_id.lower())]\n",
    "    except:\n",
    "        print(f'{cons_id} not found in actuals.')\n",
    "        return np.NaN\n",
    "    \n",
    "    cons_actuals = cons_actuals[['RC Name', 'Current Modified', 'ACT', \n",
    "                                 'CODE_KEY', 'CODE_NAME']].groupby(by='CODE_KEY', as_index=False).agg({'RC Name': 'first',\n",
    "                                                                                                     'Current Modified':sum,\n",
    "                                                                                                     'ACT':sum,\n",
    "                                                                                                     'CODE_NAME':'first'})\n",
    "    cons_actuals\n",
    "    cons_actuals.loc['Total']= cons_actuals.sum(numeric_only=True, axis=0)\n",
    "    cons_actuals.loc['Total','CODE_KEY'] = 11\n",
    "    cons_actuals.loc['Total','CODE_NAME'] = 'TOT'\n",
    "    \n",
    "    for row in cons_actuals.itertuples():\n",
    "        cons_data[f'{row.CODE_NAME}_ACT'] = row.ACT\n",
    "\n",
    "    #Setting up table and transposing data\n",
    "    cons_table_frame = table_frame\n",
    "    cons_table_frame['Formula'] = cons_table_frame['FORMULA_KEY'].iloc[:-1].apply(lambda key: cons_data[key].iloc[0])\n",
    "    cons_table_frame['Budgeted'] = cons_table_frame['BUDG_KEY'].apply(lambda key: cons_data[key].iloc[0])\n",
    "    cons_table_frame['Actual'] = cons_table_frame['ACTUALS_KEY'].iloc[:-2].apply(lambda key: cons_data[key].iloc[0])\n",
    "\n",
    "    \n",
    "    #Simplifying table\n",
    "    cons_table = cons_table_frame[['CHART_LINE', 'Formula', 'Budgeted', 'Actual']]\n",
    "    print(cons_table)\n",
    "    \n",
    "    #Defining LaTeX table format\n",
    "    \n",
    "    def make_staff_table_block(staff_data):\n",
    "    \n",
    "        table_template = r'''\n",
    "        \\begin{tabular}{l|c|c|c|}\n",
    "        \\cline{2-4}\n",
    "                                                                                     & \\cellcolor{ccfuschia}{\\color[HTML]{FFFFFF} Formula Allocation} & \\cellcolor{ccfuschia}{\\color[HTML]{FFFFFF} Budgeted} & \\cellcolor{ccfuschia}{\\color[HTML]{FFFFFF} Actual} \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Employees}                      & %s                                                      & %s                                                                & %s                                                        \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Property Manager}               & %s                                                      & %s                                                                & %s                                                       \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Asst. Property Manager}         & %s                                                      & %s                                                                & %s                                                       \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Secretaries}                    & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Housing Assistants}             & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Superintendent}                 & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Assistant Superintendent}       & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Supervisor of Caretakers (SOC)} & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Supervisor of Grounds (SOG)}    & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Maintenance Workers}            & %s                                                      & %s                                                                & %s                                                       \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Caretakers X}                   & %s                                                      & %s                                                                &                                                       \\\\ \\hline  \\cline{1-3}\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Caretakers J\\tnote{1}}                   &                                                       & %s                                                                &                                                         \\\\ \\cline{1-1} \\cline{3-3}\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Caretakers G}                   & \\multirow{-2}{*}{%s}                                                      & %s                                     & \\multirow{-3}{*}{%s}                           \\\\ \\hline\n",
    "        \\end{tabular}\n",
    "        \n",
    "        '''\n",
    "\n",
    "        values = []\n",
    "\n",
    "        def extract_data_through_mw(row):\n",
    "            [values.append(item) for item in [str(int(row['Formula'])), \n",
    "                                              str(int(row['Budgeted'])), \n",
    "                                              str(int(row['Actual']))]]\n",
    "            pass\n",
    "\n",
    "        #Processing through Maintenance Worker\n",
    "        staff_data.iloc[0:-3].apply(lambda row: extract_data_through_mw(row), axis=1)\n",
    "\n",
    "        #Processing Caretakers\n",
    "        values.append(str(int(staff_data.iloc[-3, 1])))\n",
    "        values.append(str(int(staff_data.iloc[-3, 2])))\n",
    "        values.append(str(int(staff_data.iloc[-2, 2])))\n",
    "        values.append(str(int(staff_data.iloc[-2, 1])))\n",
    "        values.append(str(int(staff_data.iloc[-1, 2])))\n",
    "        values.append(str(int(staff_data.iloc[-3, 3])))\n",
    "\n",
    "        return table_template % tuple(values)\n",
    "    \n",
    "    #Make and export LaTeX code\n",
    "    with open(f'TABLES/staff_table/{cons_tds}_staff_table.tex', 'w') as file_handle:\n",
    "        file_handle.write(make_staff_table_block(cons_table))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
