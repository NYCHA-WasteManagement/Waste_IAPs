{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaTeX Automation for NYCHA Waste Individual Action Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import docx2txt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Global Vars and Options\n",
    "os.chdir('/Users/kyleslugg/Documents/NYCHA/Production')\n",
    "cons_tds = '073'\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_overview_data():#Load Data\n",
    "    overview_data = pd.read_csv('DATA/overview_table_data.csv')\n",
    "    overview_data['CONS_TDS'] = overview_data['CONS_TDS'].apply(lambda x: str(x).zfill(3))\n",
    "    overview_data['TDS'] = overview_data['TDS'].apply(lambda x: str(x).zfill(3))\n",
    "    \n",
    "    return overview_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_data = load_overview_data()\n",
    "cons_tds_list = overview_data['CONS_TDS'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and Process Text Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO COME:\n",
    "- Waste Services and Assets\n",
    "- Waste Distribution (top text -- bottom accounted for below)\n",
    "- What Is an IAP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Character Substitutions for LaTeX -- set and define \"clean\" method\n",
    "def clean_text(text):\n",
    "    substitutions = {'“':\"``\",\n",
    "                '”': \"''\",\n",
    "                '’':\"'\",\n",
    "                ' ':' ',\n",
    "                '–':'--',\n",
    "                ' ':' ',\n",
    "                '\\xa0':' '}\n",
    "    \n",
    "    for key, value in substitutions.items():\n",
    "        text = text.replace(key, value)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_overview_text(cons_tds):\n",
    "    header = re.compile(r'((\\w*\\s)*(Overview)):?')\n",
    "    \n",
    "    overview_text = docx2txt.process(f'TEXT/{cons_tds}_Overview.docx')\n",
    "    try:\n",
    "        overview_text = overview_text.replace(header.findall(overview_text)[0]+'\\n','')\n",
    "    except:\n",
    "        overview_text = overview_text.replace(header.findall(overview_text)[0][0]+'\\n','')\n",
    "    overview_text = clean_text(overview_text)\n",
    "    \n",
    "    with open(f'TEXT/overview_text/{cons_tds}_overview.tex', 'w') as file_handle:\n",
    "        file_handle.write(overview_text)\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_overview_text(cons_tds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_analysis_text(cons_tds):\n",
    "    analysis_text = docx2txt.process(f'TEXT/{cons_tds}_Analysis.docx')\n",
    "\n",
    "    header = re.compile(r'([\\w\\s]*:)')\n",
    "\n",
    "    section_headings = {'Inspection and Collection Requirement':['Inspection and Collection Requirement',\n",
    "                                                                'Inspection and Collection Requirements',\n",
    "                                                                'Collection and Inspection Requirement',\n",
    "                                                                'Collection and Inspection Requirements'],\n",
    "                        \n",
    "                        'Removal or Storage Requirement':['Removal or Storage Requirement',\n",
    "                                                          'Removal or Storage Requirements',\n",
    "                                                         'Removal and Storage Requirement',\n",
    "                                                         'Removal and Storage Requirements',\n",
    "                                                         'Storage or Removal Requirement',\n",
    "                                                         'Storage and Removal Requirement',\n",
    "                                                         'Storage and Removal Requirements']}\n",
    "    \n",
    "    for heading, variants in section_headings.items():\n",
    "        for variant in variants:\n",
    "            analysis_text = analysis_text.replace(variant, r'\\textbf{%s}' % heading)\n",
    "\n",
    "    analysis_text = analysis_text.replace(header.findall(analysis_text)[0]+'\\n','')\n",
    "\n",
    "    latex_block = clean_text(analysis_text)\n",
    "\n",
    "    with open(f'TEXT/analysis_text/{cons_tds}_analysis.tex', 'w') as file_handle:\n",
    "        file_handle.write(latex_block)\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_analysis_text(cons_tds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'By understanding how much waste is generated at each consolidation, planners and managers\\ncan better determine how well current assets and services serve current needs, and what additional \\nelements are necessary in order for each consolidation to operate as efficiently as possible. \\n\\n%s has (%s) 30-CY external compactors, amounting to %s ft2 of storage space for garbage. \\nGiven the rate at which waste is produced at NYCHA properties, these containers will fill\\nup in about (3) days at the Sumner Consolidation. The average weight of the containers at\\ncapacity should be about (3) tons.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''By understanding how much waste is generated at each consolidation, planners and managers\n",
    "can better determine how well current assets and services serve current needs, and what additional \n",
    "elements are necessary in order for each consolidation to operate as efficiently as possible. \n",
    "\n",
    "%s has (%s) 30-CY external compactors, amounting to %s ft2 of storage space for garbage. \n",
    "Given the rate at which waste is produced at NYCHA properties, these containers will fill\n",
    "up in about (3) days at the Sumner Consolidation. The average weight of the containers at\n",
    "capacity should be about (3) tons.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and Prepare Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set asset map path\n",
    "asset_map_path = f\"MAPS/asset_maps/{cons_tds}_asset_map.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split context map into two pages\n",
    "def process_context_map(cons_tds):\n",
    "    image = Image.open(f'MAPS/context_maps/{cons_tds}_context_map.png')\n",
    "    width, height = image.size\n",
    "\n",
    "    bb1 = (0,0,width/2,height)\n",
    "    bb2 = (width/2, 0, width, height)\n",
    "\n",
    "    img_1 = image.crop(bb1)\n",
    "    img_2 = image.crop(bb2)\n",
    "\n",
    "    img_1.save(f'MAPS/context_maps/{cons_tds}_context_1.png', format=\"PNG\")\n",
    "    img_2.save(f'MAPS/context_maps/{cons_tds}_context_2.png', format=\"PNG\")\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_context_map(cons_tds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO COME:\n",
    "- Waste Services and Assets\n",
    "- Assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Overview Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_overview_table(cons_tds, overview_data=overview_data):\n",
    "    \n",
    "    cons_data = overview_data.loc[overview_data['CONS_TDS']== cons_tds]\n",
    "    \n",
    "    overview_table = ''\n",
    "\n",
    "    overview_frame = r'''\n",
    "    \\begin{tabular}{l|c|c|c|c|}\n",
    "    \\cline{2-5}\n",
    "                                                                           & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} TDS \\#} & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} Total Households} & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} Official Population} & \\cellcolor{ccteal}{\\color[HTML]{FFFFFF} Average Family Size} \\\\ \\hline\n",
    "\n",
    "    '''\n",
    "\n",
    "    development_template = r'''\\multicolumn{1}{|l|}{\\cellcolor{ccteallight}%s}        & %s                                                   & %s                                                           & %s                                                                & %s                                                                \\\\ \\hline'''\n",
    "\n",
    "\n",
    "    overview_table += overview_frame\n",
    "\n",
    "    for row in cons_data.itertuples():\n",
    "        dev_name = row.DEV_NAME.title()\n",
    "        dev_tds = row.TDS\n",
    "        total_hhs = row.TOTAL_HH\n",
    "        official_population = row.TOTAL_POP\n",
    "        avg_family_size = row.AVG_FAMILY_SIZE\n",
    "\n",
    "        overview_table += development_template % (dev_name, dev_tds, total_hhs, official_population, avg_family_size)\n",
    "\n",
    "    overview_table += r'''\n",
    "    \\end{tabular}\n",
    "    '''\n",
    "    \n",
    "    with open(f'TABLES/overview_table/{cons_tds}_overview_table.tex', 'w') as file_handle:\n",
    "        file_handle.write(overview_table)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tds in cons_tds_list:\n",
    "    make_overview_table(tds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Typology Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_typology_data():\n",
    "    #Cleaning and Shaping Data\n",
    "    typ_1 = pd.read_csv('DATA/typologies_1.csv')\n",
    "    typ_2 = pd.read_csv('DATA/typologies_2.csv')\n",
    "\n",
    "    typ_1.columns = ['CONS_NAME', 'DEV_NAME', 'TDS', 'TYPOLOGY']\n",
    "    typ_2.columns = ['CONS_NAME', 'CONS_TDS', 'DEV_NAME', 'TDS', 'METHOD', \n",
    "                     'CONSTRUCTION_DATE', 'BLDG_AGE', 'STORIES', 'BLDG_COVERAGE_SQFT', 'OPEN_SPACE_RATIO', 'SCATTERED_SITE_FLAG']\n",
    "\n",
    "    def make_dates(date_col):\n",
    "        date = str(date_col).split('/')\n",
    "        try:\n",
    "            if int(date[2]) > 18:\n",
    "                return datetime.date(int(f'19{date[2]}'), int(date[0]), int(date[1]))\n",
    "            else:\n",
    "                return datetime.date(int(f'20{date[2]}'), int(date[0]), int(date[1]))\n",
    "        except IndexError:\n",
    "            return datetime.date(1900,1,1)\n",
    "\n",
    "    typ_2['CONSTRUCTION_DATE'] = typ_2['CONSTRUCTION_DATE'].apply(lambda x: make_dates(x))\n",
    "    typ_2['SCATTERED_SITE_FLAG'] = typ_2['SCATTERED_SITE_FLAG'].apply(lambda x: x == 'YES')\n",
    "    typ_2.loc[typ_2['SCATTERED_SITE_FLAG']=='YES','SCATTERED_SITE_FLAG'] = 1\n",
    "\n",
    "    typology = typ_1.merge(typ_2[['CONS_TDS', 'TDS', 'METHOD',\n",
    "                                 'CONSTRUCTION_DATE', 'BLDG_AGE', \n",
    "                                 'STORIES', 'BLDG_COVERAGE_SQFT', \n",
    "                                 'OPEN_SPACE_RATIO', 'SCATTERED_SITE_FLAG']], how='left', on='TDS')\n",
    "\n",
    "    typology['CONS_TDS'] = typology['CONS_TDS'].apply(lambda x: str(int(x)).zfill(3))\n",
    "    typology['PREWAR'] = typology['CONSTRUCTION_DATE'].apply(lambda x: x < datetime.date(1945,1,1))\n",
    "\n",
    "    #Adding Typology Icons\n",
    "\n",
    "    typ_icons = [r'\\rootpath/IMAGES/typology_earlytower.png', r'\\rootpath/IMAGES/typology_towerpark.png', r'\\rootpath/IMAGES/typology_prewar.png', r'\\rootpath/IMAGES/typology_scatteredsite.png']\n",
    "    typ_dict = {}\n",
    "    [typ_dict.setdefault(key, '') for key in typology['TYPOLOGY'].unique().tolist()]\n",
    "\n",
    "    typ_dict['1 - High-rise in the park'] = typ_icons[1]\n",
    "    typ_dict['2 - Mid-rise in the park'] = typ_icons[1]\n",
    "    typ_dict['3 - Low-rise in the park'] = typ_icons[0]\n",
    "    typ_dict['4 - Context Towers'] = typ_icons[3]\n",
    "    typ_dict['5 - Context Mid-rises'] = typ_icons[2]\n",
    "    typ_dict['6 - Walkups & Brownstones'] = typ_icons[2]\n",
    "\n",
    "    typ_header = re.compile(r'\\d\\s-\\s')\n",
    "\n",
    "    typology['TYP_NAME'] = typology['TYPOLOGY'].apply(lambda x: typ_header.sub('', str(x)))\n",
    "    typology['IMAGE_PATH'] = typology['TYPOLOGY'].apply(lambda x: typ_dict[x])\n",
    "    \n",
    "    return typology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "typology = load_typology_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_typology_table_block(cons_tds, typ_data):\n",
    "    cons_data = typ_data[typ_data['CONS_TDS'] == cons_tds]\n",
    "    num_devs = cons_data.shape[0]\n",
    "    \n",
    "    if num_devs < 5:\n",
    "        block_1 = cons_data\n",
    "    \n",
    "    elif num_devs >=5 and num_devs < 7:\n",
    "        block_1 = cons_data.iloc[0:3]\n",
    "        block_2 = cons_data.iloc[3:]\n",
    "    \n",
    "    else:\n",
    "        block_1 = cons_data.iloc[0:4]\n",
    "        block_2 = cons_data.iloc[4:]\n",
    "    \n",
    "    len_1 = block_1.shape[0]\n",
    "    \n",
    "    try:\n",
    "        len_2 = block_2.shape[0]\n",
    "    except:\n",
    "        len_2 = 0\n",
    "    \n",
    "    headers = {1:r\"\\begin{tabular}{m{1.5in} m{2in}\"+'\\n',\n",
    "              2:r\"\\begin{tabular}{m{1.25in} m{2in} m{.1in} m{1.25in} m{2in}}\"+'\\n',\n",
    "              3:r\"\\begin{tabular}{m{1.25in} m{1.5in} m{.2in} m{1.25in} m{1.5in} m{.2in} m{1.25in} m{1.5in}}\"+'\\n',\n",
    "              4:r\"\\begin{tabular}{m{1.25in} m{1.25in} m{.2in} m{1.25in} m{1.25in} m{.2in} m{1.25in} m{1.25in} m{.2in} m{1.25in} m{1.25in}}\"+'\\n'}\n",
    "         \n",
    "    lines = {1:r'''\\textbf{%s:} {%s} & \\includegraphics[height=2in]{%s}'''+'\\n'+r'\\end{tabular}',\n",
    "            2:r'''\\textbf{%s:} {%s} & \\includegraphics[height=2in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=2in]{%s}'''+'\\n'+r'\\end{tabular}',\n",
    "            3:r'''\\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s}'''+'\\n'+r'\\end{tabular}',\n",
    "            4:r'''\\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s} & & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s}& & \\textbf{%s:} {%s} & \\includegraphics[height=1.5in]{%s}'''+'\\n'+r'\\end{tabular}'}\n",
    "    \n",
    "    \n",
    "    data_1 = []\n",
    "    data_2 = []\n",
    "    \n",
    "    for row in block_1.itertuples():\n",
    "        data_1.append(str(row.DEV_NAME).title())\n",
    "        data_1.append(str(row.TYP_NAME).replace('&', '\\&'))\n",
    "        data_1.append(row.IMAGE_PATH)\n",
    "    \n",
    "    if len_2 > 0:\n",
    "        for row in block_2.itertuples():\n",
    "            data_2.append(str(row.DEV_NAME.title()))\n",
    "            data_2.append(str(row.TYP_NAME).replace('&', '\\&'))\n",
    "            data_2.append(row.IMAGE_PATH)\n",
    "    \n",
    "    # Assembling Nested Tables\n",
    "    latex_block = ''\n",
    "    latex_block += r'''\\begin{table}[H]\n",
    "    \\resizebox{\\textwidth}{!}{\n",
    "    \\begin{tabular}{c}\n",
    "    '''\n",
    "    \n",
    "    latex_block += headers[len_1]\n",
    "    latex_block += lines[len_1] % tuple(data_1)\n",
    "    \n",
    "    if len_2 > 0:\n",
    "        latex_block += r'''\\\\\n",
    "        '''\n",
    "        latex_block += headers[len_2]\n",
    "        latex_block += lines[len_2] % tuple(data_2)\n",
    "    \n",
    "    latex_block += r'''\\end{tabular}}\n",
    "    \\end{table}'''\n",
    "    \n",
    "    with open(f'TABLES/typology_table/{cons_tds}_typology.tex', 'w') as file_handle:\n",
    "        file_handle.write(latex_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "typology = load_typology_data()\n",
    "\n",
    "for tds in cons_tds_list:\n",
    "    make_typology_table_block('073', typology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_cons_tds = {'091':'Baisley Park. Isolate important developments.',\n",
    "                   '359':'Skip for now.'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waste Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_waste_cols(overview_data=overview_data):\n",
    "    conversion_factors = {'units_to_tons_day': 0.0025,\n",
    "                         'cy_per_ton': {'trash': 21.05,\n",
    "                                        'trash_actual': 0,\n",
    "                                       'MGP': 18.02,\n",
    "                                       'cardboard': 26.67,\n",
    "                                       'paper': 6.19,\n",
    "                                       'organics': 4.32,\n",
    "                                       'ewaste': 5.65,\n",
    "                                       'textiles': 13.33},\n",
    "                         'gallons_per_cy': 201.974,\n",
    "                         'gallons_per_64gal': 64,\n",
    "                         'gallons_per_40lb_bag': 44,\n",
    "                         'cy_per_44gal_bag':0.174,\n",
    "                         'cy_per_cardboard_bale':0.193}\n",
    "\n",
    "    waste_percentages = {'trash': .26,\n",
    "                         'trash_actual':.894,\n",
    "                        'MGP': .19,\n",
    "                        'cardboard': .07,\n",
    "                        'paper': .07,\n",
    "                        'organics':.32,\n",
    "                        'ewaste': .01,\n",
    "                        'textiles': .08}\n",
    "\n",
    "    capture_rates = {'trash_primary': .75,\n",
    "                    'trash_secondary': .25,\n",
    "                    'mgp': .30,\n",
    "                    'cardboard': .50,\n",
    "                    'paper': .20}\n",
    "\n",
    "    overview_data['WASTE_TONS_DAY'] = overview_data['CURRENT_APTS'].apply(lambda x: x * conversion_factors['units_to_tons_day'])\n",
    "\n",
    "    for key, value in waste_percentages.items():\n",
    "        overview_data[f'{key.upper()}_CY'] = overview_data['WASTE_TONS_DAY'].apply(lambda x: x * value * conversion_factors['cy_per_ton'][key])\n",
    "        overview_data[f'{key.upper()}_TONS'] = overview_data['WASTE_TONS_DAY'].apply(lambda x: x * value)\n",
    "    \n",
    "    overview_data['TRASH_ACTUAL_CY'] = (overview_data['TRASH_CY']+\n",
    "                                           overview_data['MGP_CY']+\n",
    "                                           overview_data['CARDBOARD_CY']+\n",
    "                                           overview_data['PAPER_CY']+\n",
    "                                           overview_data['ORGANICS_CY']+\n",
    "                                           overview_data['EWASTE_CY']+\n",
    "                                           overview_data['TEXTILES_CY'])-(overview_data['MGP_CY']*capture_rates['mgp']+\n",
    "                                                                         overview_data['CARDBOARD_CY']*capture_rates['cardboard']+\n",
    "                                                                         overview_data['PAPER_CY']*capture_rates['paper'])\n",
    "\n",
    "    overview_data['TRASH_CHUTE_CY'] = overview_data['TRASH_ACTUAL_CY']*capture_rates['trash_primary']\n",
    "    overview_data['TRASH_CHUTE_TONS'] = overview_data['TRASH_ACTUAL_TONS']*capture_rates['trash_primary']\n",
    "    overview_data['TRASH_CHUTE_SAUSAGE'] = ((overview_data['TRASH_CHUTE_CY'])/conversion_factors['cy_per_ton']['trash'])*(2000/40)\n",
    "    overview_data['TRASH_DROP_CY'] = overview_data['TRASH_ACTUAL_CY']*capture_rates['trash_secondary']\n",
    "    overview_data['TRASH_DROP_TONS'] = overview_data['TRASH_ACTUAL_TONS']*capture_rates['trash_secondary']\n",
    "    overview_data['TRASH_DROP_BINS'] = overview_data['TRASH_DROP_CY']*conversion_factors['gallons_per_cy']/64\n",
    "    overview_data['CAPTURED_MGP_TONS_WEEK'] = overview_data['MGP_TONS']*capture_rates['mgp']*7\n",
    "    overview_data['CAPTURED_CARDBOARD_TONS_WEEK'] = overview_data['CARDBOARD_TONS']*capture_rates['cardboard']*7\n",
    "    overview_data['CAPTURED_PAPER_TONS_WEEK'] = overview_data['PAPER_TONS']*capture_rates['paper']*7\n",
    "    overview_data['MGP_BAGS_WEEK'] = overview_data['MGP_CY']*capture_rates['mgp']*7/conversion_factors['cy_per_44gal_bag']\n",
    "    overview_data['PAPER_BAGS_WEEK'] = overview_data['PAPER_CY']*capture_rates['paper']*7/conversion_factors['cy_per_44gal_bag']\n",
    "    overview_data['CARDBOARD_BALES_WEEK'] = overview_data['CARDBOARD_CY']*capture_rates['cardboard']*7/conversion_factors['cy_per_cardboard_bale']\n",
    "    \n",
    "    return overview_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_data = add_waste_cols(overview_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_waste_distribution_table(cons_tds, overview_data=overview_data):\n",
    "    cons_data = overview_data[overview_data['CONS_TDS'] == cons_tds]\n",
    "    num_devs = cons_data.shape[0]\n",
    "    \n",
    "    if num_devs > 1:\n",
    "        num_cols = num_devs+1\n",
    "    else:\n",
    "        num_cols = num_devs\n",
    "\n",
    "    dev_col_format = r'X|'\n",
    "\n",
    "    opening = r'''\n",
    "    \\begin{tabularx}{\\textwidth}{V{1.5in}|%s}\n",
    "    \\cline{2-%s}\n",
    "    ''' % (dev_col_format*num_cols, (num_cols+1))\n",
    "\n",
    "    top_row = r'''\n",
    "                                                                   '''+(r\"& \\multicolumn{1}{l|}{\\cellcolor{ccorange}%s}\"*(num_cols))+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    standard_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s}                 \"+(r\"& %s                                    \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    captured_row = r\"\\multicolumn{1}{|Y{1.5in}|}{\\cellcolor{ccorangelight}Captured / Week (tons)\\tnote{4}}                        \"+(r\"& %s                                    \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    chute_row = r\"\\multicolumn{1}{|Y{1.5in}|}{\\cellcolor{ccorangelight}Trash Chutes\\tnote{2}}                 \"+(r\"& %s tons or (%s) 40 lbs. sausage bags      \"*num_cols)+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    dropsite_row = r\"\\multicolumn{1}{|Y{1.5in}|}{\\cellcolor{ccorangelight}Drop Sites\\tnote{3}}                 \"+(r\"& %s tons or (%s) 64-gallon bins      \"*num_cols)+r\"\\tnhl\"+'\\n'\n",
    "\n",
    "    OET_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s / Day (CY)\\tnote{5}}              \"+(r\"& %s                                    \"*num_cols)+r\"\\tnhl\"+'\\n'\n",
    "    \n",
    "    recycling_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s}                 \"+(r\"& %s tons or (%s) 44-gallon bags                                   \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "    \n",
    "    cardboard_row = r\"\\multicolumn{1}{|V{1.5in}|}{\\cellcolor{ccorangelight}%s}                 \"+(r\"& %s tons or (%s) bales                                   \")*num_cols+r\"\\tnhl\"+'\\n'\n",
    "    \n",
    "    def make_waste_distribution_table_block(cons_data, num_cols):\n",
    "        if num_cols != 1:\n",
    "            cons_data.loc['Total']= cons_data.sum(numeric_only=True, axis=0)\n",
    "            cons_data.loc['Total','DEV_NAME'] = 'Total'\n",
    "\n",
    "        def make_trash_text(row, text_var, cy_col, other_col):\n",
    "            text_var.append(round(row[cy_col],2))\n",
    "            text_var.append(round(row[other_col], 2))\n",
    "            pass\n",
    "\n",
    "        latex_block = opening\n",
    "        latex_block += top_row % tuple(cons_data['DEV_NAME'].apply(lambda x: str(x).title()).tolist())\n",
    "        latex_block += standard_row % tuple([r\"Waste Generated / Day (Tons)\\tnote{1}\"]+[round(item, 2) for item in cons_data['WASTE_TONS_DAY'].tolist()])\n",
    "        latex_block += standard_row % tuple([r\"Trash / Day (tons)\\tnote{2}\"]+cons_data['TRASH_ACTUAL_TONS'].apply(lambda x: str(round(x,2))).tolist())\n",
    "\n",
    "        trash_chute_text = []\n",
    "        dropsite_text = []\n",
    "\n",
    "        cons_data.apply(lambda row: make_trash_text(row, trash_chute_text, 'TRASH_CHUTE_TONS', 'TRASH_CHUTE_SAUSAGE'), axis=1)\n",
    "        cons_data.apply(lambda row: make_trash_text(row, dropsite_text, 'TRASH_DROP_TONS', 'TRASH_DROP_BINS'), axis=1)\n",
    "\n",
    "        latex_block += chute_row % tuple(trash_chute_text)\n",
    "        latex_block += dropsite_row % tuple(dropsite_text)\n",
    "        \n",
    "        latex_block += r\"\\end{tabularx}\\bigskip\"\n",
    "        \n",
    "        latex_block += opening\n",
    "        latex_block += top_row % tuple(cons_data['DEV_NAME'].apply(lambda x: str(x).title()).tolist())\n",
    "        \n",
    "        mgp_text = []\n",
    "        cardboard_text= []\n",
    "        paper_text = []\n",
    "        \n",
    "        cons_data.apply(lambda row: make_trash_text(row, mgp_text, 'CAPTURED_MGP_TONS_WEEK', 'MGP_BAGS_WEEK'), axis=1)\n",
    "\n",
    "        cons_data.apply(lambda row: make_trash_text(row, cardboard_text, 'CAPTURED_CARDBOARD_TONS_WEEK', 'CARDBOARD_BALES_WEEK'), axis=1)\n",
    "\n",
    "        cons_data.apply(lambda row: make_trash_text(row, paper_text, 'CAPTURED_PAPER_TONS_WEEK', 'PAPER_BAGS_WEEK'), axis=1)\n",
    "\n",
    "\n",
    "        \n",
    "        latex_block += recycling_row % tuple([r\"Metal, Glass, Plastic Captured / Week (tons)\"]+mgp_text)\n",
    "        #latex_block += captured_row % tuple(cons_data['CAPTURED_MGP_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        latex_block += cardboard_row % tuple([r\"Cardboard Captured / Week (tons)\"]+cardboard_text)\n",
    "        #latex_block += captured_row % tuple(cons_data['CAPTURED_CARDBOARD_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        latex_block += recycling_row % tuple([r\"Paper Captured / Week (tons)\"]+paper_text)\n",
    "        #latex_block += captured_row % tuple(cons_data['CAPTURED_PAPER_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "\n",
    "        #latex_block += OET_row % tuple(['Organics']+cons_data['ORGANICS_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        #latex_block += OET_row % tuple(['E-Waste']+cons_data['EWASTE_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "        #latex_block += OET_row % tuple(['Textiles']+cons_data['TEXTILES_CY'].apply(lambda x: str(round(x,2))).tolist())\n",
    "\n",
    "        latex_block += r\"\\end{tabularx}\"\n",
    "\n",
    "        return latex_block\n",
    "    \n",
    "    \n",
    "    latex_block = make_waste_distribution_table_block(cons_data, num_cols)\n",
    "    \n",
    "    with open(f'TABLES/waste_distribution_table/{cons_tds}_wd_table.tex', 'w') as file_handle:\n",
    "        file_handle.write(latex_block)\n",
    "    \n",
    "    \n",
    "    text_block = r''''''\n",
    "    \n",
    "    text_line_multi = r\"\\bf{%s}: This development has %s apartment units and %s stairhalls.\\\\\"\n",
    "\n",
    "    text_line_singular = r\"\\bf{%s}: This development has %s apartment units and one stairhall.\\\\\"\n",
    "    \n",
    "    for row in cons_data.itertuples():\n",
    "    \n",
    "        if int(row.STAIRHALLS) == 1:\n",
    "            text_block += text_line_singular % (row.DEV_NAME.title(), int(row.CURRENT_APTS))\n",
    "        else:\n",
    "            text_block += text_line_multi % (row.DEV_NAME.title(), int(row.CURRENT_APTS), int(row.STAIRHALLS))\n",
    "\n",
    "    \n",
    "    with open(f'TEXT/waste_distribution_bottom/{cons_tds}_wd_bottom.tex', 'w') as file_handle:\n",
    "        file_handle.write(text_block)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception raised by 091\n"
     ]
    }
   ],
   "source": [
    "for tds in cons_tds_list:\n",
    "    try:\n",
    "        make_waste_distribution_table(tds)\n",
    "    except:\n",
    "        print(f'Exception raised by {tds}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Capital Improvements Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_asset_data():\n",
    "    asset_data = {'fwd': ['In-Sink Food Grinders', pd.read_csv('DATA/capital_fwd.csv')],\n",
    "                  'ehd': ['Enlarged Hopper Doors', pd.read_csv('DATA/capital_ehd.csv')],\n",
    "                  'int_compactor':['Interior Compactor Replacement', pd.read_csv('DATA/capital_intcom.csv')],\n",
    "                  'wasteyard':['Waste Yard Redesign', pd.read_csv('DATA/capital_wasteyard.csv')]}\n",
    "\n",
    "    for value in asset_data.values():\n",
    "        value[1].columns = [item.strip() for item in value[1].columns]\n",
    "\n",
    "    asset_data['wasteyard'][1]['ESTIMATE'] = asset_data['wasteyard'][1]['TOT_EST']\n",
    "    asset_data['wasteyard'][1]['COST'] = np.nan\n",
    "    \n",
    "    def year_to_string(year):\n",
    "        if year == np.nan:\n",
    "            return ''\n",
    "        else:\n",
    "            return str(year)\n",
    "    \n",
    "    asset_data['fwd'][1]['_YEAR'] = asset_data['fwd'][1]['EST_YEAR'].apply(lambda x: year_to_string(x))\n",
    "    asset_data['ehd'][1]['_YEAR'] = asset_data['fwd'][1]['CYEAR'].apply(lambda x: year_to_string(x))\n",
    "    asset_data['int_compactor'][1]['_YEAR'] = asset_data['int_compactor'][1]['CYEAR'].apply(lambda x: year_to_string(x))\n",
    "    asset_data['wasteyard'][1]['_YEAR'] = asset_data['wasteyard'][1]['CONS_CYEAR'].apply(lambda x: year_to_string(x))\n",
    "    return asset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_data = load_asset_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_data['wasteyard'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_capital_table(cons_tds, asset_data, overview_data=overview_data):\n",
    "    cons_data = overview_data[overview_data['CONS_TDS'] == cons_tds]\n",
    "    num_devs = cons_data.shape[0]\n",
    "\n",
    "    dev_col_format = r'X|'\n",
    "    header = r'''\n",
    "    \\begin{tabularx}{\\textwidth}{r|%s}\n",
    "    \\cline{2-%s}\n",
    "    ''' % ((dev_col_format*num_devs), num_devs)\n",
    "\n",
    "    top_row = r\"\\multicolumn{1}{l|}{}                                                        \"+r\"& \\cellcolor{ccorange}{\\color[HTML]{FFFFFF}%s} \"*num_devs+r\"\\\\ \\hline\"+\"\\n\"\n",
    "\n",
    "    project_block = r\"\\multicolumn{1}{|V{.2\\columnwidth}|}{\\cellcolor{ccorangelight}%s}          \"+(r\"&                                                                  \"*num_devs)+r\"\\\\\"+r'''\n",
    "    \\multicolumn{1}{|r|}{\\cellcolor{ccorangelight}\\textit{Status}}                '''+(r\"& %s                                                         \"*num_devs)+r'''\\\\\n",
    "    \\multicolumn{1}{|r|}{\\cellcolor{ccorangelight}\\textit{%s}}                  '''+(\"& %s                                                     \"*num_devs)+r\"\\\\ \\hline\"+\"\\n\"\n",
    "    \n",
    "    def make_capital_table_block(cons_data):\n",
    "        devs = cons_data['DEV_NAME'].apply(lambda x: str(x).upper()).tolist()\n",
    "        devs_title = cons_data['DEV_NAME'].apply(lambda x: str(x).title()).tolist()\n",
    "        latex_block = ''\n",
    "        latex_block += header\n",
    "        latex_block += top_row % tuple(cons_data['DEV_NAME'].apply(lambda x: str(x).title()).tolist())\n",
    "\n",
    "        for asset in asset_data.keys():\n",
    "            asset_df = asset_data[asset][1]\n",
    "            #print(asset_data[asset][0])\n",
    "            #print(devs)\n",
    "            #print(asset_df['DEVELOPMENT'].tolist())\n",
    "            if any((dev in asset_df['DEVELOPMENT'].tolist()) for dev in devs):\n",
    "                status_list = []\n",
    "                year_list = []\n",
    "\n",
    "                for dev in devs:\n",
    "                    if dev in asset_df['DEVELOPMENT'].tolist():\n",
    "                        #print(dev)\n",
    "                        if pd.isna(asset_df.loc[asset_df['DEVELOPMENT']== dev,'STATUS'].iloc[0]):\n",
    "                            status_list.append('Not Yet Scheduled')\n",
    "                        else:\n",
    "                            status_list.append(str(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'STATUS'].iloc[0]).title())\n",
    "\n",
    "                        #print(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'STATUS'])\n",
    "                        #print(asset_df.loc[asset_df['DEVELOPMENT']== dev, 'COST'])\n",
    "                        try:\n",
    "                            if int(asset_df.loc[asset_df['DEVELOPMENT']== dev,'_YEAR'].iloc[0])>2020:\n",
    "                                year_list.append(str(int(asset_df.loc[asset_df['DEVELOPMENT']== dev,'_YEAR'].iloc[0]))+' (est.)')\n",
    "                            else:\n",
    "                                year_list.append(str(int(asset_df.loc[asset_df['DEVELOPMENT']== dev,'_YEAR'].iloc[0])))\n",
    "                        except:\n",
    "                            year_list.append('')\n",
    "\n",
    "                    else:\n",
    "                        status_list.append('N/A')\n",
    "                        year_list.append(' ')\n",
    "\n",
    "                asset_block = project_block % tuple([asset_data[asset][0]]+status_list+['Year Planned']+year_list)\n",
    "\n",
    "                latex_block += asset_block\n",
    "\n",
    "        latex_block += r\"\\end{tabularx}\"\n",
    "\n",
    "        return latex_block\n",
    "    \n",
    "    capital_block = make_capital_table_block(cons_data)\n",
    "    \n",
    "    with open(f\"TABLES/capital_projects_table/{cons_tds}_capital_projects.tex\", 'w') as file_handle:\n",
    "        file_handle.write(make_capital_table_block(cons_data))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_capital_table('073', load_asset_data(), load_overview_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Staff Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_staff_data():\n",
    "    # Read consolidation name data\n",
    "    cons_ids = pd.read_csv('DATA/CONS_NAME_TDS.csv')\n",
    "    cons_ids['CONS_TDS'] = cons_ids['CONS_TDS'].apply(lambda x: str(x).zfill(3))\n",
    "\n",
    "    #Read budgeted staff and formula allocation\n",
    "    dev_staff = pd.read_csv('DATA/staff_for_table.csv')\n",
    "    dev_staff.dropna(inplace=True)\n",
    "    dev_staff['Consolidation'] = dev_staff['Consolidation'].apply(lambda x: str(x).upper())\n",
    "    #Note: Staff list missing for Armstrong, Ft. Washington, and Williams Plaza, as well as scatter-site third-party-managed consolidations\n",
    "    dev_staff = dev_staff.merge(cons_ids, left_on='Consolidation', right_on='CONS_NAME', how='inner', indicator=False)\n",
    "\n",
    "    #Read budgeted staff and actuals\n",
    "    actuals_data = pd.read_csv('DATA/Staffing_Analysis/DEVHC.csv')\n",
    "    actuals_data.fillna(0, inplace=True)\n",
    "    actuals_data = actuals_data[actuals_data['RC Name'].apply(lambda x: \"total\" not in str(x).lower()) & actuals_data['Department'].apply(lambda x: \"total\" not in str(x).lower())]\n",
    "\n",
    "    def convert_neg(x):\n",
    "        try:\n",
    "            return int(x)\n",
    "        except:\n",
    "            return int('-'+str(x).replace('(','').replace(')',''))\n",
    "\n",
    "    actuals_data['VARIANCE'] = actuals_data['Unnamed: 5'].apply(lambda x: convert_neg(x))\n",
    "    actuals_data['ACT'] = actuals_data['13']\n",
    "    \n",
    "    table_frame = pd.read_csv('DATA/Table_Keys.csv')\n",
    "    actuals_keys = pd.read_csv('DATA/Staffing_Analysis/DEVHC_CODES.csv')\n",
    "    \n",
    "    actuals_data = actuals_data.merge(actuals_keys, how='left', left_on='CST_NAME', right_on='TITLE_NAME')\n",
    "    for column in ['Current Modified', 'ACT', 'VARIANCE']:\n",
    "        actuals_data[column] = actuals_data[column].astype(int)\n",
    "        \n",
    "\n",
    "    \n",
    "    return (cons_ids, dev_staff, actuals_data, table_frame, actuals_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_staff_table(cons_tds, cons_ids, dev_staff, actuals_data, table_frame, actuals_keys):\n",
    "    cons_id = cons_ids['CONS_NAME'].loc[cons_ids['CONS_TDS'] == cons_tds].iloc[0]\n",
    "    \n",
    "    #Fetching staff data for consolidation\n",
    "    cons_data = dev_staff.loc[dev_staff['Consolidation'] == cons_id]\n",
    "    \n",
    "    # Isolate and process actuals data for consolidation\n",
    "    try:\n",
    "        cons_actuals = actuals_data[actuals_data['RC Name'].apply(lambda x: str(x).lower() == cons_id.lower())]\n",
    "    except:\n",
    "        print(f'{cons_id} not found in actuals.')\n",
    "        return np.NaN\n",
    "    \n",
    "    cons_actuals = cons_actuals[['RC Name', 'Current Modified', 'ACT', \n",
    "                                 'CODE_KEY', 'CODE_NAME']].groupby(by='CODE_KEY', as_index=False).agg({'RC Name': 'first',\n",
    "                                                                                                     'Current Modified':sum,\n",
    "                                                                                                     'ACT':sum,\n",
    "                                                                                                     'CODE_NAME':'first'})\n",
    "    cons_actuals\n",
    "    cons_actuals.loc['Total']= cons_actuals.sum(numeric_only=True, axis=0)\n",
    "    cons_actuals.loc['Total','CODE_KEY'] = 11\n",
    "    cons_actuals.loc['Total','CODE_NAME'] = 'TOT'\n",
    "    \n",
    "    for row in cons_actuals.itertuples():\n",
    "        cons_data[f'{row.CODE_NAME}_ACT'] = row.ACT\n",
    "    print(cons_data)\n",
    "    #Setting up table and transposing data\n",
    "    cons_table_frame = table_frame\n",
    "    cons_table_frame['Formula'] = cons_table_frame['FORMULA_KEY'].iloc[:-1].apply(lambda key: cons_data[key].iloc[0])\n",
    "    cons_table_frame['Budgeted'] = cons_table_frame['BUDG_KEY'].apply(lambda key: cons_data[key].iloc[0])\n",
    "    cons_table_frame['Actual'] = cons_table_frame['ACTUALS_KEY'].iloc[:-2].apply(lambda key: cons_data[key].iloc[0])\n",
    "\n",
    "    \n",
    "    #Simplifying table\n",
    "    cons_table = cons_table_frame[['CHART_LINE', 'Formula', 'Budgeted', 'Actual']]\n",
    "    #print(cons_table)\n",
    "    \n",
    "    #Defining LaTeX table format\n",
    "    \n",
    "    def make_staff_table_block(staff_data):\n",
    "    \n",
    "        table_template = r'''\n",
    "        \\begin{tabular}{l|c|c|c|}\n",
    "        \\cline{2-4}\n",
    "                                                                                     & \\cellcolor{ccfuschia}{\\color[HTML]{FFFFFF} Formula Allocation} & \\cellcolor{ccfuschia}{\\color[HTML]{FFFFFF} Budgeted} & \\cellcolor{ccfuschia}{\\color[HTML]{FFFFFF} Actual} \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Employees}                      & %s                                                      & %s                                                                & %s                                                        \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Property Manager}               & %s                                                      & %s                                                                & %s                                                       \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Asst. Property Manager}         & %s                                                      & %s                                                                & %s                                                       \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Secretaries}                    & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Housing Assistants}             & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Superintendent}                 & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Assistant Superintendent}       & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Supervisor of Caretakers (SOC)} & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Supervisor of Grounds (SOG)}    & %s                                                      & %s                                                                & %s                                                      \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Maintenance Workers}            & %s                                                      & %s                                                                & %s                                                       \\\\ \\hline\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Caretakers X}                   & %s                                                      & %s                                                                &                                                       \\\\ \\cline{1-3}\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Caretakers J\\tnote{1}}                   &                                                       & %s                                                                &                                                         \\\\ \\cline{1-1} \\cline{3-3}\n",
    "        \\multicolumn{1}{|l|}{\\cellcolor{ccfuschialight}Caretakers G}                   & \\multirow{-2}{*}{%s}                                                      & %s                                     & \\multirow{-3}{*}{%s}                           \\\\ \\hline\n",
    "        \\end{tabular}\n",
    "        \n",
    "        '''\n",
    "\n",
    "        values = []\n",
    "\n",
    "        def extract_data_through_mw(row):\n",
    "            [values.append(item) for item in [str(int(row['Formula'])), \n",
    "                                              str(int(row['Budgeted'])), \n",
    "                                              str(int(row['Actual']))]]\n",
    "            pass\n",
    "\n",
    "        #Processing through Maintenance Worker\n",
    "        staff_data.iloc[0:-3].apply(lambda row: extract_data_through_mw(row), axis=1)\n",
    "\n",
    "        #Processing Caretakers\n",
    "        values.append(str(int(staff_data.iloc[-3, 1])))\n",
    "        values.append(str(int(staff_data.iloc[-3, 2])))\n",
    "        values.append(str(int(staff_data.iloc[-2, 2])))\n",
    "        values.append(str(int(staff_data.iloc[-2, 1])))\n",
    "        values.append(str(int(staff_data.iloc[-1, 2])))\n",
    "        values.append(str(int(staff_data.iloc[-3, 3])))\n",
    "\n",
    "        return table_template % tuple(values)\n",
    "    \n",
    "    #Make and export LaTeX code\n",
    "    with open(f'TABLES/staff_table/{cons_tds}_staff_table.tex', 'w') as file_handle:\n",
    "        file_handle.write(make_staff_table_block(cons_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Consolidation, Borough, Acres, DU, PM, PM_FORMULA, APM, APM_FORMULA, SUPER, SUPER_FORMULA, ASUPER, ASUPER_FORMULA, SOG, SOG_FORMULA, HA, HA_FORMULA, SOC, SOC_FORMULA, CTG, CTJ, CJG_TOTAL, CJG_FORMULA, CTX, CTX_FORMULA, MW, MW_FORMULA, SEC, SEC_FORMULA, TOT, TOT_FORMULA, Unnamed: 0, CONS_NAME, CONS_TDS, TOT_ACT]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-7cec98a1c501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcons_tds_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmake_staff_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstaff_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-71-89e8bc8a10f2>\u001b[0m in \u001b[0;36mmake_staff_table\u001b[0;34m(cons_tds, cons_ids, dev_staff, actuals_data, table_frame, actuals_keys)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#Setting up table and transposing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcons_table_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mcons_table_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Formula'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcons_table_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FORMULA_KEY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcons_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mcons_table_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Budgeted'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcons_table_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BUDG_KEY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcons_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mcons_table_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcons_table_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ACTUALS_KEY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcons_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-89e8bc8a10f2>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#Setting up table and transposing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mcons_table_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable_frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mcons_table_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Formula'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcons_table_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FORMULA_KEY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcons_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mcons_table_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Budgeted'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcons_table_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'BUDG_KEY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcons_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mcons_table_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcons_table_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ACTUALS_KEY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcons_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1767\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2136\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2139\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "staff_data = load_staff_data()\n",
    "\n",
    "for tds in cons_tds_list:\n",
    "    make_staff_table(tds, *staff_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
